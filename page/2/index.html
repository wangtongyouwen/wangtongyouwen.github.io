<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" >
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <meta http-equiv="Content-Language" content="zh-cn">
  <link rel="dns-prefetch" href="https://wangtongyouwen.github.io">
  <title>jyh blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:type" content="website">
<meta property="og:title" content="jyh blog">
<meta property="og:url" content="https://wangtongyouwen.github.io/page/2/index.html">
<meta property="og:site_name" content="jyh blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="jyh">
<meta name="twitter:card" content="summary">
  
  
    <link rel="alternative" href="/atom.xml" title="jyh blog" type="application/atom+xml">
  
  
    <link rel="icon" type="image/x-icon" href="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg">
  
  <link rel="stylesheet" type="text/css" href="/css/main.0cf68a.css">
  
	<link rel="stylesheet" type="text/css" href="/css/avatarrotation.css">
  
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(45deg, #e0e5df, #96a48b);
    }
  </style>
    
  <!-- 引入font-awesome图标库 -->
  <!-- <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet"> -->
  <link href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css" rel="stylesheet">
  <!-- <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">-->
  
  <!--谷歌分析-->
  

  <!--百度统计-->
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  <!--百度自动推送-->
  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>

  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: linear-gradient(45deg, #e0e5df, #96a48b)"></div>
<div class="intrude-less">
	<header id="header" class="inner">
	
		<a href="/" class="profilepic">
			<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg" class="js-avatar" alt="avatar">
		</a>
		
		<hgroup>
		  <div class="header-author"><a href="/">jyh</a></div>
		</hgroup>
		
		
		<p class="header-subtitle">jyh的博客</p>
		

		<nav class="header-menu">
			<ul>   
			
			   	
				  <li><a href="/" class="fa fa-home fa-fw"></a></li>
				
	        
			   	
				  <li><a href="/archives/index.html">归档</a></li>
				
	        
			   	
				  <li><a href="/categories/index.html">分类</a></li>
				
	        
			
			</ul>
		</nav>

		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
			
			  
				<a href="/tags/pytorch/">pytorch</a>
			  
	        		
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
		        
					<a class="gitee" target="_blank" href="#" title="gitee"><i class="icon-gitee"></i></a>
		        
					<a class="csdn" target="_blank" href="#" title="csdn"><i class="icon-csdn"></i></a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
		        
					<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:XXX@XXX.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
		
		<!-- 网易云音乐插件 -->
		
			
		<!--时钟-->
		
			<!--时钟-->
<br>
<div style="position:absolute; bottom:120px left:auto; width:100%;height:50%">
	<script type="text/javascript" src="https://cdn.staticfile.org/vue/2.4.2/vue.min.js"></script>
	<div id="clock" style="font-family: 'Share Tech Mono', monospace;color: #ffffff;text-align: center;position: absolute;width: 250px;left: 50%;top: 50%;-webkit-transform: translate(50%, 50%);transform: translate(-50%, -50%);color: #4B8CE1;/* text-shadow: 0 0 20px #0aafe6, 0 0 20px rgba(10, 175, 230, 0); */">
		<p style="margin: 0;padding: 0;letter-spacing: 0.1em;font-size: 15px;">{{ date }}</p>
		<p style="margin: 0;padding: 0;letter-spacing: 0.01em;font-size: 25px;">{{ time }}</p>
	</div>
	<script>
		var clock = new Vue({
			el: '#clock',
			data: {
				time: '',
				date: ''
			}
		});

		var week = ['星期日', '星期一', '星期二', '星期三', '星期四', '星期五', '星期六'];
		var timerID = setInterval(updateTime, 1000);
		updateTime();
		function updateTime() {
			var cd = new Date();
			clock.time = zeroPadding(cd.getHours(), 2) + ':' + zeroPadding(cd.getMinutes(), 2) + ':' + zeroPadding(cd.getSeconds(), 2);
			clock.date = zeroPadding(cd.getFullYear(), 4) + '-' + zeroPadding(cd.getMonth() + 1, 2) + '-' + zeroPadding(cd.getDate(), 2) + ' ' + week[cd.getDay()];
		};

		function zeroPadding(num, digit) {
			var zero = '';
			for (var i = 0; i < digit; i++) {
				zero += '0';
			}
			return (zero + num).slice(-digit);
		}
	</script>
</div>
		

	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<!-- <div class="overlay js-overlay" style="background: linear-gradient(45deg, #e0e5df, #96a48b)"></div> -->
	<div class="overlay js-overlay" ></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)">
		<div class="left-icon-container">
			<i class="icon icon-sort"></i></div>
		</div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg" class="js-avatar" alt="avatar">
			</a>
			
			<hgroup>
			  <div class="header-author js-header-author">jyh</div>
			</hgroup>
			
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>jyh的博客<i class="icon icon-quo-right"></i></p>
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
			        
						<a class="gitee" target="_blank" href="#" title="gitee"><i class="icon-gitee"></i></a>
			        
						<a class="csdn" target="_blank" href="#" title="csdn"><i class="icon-csdn"></i></a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:XXX@XXX.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>
			
			
			
			
				
			
				
			
				
			
			
				
			
			

			<nav class="header-menu js-header-menu">
				<ul style="width: 80%">
					
					
						<li style="width: 25%"><a href="/">主页</a></li>
					
						<li style="width: 25%"><a href="/archives/index.html">归档</a></li>
					
						<li style="width: 25%"><a href="/categories/index.html">分类</a></li>
					
					
						<li style="width: 25%"><a href="/tags/pytorch/">pytorch</a></li>
					
				</ul>	
			</nav>
			
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-pytorch项目4-读取Excel-csv文件格式为PyTorch张量" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/9358f042.html">pytorch项目4-读取Excel/csv文件格式为PyTorch张量</a>
    </h2>
  

        
		
		  <a href="/post/9358f042.html" class="archive-article-date">
  	<time datetime="2023-04-27T08:33:55.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-27</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">299字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">1min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ExcelDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.xlsx&quot;</span>, sheet_name=<span class="number">0</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>, sheet=<span class="subst">&#123;sheet_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.xlsx&quot;</span>, sheet_name=<span class="number">0</span></span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>, sheet=<span class="subst">&#123;sheet_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            df = pandas.read_excel(</span><br><span class="line">                <span class="comment"># filepath,header=0,index_col=0,</span></span><br><span class="line">                filepath, header=<span class="number">0</span>,</span><br><span class="line">                names=[<span class="string">&#x27;admit&#x27;</span>, <span class="string">&#x27;gre&#x27;</span>, <span class="string">&#x27;gpa&#x27;</span>, <span class="string">&#x27;prestige&#x27;</span>],</span><br><span class="line">                sheet_name=sheet_name,</span><br><span class="line">                dtype=&#123;<span class="string">&quot;gre&quot;</span>: np.float32, <span class="string">&quot;gpa&quot;</span>: np.float32, <span class="string">&quot;admit&quot;</span>: np.int8, <span class="string">&quot;prestige&quot;</span>: np.string_&#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;the shape of dataframe is <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            feat = df.iloc[:, <span class="number">1</span>:<span class="number">3</span>].values</span><br><span class="line">            label = df.iloc[:, <span class="number">0</span>].values</span><br><span class="line">            self.x = torch.from_numpy(feat)</span><br><span class="line">            self.y = torch.from_numpy(label)</span><br><span class="line">            <span class="comment"># print(feat,label)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">            <span class="keyword">return</span> self.x[index], self.y[index]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Csv2Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.csv&quot;</span></span>):</span><br><span class="line">        <span class="comment"># there is no sheet name definition in csv format file</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file=filepath,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = f.readlines()</span><br><span class="line">        feat = []</span><br><span class="line">        label = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</span><br><span class="line">            values = line.strip().split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            row_feat = [<span class="built_in">float</span>(v) <span class="keyword">if</span> v <span class="keyword">is</span> <span class="keyword">not</span>  <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> v <span class="keyword">in</span> values[<span class="number">1</span>:<span class="number">2</span>]]</span><br><span class="line">            row_label = <span class="built_in">int</span>(values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            feat.append(row_feat)</span><br><span class="line">            label.append(row_label)</span><br><span class="line">        feat = np.array(feat,dtype=np.float32)</span><br><span class="line">        label = np.array(label,dtype=np.int8)</span><br><span class="line"></span><br><span class="line">        self.x = torch.from_numpy(feat)</span><br><span class="line">        self.y = torch.from_numpy(label)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br></pre></td></tr></table></figure>
<p>其中对缺省值进行处理，可以使用平均数来代替这个缺省值。</p>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">project</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/9358f042.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch项目3-基于ResNet的水果蔬菜分类" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/4627104a.html">pytorch项目3-基于ResNet的水果蔬菜分类</a>
    </h2>
  

        
		
		  <a href="/post/4627104a.html" class="archive-article-date">
  	<time datetime="2023-04-26T13:21:35.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-26</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">2.1k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">12min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h2 id="数据集介绍">1 数据集介绍</h2>
<p>https://aistudio.baidu.com/aistudio/datasetdetail/119023</p>
<p>其中的图片有36各类，不同类别在不同的文件夹中，其中文件后缀有"jpg,png,JPG"</p>
<h2 id="数据集预处理">2 数据集预处理</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pre_Data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 对所有图片进行RGB转换，并且统一调整到一致大小，但不让图片发生变形或扭曲,划分训练集和测试集&quot;&quot;&quot;</span></span><br><span class="line">    test_split_ratio = <span class="number">0.05</span></span><br><span class="line">    desired_size =<span class="number">128</span> <span class="comment"># 图片缩放后的同一大小</span></span><br><span class="line">    raw_path = <span class="string">&quot;./raw&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># class files in the raw data</span></span><br><span class="line">    dirs = glob.glob(os.path.join(raw_path,<span class="string">&quot;*&quot;</span>))</span><br><span class="line">    dirs = [d <span class="keyword">for</span> d <span class="keyword">in</span> dirs <span class="keyword">if</span> os.path.isdir(d)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(dirs)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(dirs)&#125;</span> classes: <span class="subst">&#123;dirs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> dirs:</span><br><span class="line">        <span class="comment"># 对每个类别单独处理</span></span><br><span class="line">        path = path.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>] <span class="comment"># classes</span></span><br><span class="line">        <span class="comment"># print(path)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>,exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        files = glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">        files += glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.JPG&quot;</span>))</span><br><span class="line">        files += glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.png&quot;</span>))</span><br><span class="line">        <span class="comment"># print(files)</span></span><br><span class="line">        random.shuffle(files)</span><br><span class="line"></span><br><span class="line">        boundary = <span class="built_in">int</span>(<span class="built_in">len</span>(files)*test_split_ratio) <span class="comment"># 测试集和训练集的边界</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i,file <span class="keyword">in</span> <span class="built_in">enumerate</span>(files):</span><br><span class="line">            img = Image.<span class="built_in">open</span>(file).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">            <span class="comment"># print(img)</span></span><br><span class="line">            old_size = img.size <span class="comment"># old_size[0] is in (width,height) format</span></span><br><span class="line">            <span class="comment"># print(old_size)</span></span><br><span class="line"></span><br><span class="line">            ratio = <span class="built_in">float</span>(desired_size)/<span class="built_in">max</span>(old_size)</span><br><span class="line"></span><br><span class="line">            new_size = <span class="built_in">tuple</span>([<span class="built_in">int</span>(x*ratio) <span class="keyword">for</span> x <span class="keyword">in</span> old_size])</span><br><span class="line"></span><br><span class="line">            im = img.resize(new_size,Image.LANCZOS) <span class="comment"># 无模糊</span></span><br><span class="line"></span><br><span class="line">            new_im = Image.new(<span class="string">&quot;RGB&quot;</span>,(desired_size,desired_size))</span><br><span class="line">            new_im.paste(im,((desired_size-new_size[<span class="number">0</span>])//<span class="number">2</span>,</span><br><span class="line">                             (desired_size-new_size[<span class="number">1</span>])//<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">assert</span> new_im.mode == <span class="string">&quot;RGB&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i &lt;= boundary:</span><br><span class="line">                new_im.save(os.path.join(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>,file.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]+ <span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(get_filename(file)+<span class="string">&quot;.jpg&quot;</span>) <span class="keyword">not</span> <span class="keyword">in</span> os.listdir(os.path.join(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>)):</span><br><span class="line">                    new_im.save(os.path.join(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>,file.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]+ <span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;classes <span class="subst">&#123;path&#125;</span> is done !&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_files = glob.glob(os.path.join(<span class="string">&quot;test&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">    train_files = glob.glob(os.path.join(<span class="string">&quot;train&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(test_files)&#125;</span> files for testing&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(train_files)&#125;</span> files for training&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_mean_std</span>():</span><br><span class="line">    train_files = glob.glob(os.path.join(<span class="string">&quot;train&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(train_files)&#125;</span> files for training&quot;</span>)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> train_files:</span><br><span class="line">        img = Image.<span class="built_in">open</span>(file).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        img = np.array(img).astype(np.uint8)</span><br><span class="line">        img = img / <span class="number">255</span></span><br><span class="line">        result.append(img)</span><br><span class="line">    <span class="built_in">print</span>(np.shape(result)) <span class="comment"># [bs,H,W,C]</span></span><br><span class="line">    mean = np.mean(result,axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    std = np.std(result,axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    <span class="built_in">print</span>(mean,std</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="eval">3 eval</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">data_loader, model, device</span>):</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    metric_logger = misc.MetricLogger(delimiter=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    header = <span class="string">&quot;test:&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># switch to evaluation mode</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> metric_logger.log_every(data_loader, <span class="number">10</span>, header):</span><br><span class="line">        <span class="comment"># print(batch)</span></span><br><span class="line">        images = batch[<span class="number">0</span>]</span><br><span class="line">        target = batch[-<span class="number">1</span>]</span><br><span class="line">        images = images.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line">        target = target.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute output</span></span><br><span class="line">        output = model(images)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line"></span><br><span class="line">        output = F.softmax(output, dim=-<span class="number">1</span>)</span><br><span class="line">        acc1, acc5 = accuracy(output, target, topk=(<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        batch_size = images.shape[<span class="number">0</span>]</span><br><span class="line">        metric_logger.update(loss=loss.item())</span><br><span class="line">        metric_logger.meters[<span class="string">&#x27;acc1&#x27;</span>].update(acc1.item(), n=batch_size)</span><br><span class="line">        metric_logger.meters[<span class="string">&#x27;acc5&#x27;</span>].update(acc5.item(), n=batch_size)</span><br><span class="line">    <span class="comment"># gather the stats from all processes</span></span><br><span class="line">    metric_logger.synchronize_between_processes()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;* Acc@1 &#123;top1.global_avg:.3f&#125; Acc@5 &#123;top5.global_avg:.3f&#125; loss &#123;losses.global_avg:.3f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))</span><br><span class="line">    <span class="keyword">return</span> &#123;k: meter.global_avg <span class="keyword">for</span> k, meter <span class="keyword">in</span> metric_logger.meters.items()&#125;</span><br></pre></td></tr></table></figure>
<h2 id="train">4 train</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model: nn.Module, criterion: nn.Module, data_loader: Iterable, optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">                    device: torch.device, epoch: <span class="built_in">int</span>, loss_scaler, max_norm: <span class="built_in">float</span> = <span class="number">0</span>, log_writer=<span class="literal">None</span>, args=<span class="literal">None</span></span>):</span><br><span class="line">    model.train(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    accum_iter = args.accum_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;log_dir:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(log_writer.log_dir))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_iter_step, (samples, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        samples = samples.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line">        targets = targets.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        outputs = model(samples)</span><br><span class="line"></span><br><span class="line">        warmup_lr = args.lr</span><br><span class="line">        optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>] = warmup_lr</span><br><span class="line"></span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss /= accum_iter</span><br><span class="line"></span><br><span class="line">        loss_scaler(loss, optimizer, clip_grad=max_norm,</span><br><span class="line">                    parameters=model.parameters(), create_graph=<span class="literal">False</span>,</span><br><span class="line">                    update_grad=(data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        loss_value = loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> math.isfinite(loss_value):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Loss is &#123;&#125;, stopping training&quot;</span>.<span class="built_in">format</span>(loss_value))</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot; We use epoch_1000x as the x-axis in tensorboard.</span></span><br><span class="line"><span class="string">            This calibrates different curves when batch size changes.</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            epoch_1000x = <span class="built_in">int</span>((data_iter_step / <span class="built_in">len</span>(data_loader) + epoch) * <span class="number">1000</span>)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;loss&#x27;</span>, loss_value, epoch_1000x)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;lr&#x27;</span>, warmup_lr, epoch_1000x)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch:<span class="subst">&#123;epoch&#125;</span>,Step: <span class="subst">&#123;data_iter_step&#125;</span>,loss: <span class="subst">&#123;loss&#125;</span>,lr: <span class="subst">&#123;warmup_lr&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="dataset">5 dataset</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def build_transform(is_train, args):</span><br><span class="line">    if is_train:</span><br><span class="line">        # this should always dispatch to transforms_imagenet_train</span><br><span class="line">        print(&quot;train transform&quot;)</span><br><span class="line">        return torchvision.transforms.Compose([</span><br><span class="line">            torchvision.transforms.Resize((args.input_size, args.input_size)),</span><br><span class="line">            torchvision.transforms.RandomHorizontalFlip(),</span><br><span class="line">            torchvision.transforms.RandomVerticalFlip(),</span><br><span class="line">            torchvision.transforms.RandomPerspective(distortion_scale=0.6, p=1.0),</span><br><span class="line">            torchvision.transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),</span><br><span class="line">            torchvision.transforms.ToTensor(),</span><br><span class="line">        ])</span><br><span class="line">    # eval transform</span><br><span class="line">    print(&quot;eval transform&quot;)</span><br><span class="line">    return torchvision.transforms.Compose([</span><br><span class="line">        torchvision.transforms.Resize((args.input_size, args.input_size)),</span><br><span class="line">        torchvision.transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def build_dataset(is_train, args):</span><br><span class="line">    transform = build_transform(is_train, args)</span><br><span class="line">    path = os.path.join(args.root_path, &quot;train&quot; if is_train else &quot;test&quot;)</span><br><span class="line">    dataset = torchvision.datasets.ImageFolder(path, transform=transform)</span><br><span class="line">    info = dataset.find_classes(path)</span><br><span class="line">    print(f&quot;finding classes from &#123;path&#125;:\t &#123;info[0]&#125;&quot;)</span><br><span class="line">    print(f&quot;mapping classes from &#123;path&#125; to indexes:\t &#123;info[1]&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    return dataset</span><br></pre></td></tr></table></figure>
<h2 id="argparse">6 argparse</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_args_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;MAE pre-training&#x27;</span>, add_help=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">72</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, default=<span class="number">400</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--accum_iter&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Accumulate gradient iterations (for increasing the effective batch size under memory constraints)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Model parameters</span></span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_size&#x27;</span>, default=<span class="number">128</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;images input size&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimizer parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weight_decay&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;weight decay (default: 0.0001)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>, metavar=<span class="string">&#x27;LR&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;learning rate (absolute lr)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dataset parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--root-path&#x27;</span>, default=<span class="string">&#x27;./dataset_fruit_veg/&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where the train test pic is &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--output_dir&#x27;</span>, default=<span class="string">&#x27;./output_dir_pretrained&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to save, empty for no saving&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--log_dir&#x27;</span>, default=<span class="string">&#x27;./output_dir_pretrained&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to tensorboard log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--resume&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;resume from checkpoint&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--start_epoch&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;start epoch&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, default=<span class="number">5</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--pin_mem&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--no_pin_mem&#x27;</span>, action=<span class="string">&#x27;store_false&#x27;</span>, dest=<span class="string">&#x27;pin_mem&#x27;</span>)</span><br><span class="line">    parser.set_defaults(pin_mem=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># distributed training parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--world_size&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of distributed processes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dist_on_itp&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dist_url&#x27;</span>, default=<span class="string">&#x27;env://&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;url used to set up distributed training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser</span><br></pre></td></tr></table></figure>
<h2 id="主要代码">7 主要代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args, mode=<span class="string">&quot;train&quot;</span>, test_image_path=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;mode&#125;</span> mode...&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建数据批次</span></span><br><span class="line">        dataset_train = build_dataset(is_train=<span class="literal">True</span>, args=args)</span><br><span class="line">        dataset_val = build_dataset(is_train=<span class="literal">False</span>, args=args)</span><br><span class="line"></span><br><span class="line">        sampler_train = torch.utils.data.RandomSampler(dataset_train)</span><br><span class="line">        sampler_val = torch.utils.data.SequentialSampler(dataset_val)</span><br><span class="line"></span><br><span class="line">        data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">            dataset_train, sampler=sampler_train,</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">            pin_memory=args.pin_mem,</span><br><span class="line">            drop_last=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        data_loader_val = torch.utils.data.DataLoader(</span><br><span class="line">            dataset_val, sampler=sampler_val,</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            <span class="comment"># batch_size = 1</span></span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">            pin_memory=args.pin_mem,</span><br><span class="line">            drop_last=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 构建模型</span></span><br><span class="line">        model = timm.create_model(<span class="string">&quot;resnet18&quot;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">36</span>, drop_rate=<span class="number">0.1</span>, drop_path_rate=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">        n_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;number of trainable params (M):%.2f&#x27;</span> % (n_parameters / <span class="number">1.e6</span>))</span><br><span class="line"></span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log dir</span></span><br><span class="line">        os.makedirs(args.log_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        log_writer = SummaryWriter(log_dir=args.log_dir)</span><br><span class="line">        loss_scaler = NativeScaler()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读入已有的模型</span></span><br><span class="line">        misc.load_model(args=args, model_without_ddp=model, optimizer=optimizer, loss_scaler=loss_scaler)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch<span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;length of data_loader_train is <span class="subst">&#123;<span class="built_in">len</span>(data_loader_train)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Evaluating...&quot;</span>)</span><br><span class="line">                model.<span class="built_in">eval</span>()</span><br><span class="line">                test_stats = evaluate(data_loader_val, model, device)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Accuracy of the network on the <span class="subst">&#123;<span class="built_in">len</span>(dataset_val)&#125;</span> test images: <span class="subst">&#123;test_stats[<span class="string">&#x27;acc1&#x27;</span>]:<span class="number">.1</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_acc1&quot;</span>, test_stats[<span class="string">&quot;acc1&quot;</span>], epoch)</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_acc5&quot;</span>, test_stats[<span class="string">&quot;acc5&quot;</span>], epoch)</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_loss&quot;</span>, test_stats[<span class="string">&quot;loss&quot;</span>], epoch)</span><br><span class="line">                model.train()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;training...&quot;</span>)</span><br><span class="line">            train_stats = train_one_epoch(</span><br><span class="line">                model, criterion, data_loader_train,</span><br><span class="line">                optimizer, device, epoch + <span class="number">1</span>, loss_scaler, <span class="literal">None</span>, log_writer=log_writer, args=args</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(train_stats)</span><br><span class="line">            <span class="keyword">if</span> args.output_dir:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;saving checkpoint...&quot;</span>)</span><br><span class="line">                misc.save_model(</span><br><span class="line">                    args=args,model=model,model_without_ddp=model,optimizer=optimizer,</span><br><span class="line">                    loss_scaler=loss_scaler,epoch=epoch</span><br><span class="line">                )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model = timm.create_model(<span class="string">&quot;resnet18&quot;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">36</span>, drop_rate=<span class="number">0.1</span>, drop_path_rate=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">        class_dict = &#123;<span class="string">&#x27;apple&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;banana&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;beetroot&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;bell pepper&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;cabbage&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;capsicum&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">                      <span class="string">&#x27;carrot&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;cauliflower&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;chilli pepper&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;corn&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;cucumber&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;eggplant&#x27;</span>: <span class="number">11</span>,</span><br><span class="line">                      <span class="string">&#x27;garlic&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;ginger&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;grapes&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;jalepeno&#x27;</span>: <span class="number">15</span>, <span class="string">&#x27;kiwi&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;lemon&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;lettuce&#x27;</span>: <span class="number">18</span>,</span><br><span class="line">                      <span class="string">&#x27;mango&#x27;</span>: <span class="number">19</span>, <span class="string">&#x27;onion&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;orange&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;paprika&#x27;</span>: <span class="number">22</span>, <span class="string">&#x27;pear&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;peas&#x27;</span>: <span class="number">24</span>, <span class="string">&#x27;pineapple&#x27;</span>: <span class="number">25</span>,</span><br><span class="line">                      <span class="string">&#x27;pomegranate&#x27;</span>: <span class="number">26</span>, <span class="string">&#x27;potato&#x27;</span>: <span class="number">27</span>, <span class="string">&#x27;raddish&#x27;</span>: <span class="number">28</span>, <span class="string">&#x27;soy beans&#x27;</span>: <span class="number">29</span>, <span class="string">&#x27;spinach&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;sweetcorn&#x27;</span>: <span class="number">31</span>,</span><br><span class="line">                      <span class="string">&#x27;sweetpotato&#x27;</span>: <span class="number">32</span>, <span class="string">&#x27;tomato&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;turnip&#x27;</span>: <span class="number">34</span>, <span class="string">&#x27;watermelon&#x27;</span>: <span class="number">35</span>&#125;</span><br><span class="line"></span><br><span class="line">        n_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;number of trainable params (M):%.2f&#x27;</span> % (n_parameters / <span class="number">1.e6</span>))</span><br><span class="line"></span><br><span class="line">        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)</span><br><span class="line">        os.makedirs(args.log_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        loss_scaler = NativeScaler()</span><br><span class="line"></span><br><span class="line">        misc.load_model(args=args, model_without_ddp=model, optimizer=optimizer, loss_scaler=loss_scaler)</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(test_image_path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        image = image.resize((args.input_size, args.input_size), Image.ANTIALIAS)</span><br><span class="line">        image = torchvision.transforms.ToTensor()(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            output = model(image)</span><br><span class="line"></span><br><span class="line">        output = F.softmax(output, dim=-<span class="number">1</span>)</span><br><span class="line">        class_idx = torch.argmax(output, dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">        score = torch.<span class="built_in">max</span>(output, dim=<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;image path is <span class="subst">&#123;test_image_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;score is <span class="subst">&#123;score.item()&#125;</span>, class id is <span class="subst">&#123;class_idx.item()&#125;</span>,  &quot;</span></span><br><span class="line">            <span class="string">f&quot;class name is <span class="subst">&#123;<span class="built_in">list</span>(class_dict.keys())[<span class="built_in">list</span>(class_dict.values()).index(class_idx)]&#125;</span>&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<p>分为两大部分：</p>
<ul>
<li>首先进行eval</li>
<li>然后进行训练</li>
</ul>
<h2 id="infer">8 infer</h2>
<ul>
<li>修改resume</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&#x27;--resume&#x27;, default=&#x27;./output_dir_pretrained/checkpoint-24.pth&#x27;,help=&#x27;resume from checkpoint&#x27;)</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">project</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/4627104a.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络11-GAN" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/cad0a038.html">用pytorch实现基础网络11-GAN</a>
    </h2>
  

        
		
		  <a href="/post/cad0a038.html" class="archive-article-date">
  	<time datetime="2023-04-24T11:36:29.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-24</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">2k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">8min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h1 id="generative-adversarial-nets">Generative Adversarial Nets</h1>
<p>https://arxiv.org/pdf/1406.2661.pdf</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241952572.png" alt="image-20230424195239653" /><figcaption aria-hidden="true">image-20230424195239653</figcaption>
</figure>
<p>Pearson散度和Jensen-Shannon散度都是衡量两个概率分布之间差异的方法，但它们具有不同的计算方式和特点。</p>
<ol type="1">
<li>Pearson散度（Pearson Divergence）： Pearson散度是衡量两个概率分布之间的差异的一种方法，主要基于卡方统计量（Chi-Square statistic）。对于两个概率分布P和Q，Pearson散度的计算公式如下：</li>
</ol>
<p>D_Pearson(P, Q) = Σ[(P(x) - Q(x))^2 / Q(x)]</p>
<p>其中，x表示数据空间中的元素，P(x)和Q(x)分别表示概率分布P和Q在x处的概率密度。</p>
<p>Pearson散度的值越大，表示两个概率分布之间的差异越大。需要注意的是，Pearson散度不是一种距离度量，因为它不满足三角不等式。</p>
<ol type="1">
<li>Jensen-Shannon散度（Jensen-Shannon Divergence）： Jensen-Shannon散度是一种对称的、有界的散度度量方法，用于衡量两个概率分布之间的差异。它是基于Kullback-Leibler散度（KL散度）的改进版本。对于两个概率分布P和Q，Jensen-Shannon散度的计算公式如下：</li>
</ol>
<p>D_JS(P, Q) = (1/2) * D_KL(P, M) + (1/2) * D_KL(Q, M)</p>
<p>其中，M = (1/2) * (P + Q)，D_KL(P, M)和D_KL(Q, M)分别表示P和Q相对于M的Kullback-Leibler散度。</p>
<p>Jensen-Shannon散度的值在0到1之间，值越大表示两个概率分布之间的差异越大。当两个分布完全相同时，Jensen-Shannon散度为0；当两个分布完全不相交时，Jensen-Shannon散度接近1。可以通过计算Jensen-Shannon散度的平方根得到Jensen-Shannon距离，它满足距离度量的性质。</p>
<p>总结一下，Pearson散度和Jensen-Shannon散度都是衡量两个概率分布之间差异的方法，但它们的计算方式和特点不同。Pearson散度基于卡方统计量，而Jensen-Shannon散度基于Kullback-Leibler散度。Jensen-Shannon散度是对称的、有界的，可以通过计算其平方根得到满足距离度量性质的Jensen-Shannon距离。</p>
<h1 id="code">code</h1>
<h2 id="generator">1 Generator</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.utils.data.dataloader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;基于 MNist 实现对抗生成网络(GAN)&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(latent_dim, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, np.prod(image_size)),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        output = self.model(z)</span><br><span class="line">        image = torch.reshape(output, (z.shape[<span class="number">0</span>], *image_size))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>
<h2 id="discriminator">2 Discriminator</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(np.prod(image_size), <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        prob = self.model(torch.reshape(image, (image.shape[<span class="number">0</span>], -<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> prob</span><br></pre></td></tr></table></figure>
<h2 id="training">3 training</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training</span></span><br><span class="line">image_size = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">latent_dim = <span class="number">100</span></span><br><span class="line">num_epoch = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                     transform=torchvision.transforms.Compose([</span><br><span class="line">                                         torchvision.transforms.Resize(<span class="number">28</span>),</span><br><span class="line">                                         torchvision.transforms.ToTensor(),</span><br><span class="line">                                         torchvision.transforms.Normalize(mean=[<span class="number">0.5</span>], std=[<span class="number">0.5</span>])</span><br><span class="line">                                     ]))</span><br><span class="line"></span><br><span class="line">DataLoader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator = Generator().cuda()</span><br><span class="line">discriminator = Discriminator().cuda()</span><br><span class="line"></span><br><span class="line">g_optimizer = torch.optim.Adam(params=generator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">d_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">raw = os.path.abspath(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">output_dir = os.path.join(raw, <span class="string">&quot;mnist_data/MNIST/result&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否存在预训练的权重文件</span></span><br><span class="line">generator_weights_path = os.path.join(output_dir, <span class="string">&#x27;generator.pth&#x27;</span>)</span><br><span class="line">discriminator_weights_path = os.path.join(output_dir, <span class="string">&#x27;discriminator.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(generator_weights_path) <span class="keyword">and</span> os.path.exists(discriminator_weights_path):</span><br><span class="line">    generator.load_state_dict(torch.load(generator_weights_path))</span><br><span class="line">    discriminator.load_state_dict(torch.load(discriminator_weights_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="keyword">for</span> i, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(DataLoader):</span><br><span class="line">        gt_images, _ = mini_batch</span><br><span class="line">        gt_images = gt_images.cuda()</span><br><span class="line">        z = torch.randn(batch_size, latent_dim)</span><br><span class="line">        z = z.cuda()</span><br><span class="line">        pred_images = generator(z)</span><br><span class="line">        pred_images = pred_images.cuda()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        target_ones = torch.ones(batch_size, <span class="number">1</span>)</span><br><span class="line">        target_ones = target_ones.cuda()</span><br><span class="line">        target_zeros = torch.zeros(batch_size, <span class="number">1</span>)</span><br><span class="line">        target_zeros = target_zeros.cuda()</span><br><span class="line">        g_loss = loss_fn(discriminator(pred_images), target_ones)  <span class="comment"># 生成器</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line"></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        d_loss = loss_fn(discriminator(gt_images), target_ones) + loss_fn(discriminator(pred_images.detach()), target_zeros)  <span class="comment"># 判别器</span></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            raw = os.path.abspath(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">            output_dir = os.path.join(raw, <span class="string">&quot;mnist_data/MNIST/result&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">                os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line">            torchvision.utils.save_image(pred_images, os.path.join(output_dir, <span class="string">f&quot;image_<span class="subst">&#123;epoch&#125;</span>_<span class="subst">&#123;i // <span class="number">1000</span>&#125;</span>.png&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch: <span class="subst">&#123;epoch&#125;</span>, Batch: <span class="subst">&#123;i&#125;</span>, Generator Loss: <span class="subst">&#123;g_loss.item()&#125;</span>, Discriminator Loss: <span class="subst">&#123;d_loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存模型权重</span></span><br><span class="line">    torch.save(generator.state_dict(), generator_weights_path)</span><br><span class="line">    torch.save(discriminator.state_dict(), discriminator_weights_path)</span><br></pre></td></tr></table></figure>
<h1 id="cgan">CGAN</h1>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262015876.png" alt="image-20230426201511591" /><figcaption aria-hidden="true">image-20230426201511591</figcaption>
</figure>
<p>CGAN（条件生成对抗网络，Conditional GAN）是在GAN的基础上引入条件信息的一种变体。与普通GAN相比，CGAN的生成器和判别器都接收额外的条件信息（如类别标签、文本描述等），并根据这些条件信息生成特定类别的数据。这使得CGAN能够有更好的控制生成数据的特征。</p>
<p>CGAN的特点如下：</p>
<ol type="1">
<li>控制生成数据特征：CGAN可以根据输入的条件信息，生成具有特定特征的数据。这使得CGAN在生成数据时具有更高的可控性。</li>
<li>引入条件信息：CGAN的生成器和判别器都接收额外的条件信息，使得网络可以在训练过程中学习如何利用这些条件信息来生成和识别数据。</li>
<li>更好的生成性能：由于条件信息的引入，CGAN可以在生成数据时更好地捕捉数据的特征和结构，从而提高生成数据的质量。</li>
</ol>
<p>总之，与普通GAN相比，CGAN通过引入条件信息，实现了对生成数据特征的控制，使得生成数据更具有可控性和更高的质量。在很多应用场景中，如图像生成、文本生成等，CGAN已经表现出很好的性能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,latent_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>,label_emb_dim)</span><br><span class="line">       ...</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z,labels</span>):</span><br><span class="line">        <span class="comment"># shape of z: [batchsize,latent_dim]</span></span><br><span class="line">        label_embedding = self.embedding(labels)</span><br><span class="line">        z = torch.cat([z,label_embedding], axis=-<span class="number">1</span>)</span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>,label_emb_dim)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image,labels</span>):</span><br><span class="line">        <span class="comment"># shape of image [batchsize,1,28,28]</span></span><br><span class="line">        label_embedding = self.embedding(labels)</span><br><span class="line">        prob = self.model(torch.cat([torch.reshape(image, (image.shape[<span class="number">0</span>], -<span class="number">1</span>)),label_embedding],axis=-<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> prob</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练过程中需要对generator和discriminator的调用中引入参数label</span></span><br><span class="line">gt_images, labels = mini_batch</span><br></pre></td></tr></table></figure>
<h1 id="least-squares-gan">least-squares-GAN</h1>
<p>Least Squares Generative Adversarial Networks（LSGAN）是一种生成对抗网络（GAN）的变体，它主要针对传统GAN在训练过程中容易出现的不稳定性和梯度消失问题进行了改进。LSGAN的核心思想是将判别器（Discriminator）的损失函数从交叉熵损失（Cross-Entropy Loss）替换为最小二乘损失（Least Squares Loss），从而提高训练的稳定性和生成数据的质量。</p>
<p>LSGAN的主要特点如下：</p>
<ol type="1">
<li>稳定性：与传统GAN相比，LSGAN在训练过程中表现出更高的稳定性。这主要归功于最小二乘损失函数的平滑性，它能够减少梯度消失问题的发生，使得生成器（Generator）和判别器（Discriminator）在训练过程中保持更好的平衡。</li>
<li>生成质量：LSGAN生成的数据质量通常优于传统GAN。最小二乘损失有助于判别器更好地区分真实数据和生成数据，从而为生成器提供更有效的梯度指导，使得生成器能够生成更高质量的数据。</li>
<li>更低的梯度消失风险：在传统GAN中，由于交叉熵损失在判别器接近最优时可能导致梯度消失问题，这使得生成器的训练变得困难。然而，在LSGAN中，最小二乘损失能够减轻梯度消失问题，使得生成器在整个训练过程中都能够收到有效的梯度信息。</li>
<li>容易实现：LSGAN的实现非常简单，只需将传统GAN的损失函数替换为最小二乘损失即可。这意味着在现有的GAN架构中，很容易将其升级为LSGAN。</li>
</ol>
<p>总之，LSGAN通过使用最小二乘损失改进了传统GAN的训练稳定性和生成数据质量。这使得LSGAN在各种生成任务中，如图像生成、文本生成等，都能取得更好的性能。</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262051780.png" alt="image-20230426205146063" /><figcaption aria-hidden="true">image-20230426205146063</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">logits = torch.linspace(-<span class="number">10</span>,<span class="number">10</span>,<span class="number">2000</span>)</span><br><span class="line">loss = []</span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"><span class="keyword">for</span> lgs <span class="keyword">in</span> logits:</span><br><span class="line">    loss.append(loss_fn(torch.sigmoid(lgs),torch.ones_like(lgs)))</span><br><span class="line"></span><br><span class="line">plt.plot(logits,loss)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262107840.png" alt="image-20230426210738626" /><figcaption aria-hidden="true">image-20230426210738626</figcaption>
</figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/cad0a038.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch基础入门12-位置编码" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/f94e9029.html">pytorch基础入门12-位置编码</a>
    </h2>
  

        
		
		  <a href="/post/f94e9029.html" class="archive-article-date">
  	<time datetime="2023-04-24T08:26:35.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-24</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">308字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">1min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241635006.png" alt="image-20230424163501351" /><figcaption aria-hidden="true">image-20230424163501351</figcaption>
</figure>
<h1 id="transformer">1 transformer</h1>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241637416.png" alt="image-20230424163709530" /><figcaption aria-hidden="true">image-20230424163709530</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.1d absolute sincos constant embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_1d_absolute_sincos_embeddings</span>(<span class="params">n_pos_vec,dim</span>):</span><br><span class="line">    <span class="comment"># pos_vec: torch.arrange(n_pos)</span></span><br><span class="line">    <span class="keyword">assert</span> dim % <span class="number">2</span> ==<span class="number">0</span>,<span class="string">&quot;wrong dimension&quot;</span></span><br><span class="line">    position_embedding = torch.zeros(n_pos_vec.numel(),dim,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    omega = torch.arange(dim//<span class="number">2</span>,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    omega /= dim / <span class="number">2.</span></span><br><span class="line">    omega = <span class="number">1.</span> / (<span class="number">10000</span> ** omega)</span><br><span class="line"></span><br><span class="line">    out = n_pos_vec[:,<span class="literal">None</span>] @ omega[<span class="literal">None</span>,:] <span class="comment"># [n_pos_vec,1]*[1,dim//2]</span></span><br><span class="line"></span><br><span class="line">    emb_sin = torch.sin(out)</span><br><span class="line">    emb_cos = torch.cos(out)</span><br><span class="line"></span><br><span class="line">    position_embedding[:,<span class="number">0</span>::<span class="number">2</span>] = emb_sin</span><br><span class="line">    position_embedding[:,<span class="number">1</span>::<span class="number">2</span>] = emb_cos</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>  position_embedding</span><br></pre></td></tr></table></figure>
<h1 id="swin-transformer">2 Swin transformer</h1>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241914252.png" alt="image-20230424191316681" /><figcaption aria-hidden="true">image-20230424191316681</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.2d relative bias trainable embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_2d_relative_bias_trainable_embeddings</span>(<span class="params">n_head,height,width</span>):</span><br><span class="line">    <span class="comment"># width:5   bias=[-width+1, width-1]  2*width-1</span></span><br><span class="line">    <span class="comment"># height:5                            2*height-1</span></span><br><span class="line">    position_embedding = nn.Embedding((<span class="number">2</span>*width-<span class="number">1</span>)*(<span class="number">2</span>*height-<span class="number">1</span>),n_head)</span><br><span class="line">    nn.init.constant_(position_embedding,<span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_relative_position_index</span>(<span class="params">height,width</span>):</span><br><span class="line">        cords = torch.stack(torch.meshgrid(torch.arange(height),torch.arange(width))) <span class="comment">#[2,height,width]</span></span><br><span class="line">        cords_flatten = torch.flatten(cords,<span class="number">1</span>) <span class="comment"># [2,height*width]</span></span><br><span class="line">        relative_cords_bias = cords_flatten[:,:,<span class="literal">None</span>] - cords_flatten[:,<span class="literal">None</span>,:] <span class="comment">#[2,height*width,height*width]</span></span><br><span class="line"></span><br><span class="line">        relative_cords_bias[<span class="number">0</span>,:,:] += height - <span class="number">1</span></span><br><span class="line">        relative_cords_bias[<span class="number">1</span>,:,:] += width - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># A:2d,B:1d B[i*cols+j] = a[i,j]</span></span><br><span class="line"></span><br><span class="line">        relative_cords_bias[<span class="number">0</span>,:,:] *= relative_cords_bias[<span class="number">1</span>,:,:].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  relative_cords_bias.<span class="built_in">sum</span>(<span class="number">0</span>) <span class="comment"># [height*width,height*width]</span></span><br><span class="line">    relative_position_bias = get_relative_position_index(height,width)</span><br><span class="line">    bias_embedding = position_embedding(torch.flatten(relative_position_bias)).reshape(height*width,height*width,n_head) <span class="comment"># [height*width,height*width,n_head]</span></span><br><span class="line"></span><br><span class="line">    bias_embedding.permute(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>).unsqueeze(<span class="number">0</span>) <span class="comment"># [1,n_head,height*width,height*width]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bias_embedding</span><br></pre></td></tr></table></figure>
<h1 id="masked-ae">3 Masked AE</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.2d absolute constant sincos embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_2d_absolute_sincos_embeddings</span>(<span class="params">height,width,dim</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> dim % <span class="number">4</span> == <span class="number">0</span>, <span class="string">&quot;wrong dimension&quot;</span></span><br><span class="line">    position_embedding = torch.zeros(height*width,dim)</span><br><span class="line">    cords = torch.stack(torch.meshgrid(torch.arange(height,dtype=torch.<span class="built_in">float</span>), torch.arange(width,dtype=torch.<span class="built_in">float</span>)))  <span class="comment"># [2,height,width]</span></span><br><span class="line">    height_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(cords[<span class="number">0</span>]),dim//<span class="number">2</span>) <span class="comment"># [height*width,dim//2]</span></span><br><span class="line">    width_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(cords[<span class="number">1</span>]),dim//<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    position_embedding[:,:dim//<span class="number">2</span>] = height_embedding</span><br><span class="line">    position_embedding[:,dim//<span class="number">2</span>:] = width_embedding</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> position_embedding</span><br></pre></td></tr></table></figure>
<h1 id="section"></h1>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/f94e9029.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch基础入门11-Normalization" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/87a49949.html">pytorch基础入门11-Normalization</a>
    </h2>
  

        
		
		  <a href="/post/87a49949.html" class="archive-article-date">
  	<time datetime="2023-04-20T10:24:36.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-20</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">1.2k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">5min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h1 id="layer-normalization">Layer Normalization</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.06450.pdf">1607.06450.pdf (arxiv.org)</a></p>
<p>这篇文章讨论了一种称为层归一化（Layer Normalization）的方法，用于稳定神经网络的训练过程，并减少训练时间。层归一化的核心思想是通过对单个训练样本的神经元输入求和来计算归一化所需的均值和方差。这与之前的批量归一化（Batch Normalization）方法不同，后者依赖于一个 mini-batch 中所有样本的输入分布。</p>
<p>以下是该论文的主要观点：</p>
<ol type="1">
<li>层归一化将批量归一化的概念从 mini-batch 级别扩展到层级别，计算用于归一化的均值和方差来自单个训练样本中的所有神经元输入求和。</li>
<li>与批量归一化类似，层归一化也为每个神经元提供自适应的偏置和增益，这些参数在归一化之后但在非线性激活函数之前应用。</li>
<li>与批量归一化不同，层归一化在训练和测试阶段执行相同的计算，因此不依赖于 mini-batch 大小。</li>
<li>层归一化很容易应用于循环神经网络（RNN），因为可以在每个时间步骤单独计算归一化统计数据。</li>
<li>层归一化在稳定循环神经网络的隐藏状态动态方面非常有效。</li>
<li>实证研究表明，与以前发布的技术相比，层归一化可以显著减少训练时间。</li>
</ol>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202124984.png" alt="image-20230420212422293" /><figcaption aria-hidden="true">image-20230420212422293</figcaption>
</figure>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202123289.png" alt="image-20230420212333495" /><figcaption aria-hidden="true">image-20230420212333495</figcaption>
</figure>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202229447.png" alt="image-20230420222926884" /><figcaption aria-hidden="true">image-20230420222926884</figcaption>
</figure>
<h1 id="五种归一化的代码实现">五种归一化的代码实现</h1>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202236940.png" alt="image-20230420223608053" /><figcaption aria-hidden="true">image-20230420223608053</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 首先定义一些常量</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">time_steps = <span class="number">3</span></span><br><span class="line">embedding_dim = <span class="number">4</span></span><br><span class="line">input_x = torch.randn(batch_size,time_steps,embedding_dim)</span><br></pre></td></tr></table></figure>
<h2 id="batch-normalization">1 batch normalization</h2>
<p>torch.nn.BatchNorm1d(<em>num_features</em>, <em>eps=1e-05</em>, <em>momentum=0.1</em>, <em>affine=True</em>, <em>track_running_stats=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<p>https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm1d</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202240276.png" alt="parameter and shape" /><figcaption aria-hidden="true">parameter and shape</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 官方API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [C]</span></span><br><span class="line"><span class="comment"># cv: [N,C,H,W] -&gt; [C]</span></span><br><span class="line">batch_norm_op = nn.BatchNorm1d(embedding_dim,affine=<span class="literal">False</span>)</span><br><span class="line">bn_y = batch_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(bn_y)</span><br><span class="line"><span class="comment"># 手写batch_norm</span></span><br><span class="line">bn_mean = input_x.mean(dim=(<span class="number">0</span>,<span class="number">1</span>)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).repeat(batch_size,time_steps,<span class="number">1</span>)</span><br><span class="line">bn_std = input_x.std(dim=(<span class="number">0</span>,<span class="number">1</span>),unbiased=<span class="literal">False</span>).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).repeat(batch_size,time_steps,<span class="number">1</span>)</span><br><span class="line">verify_bn_y = (input_x-bn_mean)/(bn_std + <span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_bn_y)</span><br></pre></td></tr></table></figure>
<h2 id="layer-normalization-1">2 layer normalization</h2>
<p>torch.nn.LayerNorm(<em>normalized_shape</em>, <em>eps=1e-05</em>, <em>elementwise_affine=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html?highlight=layer+norm#torch.nn.LayerNorm</p>
<ul>
<li>需要保证batchsize是第一个维度，剩下的维度中有embedding_dim即可</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现layer_norm并验证API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [N,L]</span></span><br><span class="line"><span class="comment"># Cv: [N,C,H,W] -&gt; [N,H,W]</span></span><br><span class="line">layer_norm_op = nn.LayerNorm(embedding_dim,elementwise_affine=<span class="literal">False</span>)</span><br><span class="line">ln_y = layer_norm_op(input_x)</span><br><span class="line"><span class="built_in">print</span>(ln_y)</span><br><span class="line"><span class="comment"># shouxie  layer_norm</span></span><br><span class="line">ln_mean = input_x.mean(dim=-<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">ln_std = input_x.std(dim=-<span class="number">1</span>,keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">verify_ln_y = (input_x-ln_mean)/(ln_std + <span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_ln_y)</span><br></pre></td></tr></table></figure>
<h2 id="instance-normalization">3 Instance Normalization</h2>
<ul>
<li>一般用于风格迁移中</li>
</ul>
<p>https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html?highlight=instance#torch.nn.InstanceNorm1d</p>
<p>torch.nn.InstanceNorm1d(<em>num_features</em>, <em>eps=1e-05</em>, <em>momentum=0.1</em>, <em>affine=False</em>, <em>track_running_stats=False</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用instance norm API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [N,C]</span></span><br><span class="line"><span class="comment"># Cv: [N,C,H,W] -&gt; [N,C]</span></span><br><span class="line">ins_norm_op = nn.InstanceNorm1d(embedding_dim)</span><br><span class="line">in_y = ins_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(in_y)</span><br><span class="line"><span class="comment"># 手写ins_norm</span></span><br><span class="line">in_mean = input_x.mean(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">in_std = input_x.std(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">verify_ins_y = (input_x-in_mean)/(in_std+<span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_ins_y)</span><br></pre></td></tr></table></figure>
<ul>
<li>因为在同一个mini-batch中，如果在序列上对其加权平均，最后得到的也就是序列中的风格信息。</li>
</ul>
<h2 id="group-normalization">4 group normalization</h2>
<p>与layer norm比较相同</p>
<p>torch.nn.GroupNorm(<em>num_groups</em>, <em>num_channels</em>, <em>eps=1e-05</em>, <em>affine=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html?highlight=group+norm#torch.nn.GroupNorm</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用group norm API</span></span><br><span class="line"><span class="comment"># nlp: [N,G,L,C/G] -&gt; [N,G]</span></span><br><span class="line"><span class="comment"># Cv: [N,G,C/G,H,W] -&gt; [N,G]</span></span><br><span class="line">group_norm_op = nn.GroupNorm(num_group,embedding_dim,affine=<span class="literal">False</span>)</span><br><span class="line">gn_y = group_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(gn_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写 group norm</span></span><br><span class="line">group_input_x = torch.split(input_x,split_size_or_sections=embedding_dim//num_group,dim=-<span class="number">1</span>)</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> g_inputx <span class="keyword">in</span> group_input_x:</span><br><span class="line">    gn_mean = g_inputx.mean(dim=(<span class="number">1</span>,<span class="number">2</span>),keepdim=<span class="literal">True</span>)</span><br><span class="line">    gn_std = g_inputx.std(dim=(<span class="number">1</span>,<span class="number">2</span>),keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">    gn_result = (g_inputx-gn_mean)/(gn_std+<span class="number">1e-5</span>)</span><br><span class="line">    results.append(gn_result)</span><br><span class="line">verify_gn_y = torch.cat(results,dim=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_gn_y)</span><br></pre></td></tr></table></figure>
<h2 id="weight-normalization">5 Weight Normalization</h2>
<p>torch.nn.utils.weight_norm(<em>module</em>, <em>name='weight'</em>, <em>dim=0</em>) https://pytorch.org/docs/stable/_modules/torch/nn/utils/weight_norm.html#weight_norm <span class="math display">\[
w = g\frac{v}{||v||}
\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现weight_norm并验证API</span></span><br><span class="line">linear = nn.Linear(embedding_dim,<span class="number">3</span>,bias=<span class="literal">False</span>) <span class="comment"># without weight norm</span></span><br><span class="line">wn_linear = torch.nn.utils.weight_norm(linear)</span><br><span class="line">wn_linear_output = wn_linear(input_x)</span><br><span class="line"><span class="built_in">print</span>(wn_linear_output)</span><br><span class="line"><span class="keyword">for</span> i,k <span class="keyword">in</span> <span class="built_in">enumerate</span>(wn_linear.named_parameters()):</span><br><span class="line">    <span class="built_in">print</span>(i,k)</span><br><span class="line"><span class="comment"># 手写实现 weight norm</span></span><br><span class="line">weight_direction = linear.weight/(linear.weight.norm(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>))</span><br><span class="line">weight_magnitude = wn_linear.weight_g</span><br><span class="line">verify_wn_linear_output = input_x @ (weight_direction.transpose(-<span class="number">1</span>,-<span class="number">2</span>) * weight_magnitude.transpose(-<span class="number">1</span>,-<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(verify_wn_linear_output)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">feat_dim = <span class="number">3</span></span><br><span class="line">hid_dim = <span class="number">4</span></span><br><span class="line">inputx = torch.randn(batch_size, feat_dim)</span><br><span class="line">linear = nn.Linear(feat_dim, hid_dim, bias=<span class="literal">False</span>)</span><br><span class="line">wn_linear = torch.nn.utils.weight_norm(linear)</span><br><span class="line"></span><br><span class="line">weight_magnitude = torch.tensor([linear.weight[i, :].norm() <span class="keyword">for</span> i <span class="keyword">in</span> torch.arange(linear.weight.shape[<span class="number">0</span>])],</span><br><span class="line">                                dtype=torch.float32).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">weight_direction = linear.weight / weight_magnitude</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.weight:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(linear.weight)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.magnitude:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_magnitude)  <span class="comment"># 幅度向量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.direction:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_direction)  <span class="comment"># 单位向量，表示方向</span></span><br><span class="line"><span class="built_in">print</span>((weight_direction ** <span class="number">2</span>).<span class="built_in">sum</span>(dim=-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weight_direction*weight_magnitude:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_direction * weight_magnitude)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;inputx @ (weight_direction * weight_magnitude).T:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(inputx @ (weight_direction * weight_magnitude).T)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear(inputx):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(linear(inputx))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;wn_linear(inputx:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wn_linear(inputx))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;parameters of wn_linear:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> wn_linear.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(n, p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;construct weight of linear:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wn_linear.weight_g * (wn_linear.weight_v / torch.tensor(</span><br><span class="line">    [wn_linear.weight_v[i, :].norm() <span class="keyword">for</span> i <span class="keyword">in</span> torch.arange(wn_linear.weight_v.shape[<span class="number">0</span>])],dtype=torch.float32).unsqueeze(-<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/87a49949.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络10-MAE" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/f0f056f4.html">用pytorch实现基础网络10-MAE</a>
    </h2>
  

        
		
		  <a href="/post/f0f056f4.html" class="archive-article-date">
  	<time datetime="2023-04-19T13:21:04.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-19</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">5k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">25min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h1 id="masked-autoencoders-are-scalable-vision-learners">Masked Autoencoders Are Scalable Vision Learners</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2111.06377.pdf">2111.06377.pdf (arxiv.org)</a></p>
<p>本文表明，掩蔽自编码器（MAE）是计算机视觉领域可扩展的自监督学习方法。我们的 MAE 方法很简单：我们随机遮盖输入图像的一部分区域，并重建丢失的像素。该方法基于两个核心设计。首先，我们开发了一种非对称的编码器-解码器架构，其中编码器仅对可见子图像区域（没有遮盖标记）进行操作，而轻量级的解码器则从潜在表示和遮盖标记中重建原始图像。其次，我们发现遮盖输入图像较大比例（例如 75%）会产生一个具有意义且难度适中的自监督任务。将这两个设计结合起来，使我们能够高效、有效地训练大型模型：我们加速训练（至少提高 3 倍）并提高准确性。我们的可扩展方法允许学习高容量模型以实现更好的泛化：例如，一个普通的 ViT-Huge 模型在仅使用 ImageNet-1K 数据的方法中达到了最高准确率（87.8%）。在下游任务中，迁移性能超过了有监督预训练，并展示出有希望的扩展行为。</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304192127666.png" alt="image-20230419212658615" /><figcaption aria-hidden="true">image-20230419212658615</figcaption>
</figure>
<p>image-&gt;patch-&gt;random mask-&gt;shuffle the patch-&gt;encoder-&gt;combine the whole embedding-&gt;unshuffle to align all tokens with target-&gt;decoder</p>
<p>自编码器是一种可以重构原始信号的方法，它有一个编码器，将观察到的信号映射到潜在表示，以及一个解码器，从潜在表示和掩码标记中重构原始信号。与传统的自编码器不同，我们采用了一种不对称的设计，允许编码器仅对部分观察到的信号（不带掩码标记）进行操作，并使用轻量级解码器从潜在表示和掩码标记中重构完整信号。</p>
<h2 id="mask">mask</h2>
<p>其中对于掩码的部分，并不是空向量，而是一个可以学习的向量，可以用过对其学习而恢复完整信号。因为图片中存在大量的冗余信息，所以这个掩码比例通常很高，比如75%</p>
<p>作者将图像分成规则的非重叠块，然后对其进行采样并遮蔽剩余的块。他们的采样策略很简单：随机采样块，不重复，遵循均匀分布。高遮蔽比率的随机采样大大减少了冗余，从而创造了一个不能通过可见邻近块外推来轻松解决的任务。均匀分布防止了潜在的中心偏差（即图像中心附近有更多的遮蔽块）。最后，高度稀疏的输入为设计高效编码器提供了机会。</p>
<p>重要的是，不需要任何<strong>专门的稀疏操作</strong>。首先，我们为每个输入图像块生成一个标记（通过线性投影并添加<strong>位置嵌入</strong>）。接下来，我们随机打乱标记列表，并根据遮盖比例删除列表的最后一部分。这个过程为<strong>编码器产生了一个小的标记子集</strong>，相当于在不重复采样的情况下采样图像块。编码后，我们将一列遮盖标记添加到编码后的图像块列表中，并对整个列表进行反打乱操作（反转随机打乱操作）以使所有标记与其目标对齐。解码器应用于这个完整列表（添加位置嵌入）。如前所述，不需要稀疏操作。这种简单的实现引入的开销可忽略不计，因为洗牌和反洗牌操作很快。</p>
<h2 id="encoder">encoder</h2>
<p>这个编码器类似ViT的结构，但仅应用于可见的、未遮盖的图像块。与标准的 ViT 一样，我们的编码器通过线性投影和添加位置嵌入对图像块进行嵌入，然后通过一系列 Transformer 模块处理生成的集合。然而，我们的编码器仅在完整集合的一小部分（例如，25%）上进行操作。遮盖的图像块被移除；不使用遮盖标记。这使我们能够仅用一部分计算和内存资源训练非常大的编码器。</p>
<h2 id="decoder">decoder</h2>
<p>MAE解码器的输入是完整的标记集合，包括：（i）编码后的可见图像块，以及（ii）遮盖标记。每个遮盖标记是一个共享的、可学习的向量，表示需要预测的缺失图像块的存在。我们为完整集合中的所有标记添加位置嵌入；如果没有这个，遮盖标记将无法获取关于它们在图像中的位置的信息。</p>
<p>MAE 解码器仅在预训练阶段(回归任务)用于执行图像重建任务（只有编码器用于生成图像表示以进行识别）。因此，解码器架构可以灵活地设计，其设计方式独立于编码器设计。我们尝试使用非常小的解码器，比编码器更窄、更浅。例如，我们默认的解码器每个标记的计算量不到编码器的10%。借助这种非对称设计，完整的标记集合仅由轻量级解码器处理，从而大幅减少预训练时间。</p>
<ul>
<li>解码器的目标是完成这个自回归任务，是为了更好的获得存在掩码的编码器，通过编码器才能完成cv的常见任务。</li>
<li>解码器输出中的每个元素都是代表一个图像块的像素值向量。解码器的最后一层是线性投影，其输出通道数量等于图像块中的像素值数量</li>
<li>损失函数计算像素空间中重建图像与原始图像之间的均方误差(MSE),仅在遮盖的图像块上计算损失</li>
</ul>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304192302724.png" alt="image-20230419230225444" /><figcaption aria-hidden="true">image-20230419230225444</figcaption>
</figure>
<h1 id="code">code</h1>
<p>https://github.com/facebookresearch/mae</p>
<h2 id="models_mae">1 models_mae</h2>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201412692.png" alt="image-20230420141204420" /><figcaption aria-hidden="true">image-20230420141204420</figcaption>
</figure>
<h3 id="模型搭建">1.1 模型搭建</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MaskedAutoencoderViT</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Masked Autoencoder with VisionTransformer backbone</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">1024</span>, depth=<span class="number">24</span>, num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, norm_layer=nn.LayerNorm, norm_pix_loss=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE encoder specifics</span></span><br><span class="line">        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)</span><br><span class="line">        num_patches = self.patch_embed.num_patches</span><br><span class="line"></span><br><span class="line">        self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))</span><br><span class="line">        self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line"></span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line">        self.norm = norm_layer(embed_dim)</span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE decoder specifics</span></span><br><span class="line">        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.mask_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, decoder_embed_dim))</span><br><span class="line"></span><br><span class="line">        self.decoder_pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, decoder_embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line"></span><br><span class="line">        self.decoder_blocks = nn.ModuleList([</span><br><span class="line">            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(decoder_depth)])</span><br><span class="line"></span><br><span class="line">        self.decoder_norm = norm_layer(decoder_embed_dim)</span><br><span class="line">        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**<span class="number">2</span> * in_chans, bias=<span class="literal">True</span>) <span class="comment"># decoder to patch</span></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        self.norm_pix_loss = norm_pix_loss</span><br><span class="line"></span><br><span class="line">        self.initialize_weights()</span><br></pre></td></tr></table></figure>
<h3 id="embedding的构造">1.2 embedding的构造</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span>, flatten=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])</span><br><span class="line">        self.num_patches = self.grid_size[<span class="number">0</span>] * self.grid_size[<span class="number">1</span>]</span><br><span class="line">        self.flatten = flatten</span><br><span class="line"></span><br><span class="line">        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">assert</span> H == self.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == self.img_size[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        <span class="keyword">if</span> self.flatten:</span><br><span class="line">            x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># BCHW -&gt; BNC</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="初始化参数">1.3 初始化参数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># initialization</span></span><br><span class="line">    <span class="comment"># initialize (and freeze) pos_embed by sin-cos embedding</span></span><br><span class="line">    pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-<span class="number">1</span>], <span class="built_in">int</span>(self.patch_embed.num_patches**<span class="number">.5</span>), cls_token=<span class="literal">True</span>)</span><br><span class="line">    self.pos_embed.data.copy_(torch.from_numpy(pos_embed).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    decoder_pos_embed = get_2d_sincos_pos_embed(self.decoder_pos_embed.shape[-<span class="number">1</span>], <span class="built_in">int</span>(self.patch_embed.num_patches**<span class="number">.5</span>), cls_token=<span class="literal">True</span>)</span><br><span class="line">    self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize patch_embed like nn.Linear (instead of nn.Conv2d)</span></span><br><span class="line">    w = self.patch_embed.proj.weight.data</span><br><span class="line">    torch.nn.init.xavier_uniform_(w.view([w.shape[<span class="number">0</span>], -<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># timm&#x27;s trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)</span></span><br><span class="line">    torch.nn.init.normal_(self.cls_token, std=<span class="number">.02</span>)</span><br><span class="line">    torch.nn.init.normal_(self.mask_token, std=<span class="number">.02</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize nn.Linear and nn.LayerNorm</span></span><br><span class="line">    self.apply(self._init_weights)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">        <span class="comment"># we use xavier_uniform following official JAX ViT:</span></span><br><span class="line">        torch.nn.init.xavier_uniform_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">        nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>copy?</li>
</ul>
<p><code>pos_embed</code> 是一个位置嵌入矩阵，用于捕捉序列中元素的相对或绝对位置信息。在 Transformer 网络中，位置嵌入用于将位置信息与输入嵌入相结合，从而帮助模型处理输入序列。</p>
<p><code>get_2d_sincos_pos_embed</code> 函数生成了一个基于正弦和余弦函数的二维位置嵌入矩阵。在这种情况下，<code>pos_embed</code> 是一个预先初始化的 PyTorch 张量，而 <code>get_2d_sincos_pos_embed</code> 返回的是一个 NumPy 数组。</p>
<p><code>copy_()</code> 函数的目的是将 NumPy 数组的值复制到预先分配的 PyTorch 张量中。直接将值赋给 <code>pos_embed</code> 变量会导致以下问题：</p>
<ol type="1">
<li><p>数据类型不匹配：<code>get_2d_sincos_pos_embed</code> 返回的 NumPy 数组可能具有与 PyTorch 张量不同的数据类型。使用 <code>copy_()</code> 函数可以确保在复制过程中自动执行必要的类型转换。在这里，<code>.float().unsqueeze(0)</code> 用于将 NumPy 数组转换为 PyTorch 张量，并确保其具有正确的维度和数据类型。</p></li>
<li><p>张量的引用问题：直接将值赋给 <code>pos_embed</code> 变量可能会更改原始张量的引用，这可能会导致意外的行为。<code>copy_()</code> 函数确保只有张量的值被修改，而不更改其引用。这对于在模型中保持预期的参数更新行为很重要。</p></li>
</ol>
<p>综上所述，使用 <code>copy_()</code> 函数将位置嵌入矩阵的值复制到预先分配的 PyTorch 张量中，可以确保正确处理数据类型转换，并在保持张量引用不变的情况下更新张量的值。</p>
<h3 id="patch-and-unpatch">1.4 patch and unpatch</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">patchify</span>(<span class="params">self, imgs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    imgs: (N, 3, H, W)</span></span><br><span class="line"><span class="string">    x: (N, L, patch_size**2 *3)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    p = self.patch_embed.patch_size[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> imgs.shape[<span class="number">2</span>] == imgs.shape[<span class="number">3</span>] <span class="keyword">and</span> imgs.shape[<span class="number">2</span>] % p == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    h = w = imgs.shape[<span class="number">2</span>] // p</span><br><span class="line">    x = imgs.reshape(shape=(imgs.shape[<span class="number">0</span>], <span class="number">3</span>, h, p, w, p))</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nchpwq-&gt;nhwpqc&#x27;</span>, x)</span><br><span class="line">    x = x.reshape(shape=(imgs.shape[<span class="number">0</span>], h * w, p**<span class="number">2</span> * <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unpatchify</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x: (N, L, patch_size**2 *3)</span></span><br><span class="line"><span class="string">    imgs: (N, 3, H, W)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    p = self.patch_embed.patch_size[<span class="number">0</span>]</span><br><span class="line">    h = w = <span class="built_in">int</span>(x.shape[<span class="number">1</span>]**<span class="number">.5</span>)</span><br><span class="line">    <span class="keyword">assert</span> h * w == x.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    x = x.reshape(shape=(x.shape[<span class="number">0</span>], h, w, p, p, <span class="number">3</span>))</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nhwpqc-&gt;nchpwq&#x27;</span>, x)</span><br><span class="line">    imgs = x.reshape(shape=(x.shape[<span class="number">0</span>], <span class="number">3</span>, h * p, h * p))</span><br><span class="line">    <span class="keyword">return</span> imgs</span><br></pre></td></tr></table></figure>
<h3 id="掩码构建">1.5 掩码构建</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_masking</span>(<span class="params">self, x, mask_ratio</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Perform per-sample random masking by per-sample shuffling.</span></span><br><span class="line"><span class="string">    Per-sample shuffling is done by argsort random noise.</span></span><br><span class="line"><span class="string">    x: [N, L, D], sequence</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N, L, D = x.shape  <span class="comment"># batch, length, dim</span></span><br><span class="line">    len_keep = <span class="built_in">int</span>(L * (<span class="number">1</span> - mask_ratio))</span><br><span class="line">    </span><br><span class="line">    noise = torch.rand(N, L, device=x.device)  <span class="comment"># noise in [0, 1]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># sort noise for each sample</span></span><br><span class="line">    ids_shuffle = torch.argsort(noise, dim=<span class="number">1</span>)  <span class="comment"># ascend: small is keep, large is remove</span></span><br><span class="line">    ids_restore = torch.argsort(ids_shuffle, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># keep the first subset</span></span><br><span class="line">    ids_keep = ids_shuffle[:, :len_keep]</span><br><span class="line">    x_masked = torch.gather(x, dim=<span class="number">1</span>, index=ids_keep.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, D))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate the binary mask: 0 is keep, 1 is remove</span></span><br><span class="line">    mask = torch.ones([N, L], device=x.device)</span><br><span class="line">    mask[:, :len_keep] = <span class="number">0</span></span><br><span class="line">    <span class="comment"># unshuffle to get the binary mask</span></span><br><span class="line">    mask = torch.gather(mask, dim=<span class="number">1</span>, index=ids_restore)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_masked, mask, ids_restore</span><br></pre></td></tr></table></figure>
<h3 id="encoder-forward">1.6 encoder forward</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_encoder</span>(<span class="params">self, x, mask_ratio</span>):</span><br><span class="line">    <span class="comment"># embed patches</span></span><br><span class="line">    x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add pos embed w/o cls token</span></span><br><span class="line">    x = x + self.pos_embed[:, <span class="number">1</span>:, :]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># masking: length -&gt; length * mask_ratio</span></span><br><span class="line">    x, mask, ids_restore = self.random_masking(x, mask_ratio)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># append cls token</span></span><br><span class="line">    cls_token = self.cls_token + self.pos_embed[:, :<span class="number">1</span>, :]  <span class="comment"># 第0个位置</span></span><br><span class="line">    cls_tokens = cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply Transformer blocks</span></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line">    x = self.norm(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x, mask, ids_restore</span><br></pre></td></tr></table></figure>
<h3 id="decoder-forward">1.7 decoder forward</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_decoder</span>(<span class="params">self, x, ids_restore</span>):</span><br><span class="line">    <span class="comment"># embed tokens</span></span><br><span class="line">    x = self.decoder_embed(x) <span class="comment"># 降维</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># append mask tokens to sequence</span></span><br><span class="line">    mask_tokens = self.mask_token.repeat(x.shape[<span class="number">0</span>], ids_restore.shape[<span class="number">1</span>] + <span class="number">1</span> - x.shape[<span class="number">1</span>], <span class="number">1</span>) <span class="comment"># repeat in batchsize</span></span><br><span class="line">    x_ = torch.cat([x[:, <span class="number">1</span>:, :], mask_tokens], dim=<span class="number">1</span>)  <span class="comment"># no cls token</span></span><br><span class="line">    x_ = torch.gather(x_, dim=<span class="number">1</span>, index=ids_restore.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, x.shape[<span class="number">2</span>]))  <span class="comment"># unshuffle</span></span><br><span class="line">    x = torch.cat([x[:, :<span class="number">1</span>, :], x_], dim=<span class="number">1</span>)  <span class="comment"># append cls token</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add pos embed</span></span><br><span class="line">    x = x + self.decoder_pos_embed</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply Transformer blocks</span></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.decoder_blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line">    x = self.decoder_norm(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predictor projection</span></span><br><span class="line">    x = self.decoder_pred(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove cls token</span></span><br><span class="line">    x = x[:, <span class="number">1</span>:, :]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="loss-forward">1.8 loss forward</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_loss</span>(<span class="params">self, imgs, pred, mask</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    imgs: [N, 3, H, W]</span></span><br><span class="line"><span class="string">    pred: [N, L, p*p*3]</span></span><br><span class="line"><span class="string">    mask: [N, L], 0 is keep, 1 is remove, </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    target = self.patchify(imgs)  <span class="comment"># N, L, patch_size**2 *3</span></span><br><span class="line">    <span class="keyword">if</span> self.norm_pix_loss:</span><br><span class="line">        mean = target.mean(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        var = target.var(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        target = (target - mean) / (var + <span class="number">1.e-6</span>)**<span class="number">.5</span> <span class="comment"># 防止方差为0</span></span><br><span class="line"></span><br><span class="line">    loss = (pred - target) ** <span class="number">2</span></span><br><span class="line">    loss = loss.mean(dim=-<span class="number">1</span>)  <span class="comment"># [N, L], mean loss per patch</span></span><br><span class="line"></span><br><span class="line">    loss = (loss * mask).<span class="built_in">sum</span>() / mask.<span class="built_in">sum</span>()  <span class="comment"># mean loss on removed patches</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h3 id="different-models">1.9 different models</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_base_patch16_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">16</span>, embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_large_patch16_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">16</span>, embed_dim=<span class="number">1024</span>, depth=<span class="number">24</span>, num_heads=<span class="number">16</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_huge_patch14_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">14</span>, embed_dim=<span class="number">1280</span>, depth=<span class="number">32</span>, num_heads=<span class="number">16</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mae_vit_base_patch16 = mae_vit_base_patch16_dec512d8b  # decoder: 512 dim, 8 blocks</span><br><span class="line">mae_vit_large_patch16 = mae_vit_large_patch16_dec512d8b  # decoder: 512 dim, 8 blocks</span><br><span class="line">mae_vit_huge_patch14 = mae_vit_huge_patch14_dec512d8b  # decoder: 512 dim, 8 blocks</span><br></pre></td></tr></table></figure>
<h2 id="main_pretrain">2 main_pretrain</h2>
<figure>
<img src="C:\Users\jyh\AppData\Roaming\Typora\typora-user-images\image-20230420154128379.png" alt="image-20230420154128379" /><figcaption aria-hidden="true">image-20230420154128379</figcaption>
</figure>
<h3 id="设置参数的入口">2.1 设置参数的入口</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args = get_args_parser()</span><br><span class="line">    args = args.parse_args()</span><br><span class="line">    <span class="keyword">if</span> args.output_dir:</span><br><span class="line">        Path(args.output_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure>
<h3 id="main">2.2 main</h3>
<p>略。这个函数能够实现单机单卡，多机多卡，单机多卡，cpu等模式，通用性很强</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--accum_iter&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Accumulate gradient iterations (for increasing the effective batch size under memory constraints)&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>此内容可以用在低GPU内存，但是想要训练大batchsize的网络上(时间换空间)</li>
</ul>
<h3 id="misc.init_distributed_mode">2.3 misc.init_distributed_mode</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_distributed_mode</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="keyword">if</span> args.dist_on_itp:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_RANK&#x27;</span>])</span><br><span class="line">        args.world_size = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_SIZE&#x27;</span>])</span><br><span class="line">        args.gpu = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_LOCAL_RANK&#x27;</span>])</span><br><span class="line">        args.dist_url = <span class="string">&quot;tcp://%s:%s&quot;</span> % (os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>], os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>])</span><br><span class="line">        os.environ[<span class="string">&#x27;LOCAL_RANK&#x27;</span>] = <span class="built_in">str</span>(args.gpu)</span><br><span class="line">        os.environ[<span class="string">&#x27;RANK&#x27;</span>] = <span class="built_in">str</span>(args.rank)</span><br><span class="line">        os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>] = <span class="built_in">str</span>(args.world_size)</span><br><span class="line">        <span class="comment"># [&quot;RANK&quot;, &quot;WORLD_SIZE&quot;, &quot;MASTER_ADDR&quot;, &quot;MASTER_PORT&quot;, &quot;LOCAL_RANK&quot;]</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;RANK&#x27;</span> <span class="keyword">in</span> os.environ <span class="keyword">and</span> <span class="string">&#x27;WORLD_SIZE&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&quot;RANK&quot;</span>])</span><br><span class="line">        args.world_size = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>])</span><br><span class="line">        args.gpu = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;LOCAL_RANK&#x27;</span>])</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;SLURM_PROCID&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;SLURM_PROCID&#x27;</span>])</span><br><span class="line">        args.gpu = args.rank % torch.cuda.device_count()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Not using distributed mode&#x27;</span>)</span><br><span class="line">        setup_for_distributed(is_master=<span class="literal">True</span>)  <span class="comment"># hack</span></span><br><span class="line">        args.distributed = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    args.distributed = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    torch.cuda.set_device(args.gpu)</span><br><span class="line">    args.dist_backend = <span class="string">&#x27;nccl&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;| distributed init (rank &#123;&#125;): &#123;&#125;, gpu &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        args.rank, args.dist_url, args.gpu), flush=<span class="literal">True</span>)</span><br><span class="line">    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,</span><br><span class="line">                                         world_size=args.world_size, rank=args.rank)</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">    setup_for_distributed(args.rank == <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="prepare">2.4 prepare</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">misc.init_distributed_mode(args)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;job dir: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.path.dirname(os.path.realpath(__file__))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(args).replace(<span class="string">&#x27;, &#x27;</span>, <span class="string">&#x27;,\n&#x27;</span>))</span><br><span class="line"></span><br><span class="line">device = torch.device(args.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fix the seed for reproducibility</span></span><br><span class="line">seed = args.seed + misc.get_rank()</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line"></span><br><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h3 id="simple-augmentation">2.5 simple augmentation</h3>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201555531.png" alt="image-20230420155514559" /><figcaption aria-hidden="true">image-20230420155514559</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># simple augmentation</span></span><br><span class="line">transform_train = transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(args.input_size, scale=(<span class="number">0.2</span>, <span class="number">1.0</span>), interpolation=<span class="number">3</span>),  <span class="comment"># 3 is bicubic</span></span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(), <span class="comment"># unint8-&gt;float</span></span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line">dataset_train = datasets.ImageFolder(os.path.join(args.data_path, <span class="string">&#x27;train&#x27;</span>), transform=transform_train)</span><br><span class="line"><span class="built_in">print</span>(dataset_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_train, sampler=sampler_train,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="define-model">2.6 define model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">model = models_mae.__dict__[args.model](norm_pix_loss=args.norm_pix_loss)</span><br><span class="line"></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">model_without_ddp = model</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model = %s&quot;</span> % <span class="built_in">str</span>(model_without_ddp))</span><br><span class="line"></span><br><span class="line">eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.lr <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># only base_lr is specified</span></span><br><span class="line">    args.lr = args.blr * eff_batch_size / <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;base lr: %.2e&quot;</span> % (args.lr * <span class="number">256</span> / eff_batch_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;actual lr: %.2e&quot;</span> % args.lr)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accumulate grad iterations: %d&quot;</span> % args.accum_iter)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;effective batch size: %d&quot;</span> % eff_batch_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=<span class="literal">True</span>)</span><br><span class="line">    model_without_ddp = model.module</span><br><span class="line">    </span><br><span class="line">misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)</span><br></pre></td></tr></table></figure>
<h3 id="optimizer">2.7 optimizer</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># following timm: set wd as 0 for bias and norm layers</span></span><br><span class="line">param_groups = optim_factory.add_weight_decay(model_without_ddp, args.weight_decay)</span><br><span class="line">optimizer = torch.optim.AdamW(param_groups, lr=args.lr, betas=(<span class="number">0.9</span>, <span class="number">0.95</span>))</span><br><span class="line"><span class="built_in">print</span>(optimizer)</span><br><span class="line">loss_scaler = NativeScaler()</span><br></pre></td></tr></table></figure>
<h3 id="train">2.8 train</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Start training for <span class="subst">&#123;args.epochs&#125;</span> epochs&quot;</span>)</span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line">    <span class="keyword">if</span> args.distributed:</span><br><span class="line">        data_loader_train.sampler.set_epoch(epoch)</span><br><span class="line">    train_stats = train_one_epoch(</span><br><span class="line">        model, data_loader_train,</span><br><span class="line">        optimizer, device, epoch, loss_scaler,</span><br><span class="line">        log_writer=log_writer,</span><br><span class="line">        args=args</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> (epoch % <span class="number">20</span> == <span class="number">0</span> <span class="keyword">or</span> epoch + <span class="number">1</span> == args.epochs):</span><br><span class="line">        misc.save_model(</span><br><span class="line">            args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,</span><br><span class="line">            loss_scaler=loss_scaler, epoch=epoch)</span><br><span class="line"></span><br><span class="line">    log_stats = &#123;**&#123;<span class="string">f&#x27;train_<span class="subst">&#123;k&#125;</span>&#x27;</span>: v <span class="keyword">for</span> k, v <span class="keyword">in</span> train_stats.items()&#125;,</span><br><span class="line">                    <span class="string">&#x27;epoch&#x27;</span>: epoch,&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> misc.is_main_process():</span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            log_writer.flush()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.output_dir, <span class="string">&quot;log.txt&quot;</span>), mode=<span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(log_stats) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">total_time = time.time() - start_time</span><br><span class="line">total_time_str = <span class="built_in">str</span>(datetime.timedelta(seconds=<span class="built_in">int</span>(total_time)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training time &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(total_time_str))</span><br></pre></td></tr></table></figure>
<p>其中核心代码，单个epoch的训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">                    data_loader: Iterable, optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">                    device: torch.device, epoch: <span class="built_in">int</span>, loss_scaler,</span></span><br><span class="line"><span class="params">                    log_writer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                    args=<span class="literal">None</span></span>):</span><br><span class="line">    model.train(<span class="literal">True</span>)</span><br><span class="line">    metric_logger = misc.MetricLogger(delimiter=<span class="string">&quot;  &quot;</span>)</span><br><span class="line">    metric_logger.add_meter(<span class="string">&#x27;lr&#x27;</span>, misc.SmoothedValue(window_size=<span class="number">1</span>, fmt=<span class="string">&#x27;&#123;value:.6f&#125;&#x27;</span>))</span><br><span class="line">    header = <span class="string">&#x27;Epoch: [&#123;&#125;]&#x27;</span>.<span class="built_in">format</span>(epoch)</span><br><span class="line">    print_freq = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    accum_iter = args.accum_iter</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;log_dir: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(log_writer.log_dir))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_iter_step, (samples, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(metric_logger.log_every(data_loader, print_freq, header)):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># we use a per iteration (instead of per epoch) lr scheduler</span></span><br><span class="line">        <span class="keyword">if</span> data_iter_step % accum_iter == <span class="number">0</span>:</span><br><span class="line">            lr_sched.adjust_learning_rate(optimizer, data_iter_step / <span class="built_in">len</span>(data_loader) + epoch, args)</span><br><span class="line"></span><br><span class="line">        samples = samples.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.amp.autocast(): <span class="comment"># 自动混合精度</span></span><br><span class="line">            loss, _, _ = model(samples, mask_ratio=args.mask_ratio)</span><br><span class="line"></span><br><span class="line">        loss_value = loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> math.isfinite(loss_value):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Loss is &#123;&#125;, stopping training&quot;</span>.<span class="built_in">format</span>(loss_value))</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        loss /= accum_iter</span><br><span class="line">        loss_scaler(loss, optimizer, parameters=model.parameters(),</span><br><span class="line">                    update_grad=(data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        torch.cuda.synchronize()</span><br><span class="line"></span><br><span class="line">        metric_logger.update(loss=loss_value)</span><br><span class="line"></span><br><span class="line">        lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]</span><br><span class="line">        metric_logger.update(lr=lr)</span><br><span class="line"></span><br><span class="line">        loss_value_reduce = misc.all_reduce_mean(loss_value)</span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot; We use epoch_1000x as the x-axis in tensorboard.</span></span><br><span class="line"><span class="string">            This calibrates different curves when batch size changes.</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            epoch_1000x = <span class="built_in">int</span>((data_iter_step / <span class="built_in">len</span>(data_loader) + epoch) * <span class="number">1000</span>)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, loss_value_reduce, epoch_1000x)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;lr&#x27;</span>, lr, epoch_1000x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># gather the stats from all processes</span></span><br><span class="line">    metric_logger.synchronize_between_processes()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Averaged stats:&quot;</span>, metric_logger)</span><br><span class="line">    <span class="keyword">return</span> &#123;k: meter.global_avg <span class="keyword">for</span> k, meter <span class="keyword">in</span> metric_logger.meters.items()&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果因为timm报错，需要把 qk_scale=None注释掉</p></li>
<li><p>如果需要多卡训练 python -m torch.distributed.launch --nproc_per_node=2 main_prerain.py --batchsize=32 --world_size=2 --data_path="..."</p></li>
<li><p>dataset的目录结构</p></li>
</ul>
<p>/path/to/imagenet-1k/： train/ class1/ img1.jpeg class2/ img2.jpeg val/ class1/ img3.jpeg class2/ img4.jpeg</p>
<h2 id="main_fintune">3 main_fintune</h2>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201725532.png" alt="image-20230420172505860" /><figcaption aria-hidden="true">image-20230420172505860</figcaption>
</figure>
<p>大体和main_pretrain相同，这个是对编码器进行微调，微调的目的是为了更好的完成下游任务</p>
<h3 id="datasetnew">3.1 dataset(new)</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">is_train, args</span>):</span><br><span class="line">    transform = build_transform(is_train, args)</span><br><span class="line"></span><br><span class="line">    root = os.path.join(args.data_path, <span class="string">&#x27;train&#x27;</span> <span class="keyword">if</span> is_train <span class="keyword">else</span> <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">    dataset = datasets.ImageFolder(root, transform=transform)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_transform</span>(<span class="params">is_train, args</span>):</span><br><span class="line">    mean = IMAGENET_DEFAULT_MEAN</span><br><span class="line">    std = IMAGENET_DEFAULT_STD</span><br><span class="line">    <span class="comment"># train transform</span></span><br><span class="line">    <span class="comment"># 强增广</span></span><br><span class="line">    <span class="keyword">if</span> is_train:</span><br><span class="line">        <span class="comment"># this should always dispatch to transforms_imagenet_train</span></span><br><span class="line">        transform = create_transform(</span><br><span class="line">            input_size=args.input_size,</span><br><span class="line">            is_training=<span class="literal">True</span>,</span><br><span class="line">            color_jitter=args.color_jitter,</span><br><span class="line">            auto_augment=args.aa,</span><br><span class="line">            interpolation=<span class="string">&#x27;bicubic&#x27;</span>,</span><br><span class="line">            re_prob=args.reprob,</span><br><span class="line">            re_mode=args.remode,</span><br><span class="line">            re_count=args.recount,</span><br><span class="line">            mean=mean,</span><br><span class="line">            std=std,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> transform</span><br><span class="line"></span><br><span class="line">    <span class="comment"># eval transform</span></span><br><span class="line">    <span class="comment"># 基本没有增广</span></span><br><span class="line">    t = []</span><br><span class="line">    <span class="keyword">if</span> args.input_size &lt;= <span class="number">224</span>:</span><br><span class="line">        crop_pct = <span class="number">224</span> / <span class="number">256</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        crop_pct = <span class="number">1.0</span></span><br><span class="line">    size = <span class="built_in">int</span>(args.input_size / crop_pct)</span><br><span class="line">    t.append(</span><br><span class="line">        transforms.Resize(size, interpolation=PIL.Image.BICUBIC),  <span class="comment"># to maintain same ratio w.r.t. 224 images</span></span><br><span class="line">    )</span><br><span class="line">    t.append(transforms.CenterCrop(args.input_size))</span><br><span class="line"></span><br><span class="line">    t.append(transforms.ToTensor())</span><br><span class="line">    t.append(transforms.Normalize(mean, std))</span><br><span class="line">    <span class="keyword">return</span> transforms.Compose(t)</span><br></pre></td></tr></table></figure>
<h3 id="dataloader">3.2 dataloader</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_train, sampler=sampler_train,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">data_loader_val = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_val, sampler=sampler_val,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="mixup增广">3.3 mixup增广</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mixup_fn = <span class="literal">None</span></span><br><span class="line">mixup_active = args.mixup &gt; <span class="number">0</span> <span class="keyword">or</span> args.cutmix &gt; <span class="number">0.</span> <span class="keyword">or</span> args.cutmix_minmax <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> mixup_active:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Mixup is activated!&quot;</span>)</span><br><span class="line">    mixup_fn = Mixup(</span><br><span class="line">        mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,</span><br><span class="line">        prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,</span><br><span class="line">        label_smoothing=args.smoothing, num_classes=args.nb_classes)</span><br></pre></td></tr></table></figure>
<h3 id="model定义">3.4 model定义</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = models_vit.__dict__[args.model](</span><br><span class="line">    num_classes=args.nb_classes,</span><br><span class="line">    drop_path_rate=args.drop_path,</span><br><span class="line">    global_pool=args.global_pool,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(timm.models.vision_transformer.VisionTransformer):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Vision Transformer with support for global average pooling</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, global_pool=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">        self.global_pool = global_pool</span><br><span class="line">        <span class="keyword">if</span> self.global_pool:</span><br><span class="line">            norm_layer = kwargs[<span class="string">&#x27;norm_layer&#x27;</span>]</span><br><span class="line">            embed_dim = kwargs[<span class="string">&#x27;embed_dim&#x27;</span>]</span><br><span class="line">            self.fc_norm = norm_layer(embed_dim)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">del</span> self.norm  <span class="comment"># remove the original norm</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">        cls_tokens = self.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># stole cls_tokens impl from Phil Wang, thanks</span></span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        x = x + self.pos_embed</span><br><span class="line">        x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.global_pool:</span><br><span class="line">            x = x[:, <span class="number">1</span>:, :].mean(dim=<span class="number">1</span>)  <span class="comment"># global pool without cls token</span></span><br><span class="line">            outcome = self.fc_norm(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x = self.norm(x)</span><br><span class="line">            outcome = x[:, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outcome</span><br></pre></td></tr></table></figure>
<h3 id="预训练权重的导入">3.5 预训练权重的导入</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.finetune <span class="keyword">and</span> <span class="keyword">not</span> args.<span class="built_in">eval</span>:</span><br><span class="line">    checkpoint = torch.load(args.finetune, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Load pre-trained checkpoint from: %s&quot;</span> % args.finetune)</span><br><span class="line">    checkpoint_model = checkpoint[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">    state_dict = model.state_dict()</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">in</span> checkpoint_model <span class="keyword">and</span> checkpoint_model[k].shape != state_dict[k].shape:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Removing key <span class="subst">&#123;k&#125;</span> from pretrained checkpoint&quot;</span>)</span><br><span class="line">            <span class="keyword">del</span> checkpoint_model[k]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># interpolate position embedding</span></span><br><span class="line">    interpolate_pos_embed(model, checkpoint_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load pre-trained model</span></span><br><span class="line">    msg = model.load_state_dict(checkpoint_model, strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(msg)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.global_pool:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>, <span class="string">&#x27;fc_norm.weight&#x27;</span>, <span class="string">&#x27;fc_norm.bias&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># manually initialize fc layer</span></span><br><span class="line">    trunc_normal_(model.head.weight, std=<span class="number">2e-5</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>确保head部分的权重没有导入</li>
<li>线性插值：让微调阶段的position embedding仍然适用(如果模型变大)</li>
</ul>
<h2 id="linear-probing">4 linear probing</h2>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201725555.png" alt="image-20230420172530538" /><figcaption aria-hidden="true">image-20230420172530538</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for linear prob only</span></span><br><span class="line"><span class="comment"># hack: revise model&#x27;s head with BN</span></span><br><span class="line">model.head = torch.nn.Sequential(torch.nn.BatchNorm1d(model.head.in_features, affine=<span class="literal">False</span>, eps=<span class="number">1e-6</span>), model.head)</span><br><span class="line"><span class="comment"># freeze all but the head</span></span><br><span class="line"><span class="keyword">for</span> _, p <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    p.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> _, p <span class="keyword">in</span> model.head.named_parameters():</span><br><span class="line">    p.requires_grad = <span class="literal">True</span></span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/f0f056f4.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络9-ResNet" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/1c753934.html">用pytorch实现基础网络9-ResNet</a>
    </h2>
  

        
		
		  <a href="/post/1c753934.html" class="archive-article-date">
  	<time datetime="2023-04-19T11:24:03.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-19</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">3.3k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">18min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p>https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf</p>
<h1 id="使用timm复现resnet">使用timm复现ResNet</h1>
<p>论文内容略，本文采用的python+pytorch 环境为:</p>
<p>torch 1.13.1+cu117</p>
<p>python 3.7</p>
<p>timm 0.4.12</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm</span><br><span class="line">timm.create_model(<span class="string">&quot;resnet50&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br></pre></td><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (act1): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer2): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (3): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer3): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (3): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (4): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (5): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer4): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)</span><br><span class="line">  (fc): Linear(in_features=2048, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>lib/site-packages/timm/models/resnet.py</p>
<h2 id="resnet">1 ResNet</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stem</span></span><br><span class="line">self.conv1 = nn.Conv2d(in_chans, inplanes, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = norm_layer(inplanes)</span><br><span class="line">self.act1 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">self.feature_info = [<span class="built_in">dict</span>(num_chs=inplanes, reduction=<span class="number">2</span>, module=<span class="string">&#x27;act1&#x27;</span>)]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Stem Pooling</span></span><br><span class="line"><span class="keyword">if</span> aa_layer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	self.maxpool = nn.Sequential(*[</span><br><span class="line">		nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">		aa_layer(channels=inplanes, stride=<span class="number">2</span>)])</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>核心部分：feature map</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Feature Blocks</span></span><br><span class="line">channels = [<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">stage_modules, stage_feature_info = make_blocks(</span><br><span class="line">	block, channels, layers, inplanes, cardinality=cardinality, base_width=base_width,</span><br><span class="line">	output_stride=output_stride, reduce_first=block_reduce_first, avg_down=avg_down,</span><br><span class="line">	down_kernel_size=down_kernel_size, act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer,</span><br><span class="line">	drop_block_rate=drop_block_rate, drop_path_rate=drop_path_rate, **block_args)</span><br><span class="line"><span class="keyword">for</span> stage <span class="keyword">in</span> stage_modules:</span><br><span class="line">	self.add_module(*stage)  <span class="comment"># layer1, layer2, etc</span></span><br><span class="line">self.feature_info.extend(stage_feature_info)</span><br></pre></td></tr></table></figure>
<p>其中make_blocks是构建每个stage的具体实现，这里具体内容在第二部分查看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.num_features = <span class="number">512</span> * block.expansion</span><br><span class="line">self.global_pool, self.fc = create_classifier(self.num_features, self.num_classes, pool_type=global_pool)</span><br></pre></td></tr></table></figure>
<p>为什么这里有block.expansion?</p>
<p>在ResNet50中有些stage之间的通道数是不相同的，如果直接使用残差连接，无法完成直接相加，需要对某些深度通道进行压缩，expansion能够保证某些通道的输出维度是匹配的</p>
<h2 id="make_blocks">2 make_blocks</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_blocks</span>(<span class="params"></span></span><br><span class="line"><span class="params">        block_fn, channels, block_repeats, inplanes, reduce_first=<span class="number">1</span>, output_stride=<span class="number">32</span>,</span></span><br><span class="line"><span class="params">        down_kernel_size=<span class="number">1</span>, avg_down=<span class="literal">False</span>, drop_block_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.</span>, **kwargs</span>):</span><br><span class="line">    stages = []</span><br><span class="line">    feature_info = []</span><br><span class="line">    net_num_blocks = <span class="built_in">sum</span>(block_repeats)</span><br><span class="line">    net_block_idx = <span class="number">0</span></span><br><span class="line">    net_stride = <span class="number">4</span></span><br><span class="line">    dilation = prev_dilation = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> stage_idx, (planes, num_blocks, db) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(channels, block_repeats, drop_blocks(drop_block_rate))):</span><br><span class="line">        stage_name = <span class="string">f&#x27;layer<span class="subst">&#123;stage_idx + <span class="number">1</span>&#125;</span>&#x27;</span>  <span class="comment"># never liked this name, but weight compat requires it</span></span><br><span class="line">        stride = <span class="number">1</span> <span class="keyword">if</span> stage_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> net_stride &gt;= output_stride:</span><br><span class="line">            dilation *= stride</span><br><span class="line">            stride = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            net_stride *= stride</span><br><span class="line"></span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> inplanes != planes * block_fn.expansion:</span><br><span class="line">            down_kwargs = <span class="built_in">dict</span>(</span><br><span class="line">                in_channels=inplanes, out_channels=planes * block_fn.expansion, kernel_size=down_kernel_size,</span><br><span class="line">                stride=stride, dilation=dilation, first_dilation=prev_dilation, norm_layer=kwargs.get(<span class="string">&#x27;norm_layer&#x27;</span>))</span><br><span class="line">            downsample = downsample_avg(**down_kwargs) <span class="keyword">if</span> avg_down <span class="keyword">else</span> downsample_conv(**down_kwargs)</span><br><span class="line"></span><br><span class="line">        block_kwargs = <span class="built_in">dict</span>(reduce_first=reduce_first, dilation=dilation, drop_block=db, **kwargs)</span><br><span class="line">        blocks = []</span><br><span class="line">        <span class="keyword">for</span> block_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            downsample = downsample <span class="keyword">if</span> block_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            stride = stride <span class="keyword">if</span> block_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">            block_dpr = drop_path_rate * net_block_idx / (net_num_blocks - <span class="number">1</span>)  <span class="comment"># stochastic depth linear decay rule</span></span><br><span class="line">            blocks.append(block_fn(</span><br><span class="line">                inplanes, planes, stride, downsample, first_dilation=prev_dilation,</span><br><span class="line">                drop_path=DropPath(block_dpr) <span class="keyword">if</span> block_dpr &gt; <span class="number">0.</span> <span class="keyword">else</span> <span class="literal">None</span>, **block_kwargs))</span><br><span class="line">            prev_dilation = dilation</span><br><span class="line">            inplanes = planes * block_fn.expansion</span><br><span class="line">            net_block_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        stages.append((stage_name, nn.Sequential(*blocks)))</span><br><span class="line">        feature_info.append(<span class="built_in">dict</span>(num_chs=inplanes, reduction=net_stride, module=stage_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stages, feature_info</span><br></pre></td></tr></table></figure>
<p>这段代码定义了一个名为<code>make_blocks</code>的函数，用于构建一系列残差块（residual blocks）并形成卷积神经网络（CNN）的多个阶段。这种结构在 ResNet 及其变体中很常见。<code>make_blocks</code>函数接收多个参数，用于控制网络的结构和行为。函数的主要目的是根据给定的参数创建网络的各个阶段并返回这些阶段及其相关的特征信息。</p>
<p>以下是函数参数的简要说明：</p>
<ul>
<li><code>block_fn</code>：残差块的函数，如 ResNet 中的基本块或瓶颈块。</li>
<li><code>channels</code>：每个阶段的输出通道数量。</li>
<li><code>block_repeats</code>：每个阶段的残差块重复次数。</li>
<li><code>inplanes</code>：输入通道数量。</li>
<li>其他参数用于控制步长（<code>output_stride</code>）、下采样方式（<code>avg_down</code>）、DropBlock（<code>drop_block_rate</code>）和 Stochastic Depth（<code>drop_path_rate</code>）等高级功能。</li>
</ul>
<p>代码的主要部分是一个循环，针对每个阶段执行以下操作：</p>
<ol type="1">
<li>为每个阶段创建一个名为<code>stage_name</code>的变量，如<code>layer1</code>、<code>layer2</code>等。</li>
<li>计算步长（<code>stride</code>）和扩张率（<code>dilation</code>），这些值控制每个阶段的空间分辨率。</li>
<li>如果需要，创建下采样层（<code>downsample</code>），以使输入与输出具有兼容的尺寸。</li>
<li>根据给定的参数，创建一系列残差块。</li>
<li>将这些残差块组合成一个名为<code>nn.Sequential</code>的模块，将其添加到<code>stages</code>列表中。</li>
<li>将每个阶段的特征信息添加到<code>feature_info</code>列表中。</li>
</ol>
<p>最后，函数返回<code>stages</code>和<code>feature_info</code>，它们分别表示网络的各个阶段及其相关的特征信息。这些信息通常在之后的代码中用于构建完整的神经网络，并在训练过程中用于损失计算和评估等任务。</p>
<ul>
<li>downsample和block.expansion之间的联系：</li>
</ul>
<p><code>downsample</code> 和 <code>block.expansion</code> 在这段代码中具有不同的目的，但它们之间存在联系。首先，让我们解释它们各自的作用：</p>
<ol type="1">
<li><code>downsample</code>：<code>downsample</code> 是一个可选的下采样层，用于在输入和输出之间调整维度。在构建残差网络时，<code>downsample</code> 的目的是使跳过连接（skip connection）中的输入与残差块输出具有相同的尺寸，以便将它们相加。<code>downsample</code> 层通常包含一个卷积层和一个批量归一化层，用于调整输入的通道数量和/或分辨率。这样，即使输入和输出具有不同的尺寸，也可以将它们相加。</li>
<li><code>block.expansion</code>：<code>block.expansion</code> 是残差块中的扩张因子，用于控制输入和输出通道的增长。在 ResNet 架构中，基本块的扩张因子为 1（即输入和输出通道数量相同），而瓶颈块的扩张因子为 4（即输出通道数量为输入通道数量的 4 倍）。</li>
</ol>
<p>这两者之间的联系是：<code>downsample</code> 层用于调整输入的通道数量，使其与残差块输出的通道数量匹配。而<code>block.expansion</code> 则决定了残差块输出的通道数量。因此，在计算下采样层时，通常会将输出通道数量设置为 <code>planes * block_fn.expansion</code>，其中 <code>planes</code> 是当前阶段的输出通道数量，<code>block_fn.expansion</code> 是残差块的扩张因子。</p>
<p>简而言之，<code>downsample</code> 和 <code>block.expansion</code> 分别负责调整输入尺寸以匹配输出尺寸，以及控制残差块中输入和输出通道的增长。尽管它们具有不同的目的，但它们之间存在联系，共同影响网络的整体结构。</p>
<h2 id="basicblock">3 BasicBlock</h2>
<p>这个类就是对ResNet进行的一个实现，这个网络中的block大小都是相同的，所以没有用到上述的downsample和block.expansion</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, cardinality=<span class="number">1</span>, base_width=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 reduce_first=<span class="number">1</span>, dilation=<span class="number">1</span>, first_dilation=<span class="literal">None</span>, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,</span></span><br><span class="line"><span class="params">                 attn_layer=<span class="literal">None</span>, aa_layer=<span class="literal">None</span>, drop_block=<span class="literal">None</span>, drop_path=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> cardinality == <span class="number">1</span>, <span class="string">&#x27;BasicBlock only supports cardinality of 1&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> base_width == <span class="number">64</span>, <span class="string">&#x27;BasicBlock does not support changing base width&#x27;</span></span><br><span class="line">        first_planes = planes // reduce_first</span><br><span class="line">        outplanes = planes * self.expansion</span><br><span class="line">        first_dilation = first_dilation <span class="keyword">or</span> dilation</span><br><span class="line">        use_aa = aa_layer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (stride == <span class="number">2</span> <span class="keyword">or</span> first_dilation != dilation)</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(</span><br><span class="line">            inplanes, first_planes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span> <span class="keyword">if</span> use_aa <span class="keyword">else</span> stride, padding=first_dilation,</span><br><span class="line">            dilation=first_dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = norm_layer(first_planes)</span><br><span class="line">        self.act1 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.aa = aa_layer(channels=first_planes, stride=stride) <span class="keyword">if</span> use_aa <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(</span><br><span class="line">            first_planes, outplanes, kernel_size=<span class="number">3</span>, padding=dilation, dilation=dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = norm_layer(outplanes)</span><br><span class="line"></span><br><span class="line">        self.se = create_attn(attn_layer, outplanes)</span><br><span class="line"></span><br><span class="line">        self.act2 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.dilation = dilation</span><br><span class="line">        self.drop_block = drop_block</span><br><span class="line">        self.drop_path = drop_path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">zero_init_last_bn</span>(<span class="params">self</span>):</span><br><span class="line">        nn.init.zeros_(self.bn2.weight)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        shortcut = x</span><br><span class="line"></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        <span class="keyword">if</span> self.drop_block <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_block(x)</span><br><span class="line">        x = self.act1(x)</span><br><span class="line">        <span class="keyword">if</span> self.aa <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.aa(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.bn2(x)</span><br><span class="line">        <span class="keyword">if</span> self.drop_block <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_block(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.se <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.se(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.drop_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_path(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            shortcut = self.downsample(shortcut)</span><br><span class="line">        x += shortcut</span><br><span class="line">        x = self.act2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/1c753934.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络8-ConvNext" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/aa153511.html">用pytorch实现基础网络8-ConvNext</a>
    </h2>
  

        
		
		  <a href="/post/aa153511.html" class="archive-article-date">
  	<time datetime="2023-04-18T10:32:10.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-18</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">1.2k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">6min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h1 id="a-convnet-for-the-2020s">A ConvNet for the 2020s</h1>
<p>https://arxiv.org/pdf/2201.03545.pdf</p>
<p>A vanilla <strong>ViT</strong>, on the other hand, faces <strong>difficulties</strong> when applied to general computer vision tasks such as object detection and semantic segmentation</p>
<p>It is the <strong>hierarchical</strong> Transformers (e.g., <strong>Swin Transformers</strong>) that reintroduced several <strong>ConvNet</strong> priors, making Transformers practically viable as a generic vision backbone and demonstrating <strong>remarkable performance on a wide variety of vision tasks</strong>.</p>
<h2 id="理解什么是resnet-50">1 理解什么是ResNet-50</h2>
<ul>
<li>由48层卷积+1层maxpool+1层avgpool构成，卷积每个block的配比为3:4:6:3</li>
<li>ResNet50 Architecture</li>
</ul>
<figure>
<img src="https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png" alt="Table 1" /><figcaption aria-hidden="true">Table 1</figcaption>
</figure>
<h2 id="convnext主要宗旨">2 ConVNeXt主要宗旨</h2>
<ul>
<li>本文主要是希望基于ReSNet-50结构，并参考Swin-T的思考来升级改造ResNet，最终得到ResNet结构，并实现了新的准确率，并进一步探索了它的可扩展性。</li>
</ul>
<h2 id="优化器参数">3 优化器参数</h2>
<ul>
<li>AdamW，300epochs</li>
<li>准确率直接从76.1%提升到了78.8%</li>
<li>预训练学习率为4e-3，weight_decay=0.05,batchsize=4096</li>
<li>微调学习率为5e-5,weight_decay=1e-8,batchsize=512,layer-wise Ir decay</li>
</ul>
<h2 id="宏观设计">4 宏观设计</h2>
<ul>
<li>将[3,4,6,3]的区块比例改成了[3,3,9,3]</li>
<li>将底层的卷积替换成了4*4 stride=4的卷积，类似于patch</li>
<li>引入depth-wise conv，并将channels从64提升到96</li>
<li>引入bottleneck结构{channels分别为96 384 96}，并增大 kernel size 到 7*7</li>
</ul>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191428468.png" alt="image-20230419142812305" /><figcaption aria-hidden="true">image-20230419142812305</figcaption>
</figure>
<ul>
<li>至此，ImageNet-1k的准确率从78.8%提升到80.6%</li>
</ul>
<h2 id="微观设计">5 微观设计</h2>
<ul>
<li>将RELU替换成GELU，将BN替换为LN</li>
<li>引入更少激活函数和归一化层</li>
<li>采用2*2，stride=2的卷积进行下采样，并在底层、下采样之前和最后的平均池化之后加入LN层，使得训练更加稳定</li>
<li>至此，ImageNet-1k的准确率进一步提升到82.0%，击败Swin-T中的81.3%</li>
</ul>
<h2 id="可扩展性">6 可扩展性</h2>
<ul>
<li>ImageNet-1k训练
<ul>
<li>随着参数数目和计算量的增大，准确率也在逐步提升至85.5%</li>
</ul></li>
<li>增加ImageNet-22k训练，在迁移至ImageNet-1k微调
<ul>
<li>伴随预训练，同样的模型，效果涨幅约为2%</li>
<li>最终，ConvNeXt-XL效果达到87.8%</li>
</ul></li>
</ul>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191537241.png" alt="image-20230419144017393" /><figcaption aria-hidden="true">image-20230419144017393</figcaption>
</figure>
<h1 id="code">CODE</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/ConvNeXt">facebookresearch/ConvNeXt: Code release for ConvNeXt model (github.com)</a></p>
<h2 id="block">1 block</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; ConvNeXt Block. There are two equivalent implementations:</span></span><br><span class="line"><span class="string">    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)</span></span><br><span class="line"><span class="string">    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back</span></span><br><span class="line"><span class="string">    We use (2) as we find it slightly faster in PyTorch</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        drop_path (float): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, drop_path=<span class="number">0.</span>, layer_scale_init_value=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dwconv = nn.Conv2d(dim, dim, kernel_size=<span class="number">7</span>, padding=<span class="number">3</span>, groups=dim) <span class="comment"># depthwise conv</span></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.pwconv1 = nn.Linear(dim, <span class="number">4</span> * dim) <span class="comment"># pointwise/1x1 convs, implemented with linear layers</span></span><br><span class="line">        self.act = nn.GELU()</span><br><span class="line">        self.pwconv2 = nn.Linear(<span class="number">4</span> * dim, dim)</span><br><span class="line">        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), </span><br><span class="line">                                    requires_grad=<span class="literal">True</span>) <span class="keyword">if</span> layer_scale_init_value &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="built_in">input</span> = x</span><br><span class="line">        x = self.dwconv(x)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>) <span class="comment"># (N, C, H, W) -&gt; (N, H, W, C)</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.pwconv1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.pwconv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.gamma <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.gamma * x</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>) <span class="comment"># (N, H, W, C) -&gt; (N, C, H, W)</span></span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">input</span> + self.drop_path(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="connext">2 ConNeXt</h2>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191505813.png" alt="image-20230419150530038" /><figcaption aria-hidden="true">image-20230419150530038</figcaption>
</figure>
<ul>
<li>stem
<ul>
<li>conv2d: 3-&gt;96 kernel_size =4,stride=4</li>
<li>layernarm: 96</li>
</ul></li>
<li>downsampler_layer
<ul>
<li>layernrom: 96, 192, 384</li>
<li>conv2d: 96, 192, 384 -&gt; 192, 384, 768 kernel_size = 2,stride = 2 (patch merging)</li>
</ul></li>
<li>stage(4个阶段)
<ul>
<li>block数量:3,3,9,3</li>
<li>block input_channel: 96, 192, 384, 768</li>
<li>cur记录总的深度：每个深度的dropout是不同的，随着深度增大，dropout比例越大</li>
</ul></li>
<li>layernorm：768</li>
<li>head(Linear): 768 -&gt; num_classes</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>, </span></span><br><span class="line"><span class="params">             depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">3</span>], dims=[<span class="number">96</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>], drop_path_rate=<span class="number">0.</span>, </span></span><br><span class="line"><span class="params">             layer_scale_init_value=<span class="number">1e-6</span>, head_init_scale=<span class="number">1.</span>,</span></span><br><span class="line"><span class="params">             </span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    self.downsample_layers = nn.ModuleList() <span class="comment"># stem and 3 intermediate downsampling conv layers</span></span><br><span class="line">    stem = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">4</span>, stride=<span class="number">4</span>),</span><br><span class="line">        LayerNorm(dims[<span class="number">0</span>], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    self.downsample_layers.append(stem)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        downsample_layer = nn.Sequential(</span><br><span class="line">                LayerNorm(dims[i], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>),</span><br><span class="line">                nn.Conv2d(dims[i], dims[i+<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.downsample_layers.append(downsample_layer)</span><br><span class="line"></span><br><span class="line">    self.stages = nn.ModuleList() <span class="comment"># 4 feature resolution stages, each consisting of multiple residual blocks</span></span><br><span class="line">    dp_rates=[x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))] </span><br><span class="line">    cur = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        stage = nn.Sequential(</span><br><span class="line">            *[Block(dim=dims[i], drop_path=dp_rates[cur + j], </span><br><span class="line">            layer_scale_init_value=layer_scale_init_value) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(depths[i])]</span><br><span class="line">        )</span><br><span class="line">        self.stages.append(stage)</span><br><span class="line">        cur += depths[i]</span><br><span class="line"></span><br><span class="line">    self.norm = nn.LayerNorm(dims[-<span class="number">1</span>], eps=<span class="number">1e-6</span>) <span class="comment"># final norm layer</span></span><br><span class="line">    self.head = nn.Linear(dims[-<span class="number">1</span>], num_classes)</span><br><span class="line"></span><br><span class="line">    self.apply(self._init_weights)</span><br><span class="line">    self.head.weight.data.mul_(head_init_scale)</span><br><span class="line">    self.head.bias.data.mul_(head_init_scale)</span><br></pre></td></tr></table></figure>
<h1 id="isotropic-convnext-各向同性">Isotropic ConvNeXt 各向同性</h1>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191537246.png" alt="image-20230419153724437" /><figcaption aria-hidden="true">image-20230419153724437</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ef __init__(self, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>, </span><br><span class="line">                 depth=<span class="number">18</span>, dim=<span class="number">384</span>, drop_path_rate=<span class="number">0.</span>, </span><br><span class="line">                 layer_scale_init_value=<span class="number">0</span>, head_init_scale=<span class="number">1.</span>,</span><br><span class="line">                 ):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.stem = nn.Conv2d(in_chans, dim, kernel_size=<span class="number">16</span>, stride=<span class="number">16</span>)</span><br><span class="line">        dp_rates=[x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, depth)] </span><br><span class="line">        self.blocks = nn.Sequential(*[Block(dim=dim, drop_path=dp_rates[i], </span><br><span class="line">                                    layer_scale_init_value=layer_scale_init_value)</span><br><span class="line">                                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line"></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>) <span class="comment"># final norm layer</span></span><br><span class="line">        self.head = nn.Linear(dim, num_classes)</span><br><span class="line"></span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line">        self.head.weight.data.mul_(head_init_scale)</span><br><span class="line">        self.head.bias.data.mul_(head_init_scale)</span><br></pre></td></tr></table></figure>
<ul>
<li>不需要step，各向同性，通道数目在每个阶段都是相同的</li>
</ul>
<h1 id="训练">训练</h1>
<ul>
<li>data_path</li>
<li>data_set {CIFAR,IMNET,image_foler}</li>
</ul>
<p>https://timm.fast.ai/这里有大量的cv网络的实现</p>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/aa153511.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch基础入门10-word embedding" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/70a386a7.html">pytorch基础入门10-word embedding</a>
    </h2>
  

        
		
		  <a href="/post/70a386a7.html" class="archive-article-date">
  	<time datetime="2023-04-17T14:27:03.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-17</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">828字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">3min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h2 id="语言建模">语言建模</h2>
<ul>
<li>基于已有的人类组织的文本语料，基于无监督学习如何组织一句话并还能得到单词的语义表征</li>
<li>统计模型：n-gram</li>
<li>无监督学习：NNLM</li>
<li>大规模无监督学习：word2vec,BERT</li>
</ul>
<h3 id="n-gram">1 n-gram</h3>
<ul>
<li>特点：统计性、简单、泛化能力差、无法得到单词的语义信息</li>
<li>定义：n个相邻字符构成的序列
<ul>
<li>unigram</li>
<li>bigram</li>
<li>trigram</li>
</ul></li>
<li>用途：基于n-gram的频数分析文本，如垃圾邮件分类</li>
<li>对于word n-gram，特征维度随着语料词汇增大和n增大而指数增大(curse of dimensionality 维度灾难)</li>
<li>对于character n-gram，特征维度只随着n增大而增大</li>
</ul>
<h3 id="单词的语义表征">2 单词的语义表征</h3>
<ul>
<li>稀疏式
<ul>
<li>one-hot encoding 只能反应出单词在单词表中的位置信息，不能得出任何语义上的信息</li>
</ul></li>
<li>分布式
<ul>
<li>类似于word embedding 固定长度，每个位置上都是浮点型，这种语义表征是隐式的，是训练获得的(通过向量点积能得到相似度)</li>
</ul></li>
<li>应用场景
<ul>
<li>word/character/phrase/sentence/paragraph embedding</li>
<li>speaker/user/item embedding</li>
</ul></li>
</ul>
<h3 id="基于神经网络的语言模型nnlm">3 基于神经网络的语言模型(NNLM)</h3>
<ul>
<li>NNLM包括：
<ul>
<li>输入层(one-hot)</li>
<li>投影层</li>
<li>隐含层</li>
<li>输出层</li>
</ul></li>
<li>word embeddings为副产物，隐含的语义表征</li>
<li>主要复杂度： N*D*H+H*V</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/dQiaQ6INiazLoDx1sOWTQSTiaoLahdlZvZ9gBdtWVSS6gsqz8PLgHAPUesz0mqVCyo2MwjO6yssqnBOPO5BJ8z1lg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="Image" style="zoom:67%;" /></p>
<ul>
<li>如何降低复杂度？如何训练大规模数据？</li>
</ul>
<h3 id="word2vec">4 word2vec</h3>
<h4 id="改进1抛弃了隐含层并提出cbow和skip-gram">改进1：抛弃了隐含层，并提出CBOW和Skip-gram</h4>
<ul>
<li>continuous Bag-of-Words
<ul>
<li>不同于NNLM，CBOW考虑到了前后上下文</li>
<li>使用周围单词预测中间单词</li>
<li>输入：前n个单词和后n个单词</li>
<li>目标：基于H-softmax预测中间单词</li>
</ul></li>
</ul>
<p><span class="math display">\[
J_{\theta}=\frac{1}{T}\sum^T_{t=1}log P(w_t|w_{t-n},\dots,w_{t-1},w_{t+1},\dots,w_{t+n})
\]</span></p>
<ul>
<li>Skip-gram
<ul>
<li>与CBOW相反，使用中间单词预测周围单词</li>
<li>输入：中间单词</li>
<li>目标：基于H-softmax预测前n个单词和后n个单词</li>
</ul></li>
</ul>
<p><span class="math display">\[
J_{\theta} = \frac{1}{T}\sum^T_{t=1} \sum_{-n\le j\le n,n\ne 0}log\ \ p(w_{t+j}|w_t)
\]</span></p>
<figure>
<img src="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/Screenshot-2021-03-05-at-11.29.31-1024x616-1.png" alt="Screenshot-2021-03-05-at-11.29.31" /><figcaption aria-hidden="true">Screenshot-2021-03-05-at-11.29.31</figcaption>
</figure>
<h4 id="改进2优化softmax">改进2：优化softmax</h4>
<ul>
<li>softmax
<ul>
<li>计算量跟单词表数目K呈线性关系</li>
</ul></li>
</ul>
<p><span class="math display">\[
\sigma(\vec z)_i = \frac{e^{z_i}}{\sum^K_{j=1}e^{z_j}}
\]</span></p>
<ul>
<li>hierarchical softmax(huffman树)</li>
</ul>
<ol type="1">
<li>将{w1,w2,...,wn}看成是由n棵树的森林(每棵树仅有一个节点)</li>
<li>在森林中选出两个树节点的权值最小的树合并，作为一棵新树的左右子树，且新树的根节点权值为其左、右子树节点权值之和</li>
<li>从森林中删除选取的两棵树，并将新树加入森林</li>
<li>重复2,3步，知道森林中只剩一棵树为止，该树就为所求的Huffman树</li>
</ol>
<p><img src="https://www.ruder.io/content/images/2016/05/hierarchical_softmax.png" alt="img" /> <span class="math display">\[
p(right|n,c)=\sigma(h^Tv&#39;_n)
\]</span></p>
<p><span class="math display">\[
p(left|n,c) = 1-\sigma(h^Tv&#39;_n)
\]</span></p>
<h4 id="改进3引入负采样">改进3：引入负采样</h4>
<ul>
<li>continuous bag ofwords
<ul>
<li>输入：前n个单词和后n个单词</li>
<li>目标：使得预测中间单词的概率最大，负样本单词的概率最小</li>
</ul></li>
</ul>
<p><span class="math display">\[
g(w) = \prod_{u\in {w} \bigcup NEG(w)}p(u|Context(w))
\]</span></p>
<ul>
<li>Skip-gram
<ul>
<li>入：中间单词</li>
<li>目标：使得上下文单词概率最大，负样本单词的概率最小</li>
</ul></li>
</ul>
<p><span class="math display">\[
g(w) = \prod_{\tilde w\in {Context(w)}} \prod_{u\in {w} \bigcup  NEG^{\tilde w}(w)} p(u|\tilde w)
\]</span></p>
<h2 id="word-embeddings-in-pytorch">word embeddings in pytorch</h2>
<p>https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html</p>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/70a386a7.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch实用工具2-编写技巧" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/898bb30b.html">pytorch实用工具2-编写技巧</a>
    </h2>
  

        
		
		  <a href="/post/898bb30b.html" class="archive-article-date">
  	<time datetime="2023-04-17T11:36:18.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-17</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">421字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">2min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304172006805.png" alt="编写技巧" /><figcaption aria-hidden="true">编写技巧</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange,reduce,repeat</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.randn(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>) <span class="comment"># 4D tensor bs*ic*h*w</span></span><br></pre></td></tr></table></figure>
<h2 id="rearrange">1 rearrange</h2>
<h3 id="转置">1.1 转置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转置</span></span><br><span class="line">out1 = x.transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">out2 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b h i w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="变形">1.2 变形</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变形</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; (b i) h w&#x27;</span>)</span><br><span class="line">out2 = x.reshape(<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">out3 = rearrange(out2,<span class="string">&#x27;(b i) h w -&gt; b i h w&#x27;</span>,b=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out3,x))</span><br></pre></td></tr></table></figure>
<h3 id="image2patch">1.3 image2patch</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image2patch</span></span><br><span class="line">bs, ic, h, w = x.shape</span><br><span class="line">p = <span class="number">2</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i (h1 p1) (w1 p2) -&gt; b (h1 w1) (i p1 p2)&#x27;</span>,p1=<span class="number">2</span>,p2=<span class="number">2</span>) <span class="comment"># p是patch的边长 [batchsize,num_patch,patch_depth]</span></span><br><span class="line">out2 = F.unfold(x, kernel_size=(p, p),stride=(p, p)).transpose(-<span class="number">1</span>, -<span class="number">2</span>)  <span class="comment"># [bs,num_patch,patch_depth]</span></span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="堆叠">1.4 堆叠</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 堆叠</span></span><br><span class="line"><span class="built_in">print</span>(bs,i,h,w) <span class="comment"># (2,2,4,4)</span></span><br><span class="line">tensor_list = [x,x,x] <span class="comment"># only in the form of einops</span></span><br><span class="line">out1 = rearrange(tensor_list,<span class="string">&#x27;n b i h w -&gt; n b i h w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(out1.shape)</span><br><span class="line"></span><br><span class="line">y = torch.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">out2 = y.repeat(bs,i,h,w).reshape(<span class="number">3</span>,bs,i,h,w)</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br></pre></td></tr></table></figure>
<h2 id="reduce">2 reduce</h2>
<h3 id="求平均池化">2.1 求平均池化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求平均池化</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>) <span class="comment"># mean, min, max, sum, prod</span></span><br><span class="line">out2 = torch.mean(x,(-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="求和">2.2 求和</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求和</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h 1&#x27;</span>,<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># keep dimension</span></span><br><span class="line">out2 = torch.<span class="built_in">sum</span>(x,(-<span class="number">1</span>)).unsqueeze(-<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="多个维度操作">2.3 多个维度操作</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多个维度操作</span></span><br><span class="line">b, i, h, w = x.shape</span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i&#x27;</span>,<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">out2 = torch.max_pool2d(x,(h,w)).reshape(b,i)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h2 id="repeat">3 repeat</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b i h w 1&#x27;</span>)</span><br><span class="line">out2 = repeat(out1,<span class="string">&#x27;b i h w 1 -&gt; b i (2 h) w 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">out3 = torch.tile(out1,(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,))</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br><span class="line"><span class="built_in">print</span>(out3.shape)</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tools</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/898bb30b.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&lt;&lt; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">下一页 &gt;&gt;</a>
    </nav>
  


<!-- 主页添加mathjax公式 -->

  <!-- mathjax http://docs.mathjax.org/en/latest/web/start.html -->
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true
  },
  chtml: {
    scale: 1,                      // global scaling factor for all expressions
    minScale: .5,                  // smallest scaling factor to use
    mtextInheritFont: false,       // true to make mtext elements use surrounding font
    merrorInheritFont: false,      // true to make merror text use surrounding font
    mtextFont: '',                 // font to use for mtext, if not inheriting (empty means use MathJax fonts)
    merrorFont: 'serif',           // font to use for merror, if not inheriting (empty means use MathJax fonts)
    unknownFamily: 'serif',        // font to use for character that aren't in MathJax's fonts
    mathmlSpacing: false,          // true for MathML spacing rules, false for TeX rules
    skipAttributes: {},            // RFDa and other attributes NOT to copy to the output
    exFactor: .5,                  // default size of ex in em units
    displayAlign: 'center',        // default for indentalign when set to 'auto'
    displayIndent: '0'             // default for indentshift when set to 'auto'
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
};
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<!-- 主页添加mathjax公式 -->

          </div>
        </div>
      </div>
	  
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: false,
		root: "/",
		innerArchive: false,
		showTags: true
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev"><< 上一页</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">下一页 >></a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/js/main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/js/slider.e37972.js")}()</script>

<!--添加鼠标特效-->
<!-- https://blog.csdn.net/weixin_41287260/article/details/103050877 -->



<!--添加鼠标特效结束-->
    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="搜一搜">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">aboutme</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">pytorch</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">tools</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">diffusion model</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">project</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">tips</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">github</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">network</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
			<pre style="font-size: 12px;" q-show="jsonFail">
			  jsonContent:
				meta: false
				pages: false
				posts:
				  title: true
				  date: true
				  path: true
				  text: false
				  raw: false
				  content: false
				  slug: false
				  updated: false
				  comments: false
				  link: false
				  permalink: false
				  excerpt: false
				  categories: false
				  tags: true
			</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://chat.openai.com/auth/login/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>chatgpt</a>
            </li>
          
            <li class="search-li">
              <a href="https://xs.scqylaw.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>google scholar</a>
            </li>
          
            <li class="search-li">
              <a href="https://pytorch.org/tutorials/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>pytorch</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.latexlive.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>在线latex公式编辑器</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接4</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接5</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接6</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
		<div class="aboutme-wrap"> 
			<div style="display:;color:LightSkyBlue;"> 
				
					<p id="hitokoto" style="margin:0 20px 0 20px;color:GreenYellow;"></p>
					<div style="margin:0 20px 0 20px;">
						<p id="from" style="margin:10px;text-align:right;color:Salmon;"></p>
					</div>	
					<script>
						var xmlhttp = new XMLHttpRequest();
						xmlhttp.onreadystatechange = function() {
								if (this.readyState == 4 && this.status == 200) {
									yiyan = JSON.parse(this.responseText);
									document.getElementById("hitokoto").innerHTML =yiyan.hitokoto;
								document.getElementById("from").innerHTML ="——《"+ yiyan.from+"》";
							 }
						};
						xmlhttp.open("GET", "https://v1.hitokoto.cn/?c=a&c=d&c=c", true);
						xmlhttp.send();
					</script>
				
			
				<br>
				  
					<p id="js-aboutme" style="margin:0 20px 0 20px;">just for fun</p>
				
			</div> 
		</div> 
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
  
  <!-- 代码块复制功能 -->
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js"></script>
  <script type="text/javascript" src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
  <script type="text/javascript" src="/js/clipboard_use.js"></script>
  <!-- 代码块复制功能结束 -->
  
  <!--全局添加雪花特效 -->
  
  <!--全局添加雪花特效结束 -->

  <!--全局添加 aplayer播放器 https://aplayer.js.org/#/zh-Hans/ -->
  
  <!-- aplayer播放器功能结束 -->
  
</body>
