<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" >
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <meta http-equiv="Content-Language" content="zh-cn">
  <link rel="dns-prefetch" href="https://wangtongyouwen.github.io">
  <title>jyh blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:type" content="website">
<meta property="og:title" content="jyh blog">
<meta property="og:url" content="https://wangtongyouwen.github.io/page/2/index.html">
<meta property="og:site_name" content="jyh blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="jyh">
<meta name="twitter:card" content="summary">
  
  
    <link rel="alternative" href="/atom.xml" title="jyh blog" type="application/atom+xml">
  
  
    <link rel="icon" type="image/x-icon" href="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg">
  
  <link rel="stylesheet" type="text/css" href="/css/main.0cf68a.css">
  
	<link rel="stylesheet" type="text/css" href="/css/avatarrotation.css">
  
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(45deg, #e0e5df, #96a48b);
    }
  </style>
    
  <!-- 引入font-awesome图标库 -->
  <!-- <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet"> -->
  <link href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css" rel="stylesheet">
  <!-- <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">-->
  
  <!--谷歌分析-->
  

  <!--百度统计-->
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  <!--百度自动推送-->
  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>

  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: linear-gradient(45deg, #e0e5df, #96a48b)"></div>
<div class="intrude-less">
	<header id="header" class="inner">
	
		<a href="/" class="profilepic">
			<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg" class="js-avatar" alt="avatar">
		</a>
		
		<hgroup>
		  <div class="header-author"><a href="/">jyh</a></div>
		</hgroup>
		
		
		<p class="header-subtitle">jyh的博客</p>
		

		<nav class="header-menu">
			<ul>   
			
			   	
				  <li><a href="/" class="fa fa-home fa-fw"></a></li>
				
	        
			   	
				  <li><a href="/archives/index.html">归档</a></li>
				
	        
			   	
				  <li><a href="/categories/index.html">分类</a></li>
				
	        
			
			</ul>
		</nav>

		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
			
			  
				<a href="/tags/pytorch/">pytorch</a>
			  
	        		
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
		        
					<a class="gitee" target="_blank" href="#" title="gitee"><i class="icon-gitee"></i></a>
		        
					<a class="csdn" target="_blank" href="#" title="csdn"><i class="icon-csdn"></i></a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
		        
					<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:XXX@XXX.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
		
		<!-- 网易云音乐插件 -->
		
			
		<!--时钟-->
		
			<!--时钟-->
<br>
<div style="position:absolute; bottom:120px left:auto; width:100%;height:50%">
	<script type="text/javascript" src="https://cdn.staticfile.org/vue/2.4.2/vue.min.js"></script>
	<div id="clock" style="font-family: 'Share Tech Mono', monospace;color: #ffffff;text-align: center;position: absolute;width: 250px;left: 50%;top: 50%;-webkit-transform: translate(50%, 50%);transform: translate(-50%, -50%);color: #4B8CE1;/* text-shadow: 0 0 20px #0aafe6, 0 0 20px rgba(10, 175, 230, 0); */">
		<p style="margin: 0;padding: 0;letter-spacing: 0.1em;font-size: 15px;">{{ date }}</p>
		<p style="margin: 0;padding: 0;letter-spacing: 0.01em;font-size: 25px;">{{ time }}</p>
	</div>
	<script>
		var clock = new Vue({
			el: '#clock',
			data: {
				time: '',
				date: ''
			}
		});

		var week = ['星期日', '星期一', '星期二', '星期三', '星期四', '星期五', '星期六'];
		var timerID = setInterval(updateTime, 1000);
		updateTime();
		function updateTime() {
			var cd = new Date();
			clock.time = zeroPadding(cd.getHours(), 2) + ':' + zeroPadding(cd.getMinutes(), 2) + ':' + zeroPadding(cd.getSeconds(), 2);
			clock.date = zeroPadding(cd.getFullYear(), 4) + '-' + zeroPadding(cd.getMonth() + 1, 2) + '-' + zeroPadding(cd.getDate(), 2) + ' ' + week[cd.getDay()];
		};

		function zeroPadding(num, digit) {
			var zero = '';
			for (var i = 0; i < digit; i++) {
				zero += '0';
			}
			return (zero + num).slice(-digit);
		}
	</script>
</div>
		

	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<!-- <div class="overlay js-overlay" style="background: linear-gradient(45deg, #e0e5df, #96a48b)"></div> -->
	<div class="overlay js-overlay" ></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)">
		<div class="left-icon-container">
			<i class="icon icon-sort"></i></div>
		</div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304051210238.jpg" class="js-avatar" alt="avatar">
			</a>
			
			<hgroup>
			  <div class="header-author js-header-author">jyh</div>
			</hgroup>
			
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>jyh的博客<i class="icon icon-quo-right"></i></p>
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
			        
						<a class="gitee" target="_blank" href="#" title="gitee"><i class="icon-gitee"></i></a>
			        
						<a class="csdn" target="_blank" href="#" title="csdn"><i class="icon-csdn"></i></a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:XXX@XXX.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>
			
			
			
			
				
			
				
			
				
			
			
				
			
			

			<nav class="header-menu js-header-menu">
				<ul style="width: 80%">
					
					
						<li style="width: 25%"><a href="/">主页</a></li>
					
						<li style="width: 25%"><a href="/archives/index.html">归档</a></li>
					
						<li style="width: 25%"><a href="/categories/index.html">分类</a></li>
					
					
						<li style="width: 25%"><a href="/tags/pytorch/">pytorch</a></li>
					
				</ul>	
			</nav>
			
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-pytorch基础入门10-word embedding" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/70a386a7.html">pytorch基础入门10-word embedding</a>
    </h2>
  

        
		
		  <a href="/post/70a386a7.html" class="archive-article-date">
  	<time datetime="2023-04-17T14:27:03.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-17</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">828字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">3min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h2 id="语言建模">语言建模</h2>
<ul>
<li>基于已有的人类组织的文本语料，基于无监督学习如何组织一句话并还能得到单词的语义表征</li>
<li>统计模型：n-gram</li>
<li>无监督学习：NNLM</li>
<li>大规模无监督学习：word2vec,BERT</li>
</ul>
<h3 id="n-gram">1 n-gram</h3>
<ul>
<li>特点：统计性、简单、泛化能力差、无法得到单词的语义信息</li>
<li>定义：n个相邻字符构成的序列
<ul>
<li>unigram</li>
<li>bigram</li>
<li>trigram</li>
</ul></li>
<li>用途：基于n-gram的频数分析文本，如垃圾邮件分类</li>
<li>对于word n-gram，特征维度随着语料词汇增大和n增大而指数增大(curse of dimensionality 维度灾难)</li>
<li>对于character n-gram，特征维度只随着n增大而增大</li>
</ul>
<h3 id="单词的语义表征">2 单词的语义表征</h3>
<ul>
<li>稀疏式
<ul>
<li>one-hot encoding 只能反应出单词在单词表中的位置信息，不能得出任何语义上的信息</li>
</ul></li>
<li>分布式
<ul>
<li>类似于word embedding 固定长度，每个位置上都是浮点型，这种语义表征是隐式的，是训练获得的(通过向量点积能得到相似度)</li>
</ul></li>
<li>应用场景
<ul>
<li>word/character/phrase/sentence/paragraph embedding</li>
<li>speaker/user/item embedding</li>
</ul></li>
</ul>
<h3 id="基于神经网络的语言模型nnlm">3 基于神经网络的语言模型(NNLM)</h3>
<ul>
<li>NNLM包括：
<ul>
<li>输入层(one-hot)</li>
<li>投影层</li>
<li>隐含层</li>
<li>输出层</li>
</ul></li>
<li>word embeddings为副产物，隐含的语义表征</li>
<li>主要复杂度： N*D*H+H*V</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/dQiaQ6INiazLoDx1sOWTQSTiaoLahdlZvZ9gBdtWVSS6gsqz8PLgHAPUesz0mqVCyo2MwjO6yssqnBOPO5BJ8z1lg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="Image" style="zoom:67%;" /></p>
<ul>
<li>如何降低复杂度？如何训练大规模数据？</li>
</ul>
<h3 id="word2vec">4 word2vec</h3>
<h4 id="改进1抛弃了隐含层并提出cbow和skip-gram">改进1：抛弃了隐含层，并提出CBOW和Skip-gram</h4>
<ul>
<li>continuous Bag-of-Words
<ul>
<li>不同于NNLM，CBOW考虑到了前后上下文</li>
<li>使用周围单词预测中间单词</li>
<li>输入：前n个单词和后n个单词</li>
<li>目标：基于H-softmax预测中间单词</li>
</ul></li>
</ul>
<p><span class="math display">\[
J_{\theta}=\frac{1}{T}\sum^T_{t=1}log P(w_t|w_{t-n},\dots,w_{t-1},w_{t+1},\dots,w_{t+n})
\]</span></p>
<ul>
<li>Skip-gram
<ul>
<li>与CBOW相反，使用中间单词预测周围单词</li>
<li>输入：中间单词</li>
<li>目标：基于H-softmax预测前n个单词和后n个单词</li>
</ul></li>
</ul>
<p><span class="math display">\[
J_{\theta} = \frac{1}{T}\sum^T_{t=1} \sum_{-n\le j\le n,n\ne 0}log\ \ p(w_{t+j}|w_t)
\]</span></p>
<figure>
<img src="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/Screenshot-2021-03-05-at-11.29.31-1024x616-1.png" alt="Screenshot-2021-03-05-at-11.29.31" /><figcaption aria-hidden="true">Screenshot-2021-03-05-at-11.29.31</figcaption>
</figure>
<h4 id="改进2优化softmax">改进2：优化softmax</h4>
<ul>
<li>softmax
<ul>
<li>计算量跟单词表数目K呈线性关系</li>
</ul></li>
</ul>
<p><span class="math display">\[
\sigma(\vec z)_i = \frac{e^{z_i}}{\sum^K_{j=1}e^{z_j}}
\]</span></p>
<ul>
<li>hierarchical softmax(huffman树)</li>
</ul>
<ol type="1">
<li>将{w1,w2,...,wn}看成是由n棵树的森林(每棵树仅有一个节点)</li>
<li>在森林中选出两个树节点的权值最小的树合并，作为一棵新树的左右子树，且新树的根节点权值为其左、右子树节点权值之和</li>
<li>从森林中删除选取的两棵树，并将新树加入森林</li>
<li>重复2,3步，知道森林中只剩一棵树为止，该树就为所求的Huffman树</li>
</ol>
<p><img src="https://www.ruder.io/content/images/2016/05/hierarchical_softmax.png" alt="img" /> <span class="math display">\[
p(right|n,c)=\sigma(h^Tv&#39;_n)
\]</span></p>
<p><span class="math display">\[
p(left|n,c) = 1-\sigma(h^Tv&#39;_n)
\]</span></p>
<h4 id="改进3引入负采样">改进3：引入负采样</h4>
<ul>
<li>continuous bag ofwords
<ul>
<li>输入：前n个单词和后n个单词</li>
<li>目标：使得预测中间单词的概率最大，负样本单词的概率最小</li>
</ul></li>
</ul>
<p><span class="math display">\[
g(w) = \prod_{u\in {w} \bigcup NEG(w)}p(u|Context(w))
\]</span></p>
<ul>
<li>Skip-gram
<ul>
<li>入：中间单词</li>
<li>目标：使得上下文单词概率最大，负样本单词的概率最小</li>
</ul></li>
</ul>
<p><span class="math display">\[
g(w) = \prod_{\tilde w\in {Context(w)}} \prod_{u\in {w} \bigcup  NEG^{\tilde w}(w)} p(u|\tilde w)
\]</span></p>
<h2 id="word-embeddings-in-pytorch">word embeddings in pytorch</h2>
<p>https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html</p>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/70a386a7.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch实用工具2-编写技巧" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/898bb30b.html">pytorch实用工具2-编写技巧</a>
    </h2>
  

        
		
		  <a href="/post/898bb30b.html" class="archive-article-date">
  	<time datetime="2023-04-17T11:36:18.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-17</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">421字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">2min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304172006805.png" alt="编写技巧" /><figcaption aria-hidden="true">编写技巧</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange,reduce,repeat</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.randn(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>) <span class="comment"># 4D tensor bs*ic*h*w</span></span><br></pre></td></tr></table></figure>
<h2 id="rearrange">1 rearrange</h2>
<h3 id="转置">1.1 转置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转置</span></span><br><span class="line">out1 = x.transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">out2 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b h i w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="变形">1.2 变形</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变形</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; (b i) h w&#x27;</span>)</span><br><span class="line">out2 = x.reshape(<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">out3 = rearrange(out2,<span class="string">&#x27;(b i) h w -&gt; b i h w&#x27;</span>,b=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out3,x))</span><br></pre></td></tr></table></figure>
<h3 id="image2patch">1.3 image2patch</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image2patch</span></span><br><span class="line">bs, ic, h, w = x.shape</span><br><span class="line">p = <span class="number">2</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i (h1 p1) (w1 p2) -&gt; b (h1 w1) (i p1 p2)&#x27;</span>,p1=<span class="number">2</span>,p2=<span class="number">2</span>) <span class="comment"># p是patch的边长 [batchsize,num_patch,patch_depth]</span></span><br><span class="line">out2 = F.unfold(x, kernel_size=(p, p),stride=(p, p)).transpose(-<span class="number">1</span>, -<span class="number">2</span>)  <span class="comment"># [bs,num_patch,patch_depth]</span></span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="堆叠">1.4 堆叠</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 堆叠</span></span><br><span class="line"><span class="built_in">print</span>(bs,i,h,w) <span class="comment"># (2,2,4,4)</span></span><br><span class="line">tensor_list = [x,x,x] <span class="comment"># only in the form of einops</span></span><br><span class="line">out1 = rearrange(tensor_list,<span class="string">&#x27;n b i h w -&gt; n b i h w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(out1.shape)</span><br><span class="line"></span><br><span class="line">y = torch.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">out2 = y.repeat(bs,i,h,w).reshape(<span class="number">3</span>,bs,i,h,w)</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br></pre></td></tr></table></figure>
<h2 id="reduce">2 reduce</h2>
<h3 id="求平均池化">2.1 求平均池化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求平均池化</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>) <span class="comment"># mean, min, max, sum, prod</span></span><br><span class="line">out2 = torch.mean(x,(-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="求和">2.2 求和</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求和</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h 1&#x27;</span>,<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># keep dimension</span></span><br><span class="line">out2 = torch.<span class="built_in">sum</span>(x,(-<span class="number">1</span>)).unsqueeze(-<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h3 id="多个维度操作">2.3 多个维度操作</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多个维度操作</span></span><br><span class="line">b, i, h, w = x.shape</span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i&#x27;</span>,<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">out2 = torch.max_pool2d(x,(h,w)).reshape(b,i)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure>
<h2 id="repeat">3 repeat</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b i h w 1&#x27;</span>)</span><br><span class="line">out2 = repeat(out1,<span class="string">&#x27;b i h w 1 -&gt; b i (2 h) w 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">out3 = torch.tile(out1,(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,))</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br><span class="line"><span class="built_in">print</span>(out3.shape)</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tools</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/898bb30b.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch基础入门9-seq2seq2" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/86ae38c6.html">pytorch基础入门9-seq2seq2</a>
    </h2>
  

        
		
		  <a href="/post/86ae38c6.html" class="archive-article-date">
  	<time datetime="2023-04-17T04:40:39.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-17</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">1.3k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">7min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h1 id="neural-machine-translation-by-jointly-learning-to-align-and-translate">1 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</h1>
<p>https://arxiv.org/pdf/1409.0473.pdf?utm_source=ColumnsChannel</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304171444845.png" alt="image-20230417144427318" /><figcaption aria-hidden="true">image-20230417144427318</figcaption>
</figure>
<h1 id="effective-approaches-to-attention-based-neural-machine-translation">2 Effective Approaches to Attention-based Neural Machine Translation</h1>
<p>https://arxiv.org/pdf/1508.04025)</p>
<h2 id="global-attention">2.1 global attention</h2>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304171447590.png" alt="image-20230417144755015" /><figcaption aria-hidden="true">image-20230417144755015</figcaption>
</figure>
<p>The idea of a global attentional model is to consider all the hidden states of the encoder when deriving the <strong>context vector</strong> <span class="math inline">\(c_t\)</span> . In this model type, a <strong>variable-length alignment vector</strong> <span class="math inline">\(a_t\)</span> , whose size equals the number of time steps on the source side, is derived by comparing the current target hidden state ht with each <strong>source hidden state</strong> <span class="math inline">\(\bar h _s\)</span>: <span class="math display">\[
\begin{aligned}
\boldsymbol{a}_{t}(s) &amp; =\operatorname{align}\left(\boldsymbol{h}_{t}, \overline{\boldsymbol{h}}_{s}\right) \\
&amp; =\frac{\exp \left(\operatorname{score}\left(\boldsymbol{h}_{t}, \overline{\boldsymbol{h}}_{s}\right)\right)}{\sum_{s^{\prime}} \exp \left(\operatorname{score}\left(\boldsymbol{h}_{t}, \overline{\boldsymbol{h}}_{s^{\prime}}\right)\right)}
\end{aligned}
\]</span> score is referred as a <strong>content-based function</strong> for which we consider three different alternatives <span class="math display">\[
\operatorname{score}\left(\boldsymbol{h}_{t}, \overline{\boldsymbol{h}}_{s}\right)=\left\{\begin{array}{ll}
\boldsymbol{h}_{t}^{\top} \overline{\boldsymbol{h}}_{s} &amp; \text { dot } \\
\boldsymbol{h}_{t}^{\top} \boldsymbol{W}_{\boldsymbol{a}} \overline{\boldsymbol{h}}_{s} &amp; \text { general } \\
\boldsymbol{v}_{a}^{\top} \tanh \left(\boldsymbol{W}_{\boldsymbol{a}}\left[\boldsymbol{h}_{t} ; \overline{\boldsymbol{h}}_{s}\right]\right) &amp; \text { concat }
\end{array}\right.
\]</span> dot: transformer Q K V 并行计算</p>
<p>general: 乘法注意力机制</p>
<p>concat: 加法注意力机制</p>
<p>基于位置的: location-based function in which the <strong>alignment scores</strong> are computed from solely the target hidden state <span class="math inline">\(h_t\)</span> <span class="math display">\[
a_t = softmax(W_ah_t)  \     \ location
\]</span></p>
<p>全局注意力计算量大，有些任务也不需要进行全局注意力计算。</p>
<h2 id="local-attention">2.2 local attention</h2>
<p>This model takes inspiration from the tradeoff between the <strong>soft and hard</strong> attentional models</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304171454431.png" alt="image-20230417145444733" /><figcaption aria-hidden="true">image-20230417145444733</figcaption>
</figure>
<ul>
<li>generate an aligned position <span class="math inline">\(p_t\)</span> for each target word at time <span class="math inline">\(t\)</span></li>
<li>the context vector <span class="math inline">\(c_t\)</span> is then derived as a weighted average over the set of source hidden states within the window <span class="math inline">\([p_t-D,p_t+D]\)</span> <span class="math inline">\(D\)</span> is empirically selected</li>
<li><span class="math inline">\(a_t\)</span> is fixed-dimensional, i.e. <span class="math inline">\(\in \R^{2D+1}\)</span></li>
<li>Monotonic alignment (<strong>local-m</strong>) <span class="math inline">\(p_t = t\)</span> assuming that source and target sequences are roughly monotonically aligned 编码器的中心位置是经验性的，不是训练出来的。hard 方法</li>
<li>Predictive alignment (<strong>local-p</strong>) 模型能够计算出编码器的中心位置，这是训练得到的 soft 方法</li>
</ul>
<p><span class="math display">\[
p_{t}=S \cdot \operatorname{sigmoid}\left(\boldsymbol{v}_{p}^{\top} \tanh \left(\boldsymbol{W}_{\boldsymbol{p}} \boldsymbol{h}_{t}\right)\right)
\]</span></p>
<ul>
<li><ul>
<li><span class="math inline">\(W_p,v_p\)</span>: the model parameters which will be learned to predict positions</li>
<li><span class="math inline">\(S\)</span>: the source sentence length</li>
</ul></li>
<li>alignment weights -&gt; Gaussian distribution</li>
</ul>
<p><span class="math display">\[
\boldsymbol{a}_{t}(s)=\operatorname{align}\left(\boldsymbol{h}_{t}, \overline{\boldsymbol{h}}_{s}\right) \exp \left(-\frac{\left(s-p_{t}\right)^{2}}{2 \sigma^{2}}\right)  where \ \sigma = \frac{D}{2}
\]</span></p>
<h1 id="代码实现">3 代码实现</h1>
<h2 id="encoder">3.1 encoder</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;以离散符号(索引的符号)的分类任务为例，实现基于注意力机制的seq2seq模型&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Seq2SeqEncoder(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;实现基于LSTM的编码器，也可以是其他类型的，如CNN，TransformerEncoder&quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot;对原序列进行上下文相关的表征&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, embedding_dim, hidden_size, source_vocab_size):</span><br><span class="line">        super(Seq2SeqEncoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.lstm_layer = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)</span><br><span class="line">        # num_embeddings (int): size of the dictionary of embeddings</span><br><span class="line">        # embedding_dim (int): the size of each embedding vector</span><br><span class="line">        self.embedding_table = nn.Embedding(source_vocab_size, embedding_dim)  # 将token转换成 token_embedding # 可训练</span><br><span class="line"></span><br><span class="line">    def forward(self, input_ids):</span><br><span class="line">        # 原序列不是流式的，所以能够一次性拿到全部序列</span><br><span class="line">        input_sequence = self.embedding_table(input_ids)  # [bs,source_length,embedding_dim]</span><br><span class="line">        output_states, (final_h, final_c) = self.lstm_layer(input_sequence)</span><br><span class="line"></span><br><span class="line">        return output_states, final_h</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="attentionmechanism">3.2 AttentionMechanism</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class Seq2SeqAttentionMechanism(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;实现dot-product的attention&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Seq2SeqAttentionMechanism, self).__init__()</span><br><span class="line"></span><br><span class="line">    def forward(self, decoder_state_t, encoder_states):</span><br><span class="line">        # encoder_states: 完整的编码序列</span><br><span class="line">        # decoder_State_t: t 时刻的decoder序列</span><br><span class="line">        bs, source_length, hidden_size = encoder_states.shape</span><br><span class="line"></span><br><span class="line">        decoder_state_t = decoder_state_t.unsqueeze(1)  # [bs,1,hidden_size]</span><br><span class="line">        decoder_state_t = torch.tile(decoder_state_t, dims=(1, source_length, 1))  # 复制为 [bs,source_length,hidden_size]</span><br><span class="line"></span><br><span class="line">        score = torch.sum(decoder_state_t * encoder_states, dim=-1)  # [bs,source_length]</span><br><span class="line"></span><br><span class="line">        attn_prob = F.softmax(score, dim=-1)  # 得到序列中每个具体索引在整个序列中的权重值,总和为1 [bs,source_length]</span><br><span class="line"></span><br><span class="line">        # 加权求和</span><br><span class="line">        # 使用了广播机制 attn_prob: [bs,source_length], decoder_state_t: [bs,source_length,hidden_size]</span><br><span class="line">        context = torch.sum(attn_prob.unsqueeze(-1) * encoder_states,1) # [bs,hidden_size] -&gt; 第t时刻解码器需要的上下文向量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return attn_prob, context</span><br></pre></td></tr></table></figure>
<h2 id="decoder">3.3 Decoder</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">class Seq2SeqDecoder(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, embedding_dim, hidden_size, num_classes, target_vocab_size, start_id, end_id):</span><br><span class="line">        super(Seq2SeqDecoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.lstm_cell = nn.LSTMCell(embedding_dim, hidden_size) # cell 是单步完成，[bs,embedding_dim]</span><br><span class="line">        self.proj_layer = nn.Linear(hidden_size * 2, num_classes) # [context_vector+decode_state_t,num_classes]</span><br><span class="line">        self.attention_mechanism = Seq2SeqAttentionMechanism()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.embedding_table = nn.Embedding(target_vocab_size, embedding_dim)</span><br><span class="line">        self.start_id = start_id # 会传入一个真实的target作为输入，可以进行第一个位置的预测</span><br><span class="line">        self.end_id = end_id # 能够判断序列的截止位置</span><br><span class="line"></span><br><span class="line">    def forward(self, shifted_target_ids, encoder_states):</span><br><span class="line">        # 训练阶段调用，teacher-force mode</span><br><span class="line">        # shifted_target_ids 真实的序列id</span><br><span class="line">        shifted_target = self.embedding_table(shifted_target_ids)</span><br><span class="line"></span><br><span class="line">        bs, target_length, embedding_dim = shifted_target.shape</span><br><span class="line">        bs, source_length, hidden_size = encoder_states.shape</span><br><span class="line"></span><br><span class="line">        logits = torch.zeros(bs, target_length, self.num_classes)</span><br><span class="line">        probs = torch.zeros(bs, target_length, source_length)</span><br><span class="line"></span><br><span class="line">        for t in range(target_length):</span><br><span class="line">            decoder_input_t = shifted_target[:, t, :]  # [bs,embedding_dim]</span><br><span class="line">            if t == 0:</span><br><span class="line">                h_t, c_t = self.lstm_cell(decoder_input_t)</span><br><span class="line">            else:</span><br><span class="line">                h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))</span><br><span class="line"></span><br><span class="line">            attn_prob, context = self.attention_mechanism(h_t, encoder_states) # [decoder_state_t, encoder_states]</span><br><span class="line">            # context: [bs,hidden_size] h_t: [bs,hidden_size]</span><br><span class="line">            decoder_output = torch.cat((context, h_t), -1)</span><br><span class="line">            logits[:, t, :] = self.proj_layer(decoder_output)</span><br><span class="line">            probs[:, t, :] = attn_prob # [bs,source_length]</span><br><span class="line"></span><br><span class="line">        return probs, logits</span><br><span class="line"></span><br><span class="line">    def inference(self, encoder_states):</span><br><span class="line">        # 推理阶段使用</span><br><span class="line">        target_id = self.start_id</span><br><span class="line">        h_t = None</span><br><span class="line">        result = []</span><br><span class="line"></span><br><span class="line">        while True:</span><br><span class="line">            decoder_input_t = self.embedding_table(target_id)</span><br><span class="line">            if h_t is None:</span><br><span class="line">                h_t, c_t = self.lstm_cell(decoder_input_t)</span><br><span class="line">            else:</span><br><span class="line">                h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))</span><br><span class="line"></span><br><span class="line">            attn_prob, context = self.attention_mechanism(h_t, encoder_states)</span><br><span class="line"></span><br><span class="line">            decoder_output = torch.cat((context, h_t), -1)</span><br><span class="line">            logits = self.proj_layer(decoder_output)</span><br><span class="line"></span><br><span class="line">            target_id = torch.argmax(logits, -1)</span><br><span class="line">            result.append(target_id)</span><br><span class="line"></span><br><span class="line">            if torch.any(target_id == self.end_id): # 解码终止条件,在构造训练数据的时候需要在每个句子后面添加一个字符用做end id</span><br><span class="line">                print(&quot;start coding!&quot;)</span><br><span class="line">                break</span><br><span class="line">        predict_ids = torch.stack(result, dim=0)</span><br><span class="line"></span><br><span class="line">        return predict_ids</span><br></pre></td></tr></table></figure>
<h2 id="model">3.4 Model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_size, num_classes, source_vocab_size, target_vocab_size, start_id, end_id</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.encoder = Seq2SeqEncoder(embedding_dim, hidden_size, source_vocab_size)</span><br><span class="line">        self.decoder = Seq2SeqDecoder(embedding_dim, hidden_size, num_classes, target_vocab_size, start_id, end_id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_sequence_ids, shifted_target_ids</span>):</span><br><span class="line">        <span class="comment"># 训练阶段</span></span><br><span class="line">        encoder_states, final_h = self.encoder(input_sequence_ids)</span><br><span class="line">        probs, logits = self.decoder(shifted_target_ids, encoder_states)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> probs, logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">self,predict_ids,input_sequence_ids</span>):</span><br><span class="line">        <span class="comment"># 推理阶段</span></span><br><span class="line">        encoder_states, final_h = self.encoder(input_sequence_ids)</span><br><span class="line">        probs, logits = self.decoder(predict_ids, encoder_states)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> probs, logits</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304171935294.png" alt="seq2seq代码编写技巧" /><figcaption aria-hidden="true">seq2seq代码编写技巧</figcaption>
</figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/86ae38c6.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络7-SwinTransformer" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/daaec8c8.html">用pytorch实现基础网络7-SwinTransformer</a>
    </h2>
  

        
		
		  <a href="/post/daaec8c8.html" class="archive-article-date">
  	<time datetime="2023-04-15T14:34:26.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-15</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">2.9k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">14min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304152245800.png" alt="image-20230415224534491" /><figcaption aria-hidden="true">image-20230415224534491</figcaption>
</figure>
<p>将transformer直接使用到CV领域遇到的问题：</p>
<ul>
<li>尺度问题：同一张图中代表不用语义信息的block尺度差距很大</li>
<li>处理像素问题的计算成本大(形成的序列很长)</li>
</ul>
<p>本文提出一种hierarchical transformer,主要使用了shifted windows</p>
<ul>
<li>自注意力机制是在这个窗口中计算的，序列长度大大降低</li>
<li>通过shifting这个操作能够让相邻的两个窗口之间产生交互，上下层之间有了cross-window-connection</li>
</ul>
<p>image classification/object detection/semantic segmentation</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304152255423.png" alt="image-20230415225520894" /><figcaption aria-hidden="true">image-20230415225520894</figcaption>
</figure>
<h1 id="如何基于图片生成-patch-embedding">1.如何基于图片生成 patch embedding?</h1>
<h2 id="方法一">方法一</h2>
<ul>
<li>基于 pytorch unfold 的API将图片进行分块，也就是模仿卷积的思路，设置kernel_size=patch_size，得到分块后的图片</li>
<li>得到格式为[bs,num_patch,patch_depth]的张量</li>
<li>将张量与形状为[patch_depth,model_dim_C]的权重矩阵进行乘法操作，即可得到形状为[bs,num_patch,model_dim_C]的path_embedding ## 方法二</li>
<li>patch_depth等于input_channel*patch_size*patch_size</li>
<li>model_dim_C相当于二维卷积的输出通道数目</li>
<li>将形状为[patch_depth,model_dim_C]的权重矩阵转换为[model_dim_C,input_channel,patch_size,path_size]的卷积核</li>
<li>调用pytorch中的conv2d API得到卷积的输出张量，形状为[bs,output_channel,height,width]</li>
<li>转换为[bs,num_patch,model_dim_C]的格式，即为patch embedding</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image2emb_naive</span>(<span class="params">image,patch_size,weight</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;直观方法实现patch_embedding&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># image shape: bs*channel*h*w</span></span><br><span class="line">    patch = F.unfold(image,kernel_size=(patch_size,patch_size),</span><br><span class="line">                    stride=(patch_size,patch_size)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line">    patch_embedding = patch @ weight</span><br><span class="line">    <span class="keyword">return</span> patch_embedding</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image2emb_conv</span>(<span class="params">image,kernel,stride</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;基于二维卷积来实现patch_embedding，embedding的维度就是卷积的输出通道数&quot;&quot;&quot;</span></span><br><span class="line">    conv_output = F.conv2d(image,kernel,stride=stride) <span class="comment">#[bs,oc,oh.ow]</span></span><br><span class="line">    bs, oc, oh, ow = conv_output.shape</span><br><span class="line">    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> patch_embedding</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<h1 id="如何构建mhsa并计算其复杂度">2.如何构建MHSA并计算其复杂度？</h1>
<ul>
<li>基于输入x进行三个映射分别得到q,k,v
<ul>
<li>此步复杂度为<span class="math inline">\(3LC^2\)</span>,其中<span class="math inline">\(L\)</span>为序列长度，<span class="math inline">\(C\)</span>为特征大小<br />
</li>
<li><span class="math inline">\(q,k,v\)</span>维度:<span class="math inline">\([L,C]\)</span></li>
</ul></li>
<li>将q,k,v拆分成多头的形式，注意这里的多头各自计算不受影响，所以可以与bs维度进行统一看待(c-&gt;c/n，把embedding看成一个个小的embedding)</li>
<li>计算<span class="math inline">\(qk^T\)</span>,并考虑可能的掩码，即让无效的两两位置之间的能量为负无穷，掩码在shift window MHSA中会需要，而在window MHSA中暂不需要
<ul>
<li><span class="math inline">\(attn\_prob=\frac{q\times k^T}{\sqrt{d}}\)</span></li>
<li>此步复杂度为<span class="math inline">\(L^2C\)</span></li>
</ul></li>
<li>计算概率值与<span class="math inline">\(v\)</span>的乘积
<ul>
<li>概率维度:<span class="math inline">\([L,L]\)</span>;<span class="math inline">\(v\)</span>维度:<span class="math inline">\([L,C]\)</span></li>
<li>此步复杂度为<span class="math inline">\(L^2C\)</span></li>
</ul></li>
<li>对输出进行再次映射
<ul>
<li>映射矩阵:<span class="math inline">\([C,C]\)</span>;输出矩阵:<span class="math inline">\([L,C]\)</span></li>
<li>此步复杂度为<span class="math inline">\(LC^2\)</span></li>
</ul></li>
<li>总体复杂度为<span class="math inline">\(4LC^2+2L^2C\)</span></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadSelfAttention</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model_dim,num_head</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiHeadSelfAttention,self).__init__()</span><br><span class="line">        self.num_head = num_head</span><br><span class="line">        </span><br><span class="line">        self.proj_linear_layer = nn.Linear(model_dim,<span class="number">3</span>*model_dim)</span><br><span class="line">        self.final_linear_layer = nn.Linear(model_dim,model_dim)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span>,additive_mask = <span class="literal">None</span></span>):</span><br><span class="line">        bs, seqlen, model_dim = <span class="built_in">input</span>.shape</span><br><span class="line">        num_head = self.num_head</span><br><span class="line">        head_dim = model_dim // num_head</span><br><span class="line">        </span><br><span class="line">        proj_output = self.proj_linear_layer(<span class="built_in">input</span>)</span><br><span class="line">        q,k,v = proj_output.chunk(<span class="number">3</span>,dim=-<span class="number">1</span>) <span class="comment"># [bs,seqlen,seqlen,model_dim]</span></span><br><span class="line">        </span><br><span class="line">        q = q.reshape(bs,seqlen,num_head,head_dim).transpose(<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># [bs,num_head,seqlen,head_dim]</span></span><br><span class="line">        q = q.reshape(bs*num_head,seqlen,head_dim)</span><br><span class="line">        </span><br><span class="line">        k = k.reshape(bs,seqlen,num_head,head_dim).transpose(<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># [bs,num_head,seqlen,head_dim]</span></span><br><span class="line">        k = k.reshape(bs*num_head,seqlen,head_dim)</span><br><span class="line">        </span><br><span class="line">        v = v.reshape(bs,seqlen,num_head,head_dim).transpose(<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># [bs,num_head,seqlen,head_dim]</span></span><br><span class="line">        v = v.reshape(bs*num_head,seqlen,head_dim) </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> additive_mask <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            attn_prob = F.softmax(torch.bmm(q,k.transpose(-<span class="number">2</span>,-<span class="number">1</span>))/math.sqrt(head_dim),dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            additive_mask = additive_mask.tile((num_head,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">            attn_prob = F.softmax(bs,num_head,seqlen,head_dim).transpose(<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># [bs*num_head,seqlen,seqlen]</span></span><br><span class="line">            </span><br><span class="line">        output = torch.bmm(attn_prob,v) <span class="comment"># [bs*num_head,seqlen,head_dim]</span></span><br><span class="line">        output = output.reshape(bs,num_head,seqlen,head_dim).transpose(<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># [bs,seqlen,num_head,head_dim]</span></span><br><span class="line">        output = output.reshape(bs,seqlen,model_dim)</span><br><span class="line">        </span><br><span class="line">        output = self.final_linear_layer(output)</span><br><span class="line">        <span class="keyword">return</span> attn_prob,ouput</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="如何构建window-mhsa并计算其复杂度">3.如何构建Window MHSA并计算其复杂度？</h1>
<ul>
<li><p>将patch组成的图片进一步划分成一个个更大的window</p>
<ul>
<li>首先需要将三维的patch embedding转换成图片格式 [bs,channel,h,w] num_patch = h*w</li>
<li>使用unfold来将patch换分成window</li>
</ul></li>
<li><p>在每个window内部计算MHSA</p>
<ul>
<li><p>window数目其实可以跟batchsize进行统一对待，因为window与window之间没有交互计算</p></li>
<li><p>关于计算复杂度</p>
<ul>
<li><p>假设窗的边长为<span class="math inline">\(W\)</span>，起那么计算每个窗的总体复杂度是<span class="math inline">\(4W^2C^2+2W^4C\)</span></p></li>
<li><p>假设patch的总数目为<span class="math inline">\(L\)</span>,那么窗的数目为<span class="math inline">\(\frac{L}{W^2}\)</span></p></li>
<li><p>因此，W-HMSA的总体复杂度为<span class="math inline">\((4W^2C^2+2W^4C)\times\frac{L}{W^2} = 4LC^2+2LW^2C\)</span></p></li>
</ul></li>
<li><p>此处不需要mask</p></li>
<li><p>将计算结果转换成window的四维张量形式</p></li>
</ul></li>
<li><p>复杂度对比</p>
<ul>
<li>MHSA:<span class="math inline">\(4LC^2+2L^2C\)</span></li>
<li>W-MHSA:<span class="math inline">\(4LC^2+2LW^2C\)</span></li>
</ul>
<p>​</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window_multi_head_self_attention</span>(<span class="params">patch_embedding,mhsa,window_size=<span class="number">4</span>,num_head=<span class="number">2</span></span>):</span><br><span class="line">    num_patch_in_window = widow_size * widow_size</span><br><span class="line">    bs, num_patch, patch_depth = patch_embedding.shape</span><br><span class="line">    image_height = image_width = <span class="built_in">int</span>(math.sqrt(num_patch))</span><br><span class="line">    </span><br><span class="line">    patch_embedding = patch_embedding,transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line">    patch = patch_embedding.reshape(bs,patch_depth,image_height,image_width)</span><br><span class="line">    window = F.unfold(patch,kernel_size=(widow_size,widow_size),</span><br><span class="line">                     stride=(window_size,window_size)).transpose(-<span class="number">1</span>,-<span class="number">2</span>) <span class="comment"># [bs,num_window,window_depth]</span></span><br><span class="line">    bs,num_window,patch_depth_times_num_patch_in_window = window.shape</span><br><span class="line">    window = window.reshape(bs*num_window,patch_depth,num_patch_in_window).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    attn_prob, output = mhsa(window) <span class="comment"># [bs*num_window,num_patch_in_window,patch_depth]</span></span><br><span class="line">    output = output.reshape(bs,num_window,num_patch_in_window,patch_depth)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h1 id="如何构建shift-window-mhsa及其mask">4.如何构建Shift Window MHSA及其Mask？</h1>
<ul>
<li>将上一步的W-MHSA的结果转换成图片格式</li>
<li>假设已经做了新的window划分，这一步叫做shift-window</li>
<li>为了保持window数目不变从而有高效的计算，需要将图片的patch往左和往上各自滑动半个窗口大小的步长，保持patch所属window类型不变</li>
<li>将图片patch还原成window的数据格式</li>
<li>由于cycle shift后，每个window虽然形状规整，但部分window中存在原本不属于同一个窗口的patch，所以需要生成mask</li>
<li>如何生成mask？
<ul>
<li>首先构建一个shift-window的patch所属的window类别矩阵</li>
<li>对该矩阵进行同样的往左往上各自滑动半个窗口大小的步长的操作</li>
<li>通过unfold操作得到[bs,num_window,num_patch_in_window]形状的类别矩阵</li>
<li>对该矩阵进行扩维成[bs,num_window,num_patch_in_window,1]</li>
<li>将该矩阵与其转置矩阵进行作差，得到同类关系矩阵(为0的位置上的patch属于同类，否则属于不同类)</li>
<li>对同类关系矩阵中非零的位置用负无穷数进行填充，对于零的位置用0去填充，这样就构建好了MHSA所需要的mask</li>
<li>此mask的形状为[bs,num_window,num_patch_in_window,num_patch_in_window]</li>
</ul></li>
<li>将window转换成三维的格式，[bs*num_window,num_patch_in_window,patch_depth]</li>
<li>将三维格式的特征连同mask一起送入MHSA中计算得到注意力输出</li>
<li>将注意力输出转换成图片patch格式，[bs,num_window,num_patch_in_window,patch_depth]</li>
<li>为了恢复位置，需要将图片的patch往右和往下各自滑动半个窗口大小的步长，至此，SW-MHSA计算完毕</li>
</ul>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/note/other/image-20230416152318837.png" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个辅助函数，window2image，也就是将transformer block的结构转换成图片的形式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window2image</span>(<span class="params">msa_output</span>):</span><br><span class="line">    bs,num_window,num_patch_in_window,patch_depth = msa_output.shape</span><br><span class="line">    window_size = <span class="built_in">int</span>(math.sqrt(num_patch_in_window))</span><br><span class="line">    image_height = <span class="built_in">int</span>(math.sqrt(num_window)) * window_size</span><br><span class="line">    image_width = image_height</span><br><span class="line">    </span><br><span class="line">    msa_output = msa_output.reshape(bs,<span class="built_in">int</span>(math.sqrt(num_window)),</span><br><span class="line">                                       <span class="built_in">int</span>(math.sqrt(num_window)),</span><br><span class="line">                                       window_size,</span><br><span class="line">                                       window_size,</span><br><span class="line">                                       patch_depth)</span><br><span class="line">    msa_output = msa_output.transpose(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">    image = msa_output.reshape(bs,image_height*image_width,patch_depth)</span><br><span class="line">    image = image.transpose(-<span class="number">1</span>,-<span class="number">2</span>).reshape(bs,patch_depth,image_height,image_width)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义辅助函数 shift_window，即高效计算sw-msa</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shift_window</span>(<span class="params">w_msa_output,window_size,shift_size,generate_mask=<span class="literal">False</span></span>): <span class="comment"># 只有在正向的时候才会 shift</span></span><br><span class="line">    bs,num_window,num_patch_in_window,patch_depth = w_msa_output.shape</span><br><span class="line">    </span><br><span class="line">    w_msa_output = window2image(w_msa_output) <span class="comment"># [bs,depth,h,w]</span></span><br><span class="line">    bs,patch_depth,image_height,image_width = w_msa_output.shape</span><br><span class="line">    </span><br><span class="line">    rolled_w_msa_output = torch.roll(w_msa_output,shifts=(shift_size,shift_size),dim=(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    shifted_w_msa_input = rolled_w_msa_output.reshape(bs,patch_depth,</span><br><span class="line">                                                     <span class="built_in">int</span>(math.sqrt(num_window)),</span><br><span class="line">                                                     window_size,</span><br><span class="line">                                                     <span class="built_in">int</span>(math.sqrt(num_window)),</span><br><span class="line">                                                     window_size)</span><br><span class="line">    </span><br><span class="line">    shifted_w_msa_input = shifted_w_msa_input.transpose(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">    shifted_w_msa_input = shifted_w_msa_input.reshape(bs,patch_depth,num_window*num_patch_in_window)</span><br><span class="line">    shifted_w_msa_input = shifted_w_msa_input.transpose(-<span class="number">1</span>,-<span class="number">2</span>) <span class="comment"># [bs,num_window*num_patch_in_window,patch_depth]</span></span><br><span class="line">    shifted_window = shifted_w_msa_input.reshape(bs,num_window,num_patch_in_window,patch_depth)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> generate_mask:</span><br><span class="line">        additive_mask = build_mask_for_shifted_wmsa(bs,image_height,image_width,window_size) <span class="comment"># [bs,num_window,num_patch_in_windows,num_patch_in_windows]</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        additive_mask = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> shifted_window, additive_mask</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建shift window multi-head attention mask</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_mask_for_shifted_wmsa</span>(<span class="params">batch_size,image_height,image_width,window_size</span>):</span><br><span class="line">    index_metrix = torch.zeros(image_height,image_width)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(image_height):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(image_width):</span><br><span class="line">            row_times = (i + window_size // <span class="number">2</span>) // window_size</span><br><span class="line">            col_times = (j + window_size // <span class="number">2</span>) // window_size</span><br><span class="line">            index_metrix[i,j] = row_times * (image_height/window_size) + col_times + <span class="number">1</span></span><br><span class="line">    rolled_index_matrix = torch.roll(index_metrix,shifts=(-window_size//<span class="number">2</span>,-window_size//<span class="number">2</span>),dims=(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    rolled_index_matrix = rolled_index_matrix.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>) <span class="comment"># [bs,ch,h,w]</span></span><br><span class="line">    </span><br><span class="line">    c = F.unfold(rolled_index_matrix,kernel_size=(window_size,window_size),</span><br><span class="line">                stride=(window_size,window_size)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    c = c.tile(batch_size,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># [bs.num_window,num_patch_in_window]</span></span><br><span class="line">    </span><br><span class="line">    bs, num_window,num_patch_in_window = c.shape</span><br><span class="line">    </span><br><span class="line">    c1 = c.unsqueeze(-<span class="number">1</span>) <span class="comment"># [bs,num_window,num_patch_in_windows,1]</span></span><br><span class="line">    c2 = (c1-c1.transpose(-<span class="number">1</span>,-<span class="number">2</span>) == -<span class="number">0</span>) <span class="comment"># [bs,num_window,num_patch_in_windows,num_patch_in_windows]</span></span><br><span class="line">    valid_matrix = c2.to(torch.float32)</span><br><span class="line">    additive_mask = (<span class="number">1</span> - valid_matrix) * (-<span class="number">1e-9</span>) </span><br><span class="line">    </span><br><span class="line">    additive_mask = additive_mask.reshape(bs*num_window,num_patch_in_window,num_patch_in_window)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> additive_mask</span><br><span class="line">            </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shift_window_multi_head_self_attention</span>(<span class="params">w_msa_output,mhsa,window_size=<span class="number">4</span>,num_head=<span class="number">2</span></span>):</span><br><span class="line">    bs, num_window, num_patch_in_window, patch_depth = w_msa_output.shape</span><br><span class="line">    </span><br><span class="line">    shifted_w_msa_input, additive_mask = shift_window(w_msa_output,window_size,</span><br><span class="line">                                                      shift_size=(-window_size//<span class="number">2</span>),</span><br><span class="line">                                                      generate_mask=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(shifted_w_msa_input.shape) <span class="comment"># [bs,num_window,num_patch_in_window,patch_depth]</span></span><br><span class="line">    <span class="built_in">print</span>(additive_mask.shape) <span class="comment"># [bs*num_window,num_patch_in_window,num_patch_in_window]</span></span><br><span class="line">    </span><br><span class="line">    shifted_w_msa_input = shifted_w_msa_input.reshape(bs*num_window,num_patch_in_window,patch_depth)</span><br><span class="line">    </span><br><span class="line">    attn_prob,output = mhsa(shifted_w_msa_input,additive_mask=additive_mask)</span><br><span class="line">    </span><br><span class="line">    output = output.reshape(bs,num_window,num_patch_in_window,patch_depth)</span><br><span class="line">    </span><br><span class="line">    output, _ = shift_window(output,window_size,shift_size=window_size//<span class="number">2</span>,generate_mask=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(output.shape) <span class="comment"># [bs,num_window,num_patch_in_window,patch_depth]</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h1 id="如何构建patch-merging">5.如何构建Patch Merging？</h1>
<ul>
<li>将window格式的特征转换成图片patch格式</li>
<li>利用unfold操作，按照merge_size*merge_size大小得到新的patch,形状为[bs,num_patch_new,merge_size*merge_size*patch_depth_old]</li>
<li>使用一个全连接层对depth进行降维成0.5倍，也就是从merge_size*merge_size*patch_depth_old映射到0.5*merge_size*merge_size*patch_depth_old</li>
<li>输出的是patch embedding的形状格式,[bs,num_patch,patch_depth]</li>
<li>举例说明：以merge_size=2为例，经过PatchMerging后，patch数目减少为之前的<span class="math inline">\(\frac{1}{4}\)</span>，但是depth增大为原来的2倍，而不是4倍</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchMerging</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_dim, merge_size,output_depth_scale=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PatchMerging, self).__init__()</span><br><span class="line">        self.merge_size = merge_size</span><br><span class="line">        self.model_dim = model_dim</span><br><span class="line">        self.proj_layer = nn.Linear(</span><br><span class="line">            model_dim * merge_size * merge_size,</span><br><span class="line">            <span class="built_in">int</span>(model_dim * merge_size * merge_size * output_depth_scale))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        bs, num_window, num_patch_in_window, patch_depth = <span class="built_in">input</span>.shape</span><br><span class="line">        window_size = <span class="built_in">int</span>(math.sqrt(num_patch_in_window))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">input</span> = window2image(<span class="built_in">input</span>)  <span class="comment"># [bs,patch_depth,image_h,image_w]</span></span><br><span class="line"></span><br><span class="line">        merged_window = F.unfold(<span class="built_in">input</span>, kernel_size=(self.merge_size, self.merge_size),</span><br><span class="line">                                 stride=(self.merge_size, self.merge_size)).transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line">        merged_window = self.proj_layer(merged_window)  <span class="comment"># [bs,num_patch,new_patch_depth]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> merged_window</span><br></pre></td></tr></table></figure>
<h1 id="如何构建swin-transformerblock">6.如何构建Swin TransformerBlock?</h1>
<ul>
<li>每个block包含LayerNorm，W-MHSA，MLP，SW-MHSA，残差连接等模块</li>
<li>输入是patch embedding格式</li>
<li>每个MLP包括两层，分别是4*mode_dim和mode_dim大小</li>
<li>输出的是window的数据格式，[bs,num_window,num_patch_in_window,patch_depth]</li>
<li>需要注意残差连接对数据形状的要求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model_dim,window_size,num_head</span>):</span><br><span class="line">        <span class="built_in">super</span>(SwinTransformerBlock,self).__init__()</span><br><span class="line">        self.layer_norm1 = nn.LayerNorm(model_dim)</span><br><span class="line">        self.layer_norm2 = nn.LayerNorm(model_dim)</span><br><span class="line">        self.layer_norm3 = nn.LayerNorm(model_dim)</span><br><span class="line">        self.layer_norm4 = nn.LayerNorm(model_dim)</span><br><span class="line">        </span><br><span class="line">        self.wsma_mlp1 = nn.Linear(model_dim,<span class="number">4</span>*model_dim)</span><br><span class="line">        self.wsma_mlp2 = nn.Linear(<span class="number">4</span>*model_dim,model_dim)</span><br><span class="line">        self.swsma_mlp1 = nn.Linear(model_dim,<span class="number">4</span>*model_dim)</span><br><span class="line">        self.swsma_mlp2 = nn.Linear(<span class="number">4</span>*model_dim,model_dim)</span><br><span class="line">        </span><br><span class="line">        self.mhsa1 = MultiHeadSelfAttention(model_dim,num_head)</span><br><span class="line">        self.mhsa2 = MultiHeadSelfAttention(model_dim,num_head)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        </span><br><span class="line">        bs,num_patch,patch_depth = <span class="built_in">input</span>.shape</span><br><span class="line">        </span><br><span class="line">        input1 = self.layer_norm1(<span class="built_in">input</span>)</span><br><span class="line">        w_msa_output = window_multi_head_self_attention(<span class="built_in">input</span>,self.mhsa1,window_size=<span class="number">4</span>,num_head=<span class="number">2</span>)</span><br><span class="line"><span class="comment">#         bs, num_head, num_patch_in_window, patch_depth = w_msa_output.shape </span></span><br><span class="line">        w_msa_output = <span class="built_in">input</span> + w_msa_output.reshape(bs,num_patch,patch_depth)</span><br><span class="line">        output1 = self.wsma_mlp2(self.wsma_mlp1(self.layer_norm2(w_msa_output)))</span><br><span class="line">        output1 += w_msa_output</span><br><span class="line">        </span><br><span class="line">        input2 = self.layer_norm3(input1)</span><br><span class="line">        input2 = input2.reshape(bs,num_patch,num_patch_in_window,patch_depth)</span><br><span class="line">        sw_msa_output = shift_window_multi_head_self_attention(input2,self.mhsa2,window_size=<span class="number">4</span>,num_head=<span class="number">2</span>)</span><br><span class="line">        sw_msa_output = output1 + sw_msa_output.reshape(bs,num_patch,patch_depth)</span><br><span class="line">        output2 = self.swsma_mlp2(self.swsma_mlp1(self.layer_norm4(sw_msa_output)))</span><br><span class="line">        output2 += sw_msa_output</span><br><span class="line">        </span><br><span class="line">        output2 = output2.reshape(bs,num_patch,num_patch_in_window.patch_depth)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="如何构建swintransformermodel">7.如何构建SwinTransformerModel？</h1>
<ul>
<li>输入是图片</li>
<li>首先对图片进行分块并得到Patch embedding</li>
<li>经过第一个stage</li>
<li>进行patch merging,在进行第二个stage</li>
<li>以此类推...</li>
<li>对最后一个block的输出转换成patch embedding的格式[bs,num_patch_depth]</li>
<li>对patch embedding在时间维度进行平均池化，并映射到分类层得到分类的logits</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_image_channel=<span class="number">3</span>, patch_size=<span class="number">4</span>, model_dim_C=<span class="number">8</span>, num_classes=<span class="number">10</span>,</span></span><br><span class="line"><span class="params">                 window_size=<span class="number">4</span>, num_head=<span class="number">2</span>, merge_size=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SwinTransformerModel, self).__init__()</span><br><span class="line">        patch_depth = patch_size * patch_size * input_image_channel</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.model_dim_C = model_dim_C</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        self.patch_embedding_weight = nn.Parameter(torch.randn(patch_depth, model_dim_C))  <span class="comment"># 模型可训练的一部分参数</span></span><br><span class="line"></span><br><span class="line">        self.block1 = SwinTransformerBlock(model_dim_C, window_size, num_head)</span><br><span class="line">        self.block2 = SwinTransformerBlock(model_dim_C * <span class="number">2</span>, window_size, num_head)</span><br><span class="line">        self.block3 = SwinTransformerBlock(model_dim_C * <span class="number">4</span>, window_size, num_head)</span><br><span class="line">        self.block4 = SwinTransformerBlock(model_dim_C * <span class="number">8</span>, window_size, num_head)</span><br><span class="line"></span><br><span class="line">        self.patch_merging1 = PatchMerging(model_dim_C , merge_size)</span><br><span class="line">        self.patch_merging2 = PatchMerging(model_dim_C * <span class="number">2</span>, merge_size)</span><br><span class="line">        self.patch_merging3 = PatchMerging(model_dim_C * <span class="number">4</span>, merge_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分类</span></span><br><span class="line">        self.final_layer = nn.Linear(model_dim_C * <span class="number">8</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        patch_embedding_naive = image2emb_naive(image, self.patch_size, self.patch_embedding_weight)</span><br><span class="line">        <span class="built_in">print</span>(patch_embedding_naive.shape)</span><br><span class="line"></span><br><span class="line">        kernel = self.patch_embedding_weight.transpose(<span class="number">0</span>, <span class="number">1</span>).reshape((-<span class="number">1</span>, ic, patch_size, patch_size))  <span class="comment"># oc*ic*kh*kw</span></span><br><span class="line">        patch_embedding_conv = image2emb_conv(image, kernel, self.patch_size)  <span class="comment"># 二维卷积的方法得到embedding</span></span><br><span class="line">        <span class="built_in">print</span>(patch_embedding_conv.shape)</span><br><span class="line">        <span class="comment"># block1</span></span><br><span class="line">        patch_embedding = patch_embedding_naive</span><br><span class="line">        <span class="built_in">print</span>(patch_embedding.shape)</span><br><span class="line">        sw_msa_output = self.block1(patch_embedding)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;block1_output&quot;</span>, sw_msa_output.shape)  <span class="comment"># [bs,num_window,num_patch_in_window,patch_depth]</span></span><br><span class="line"></span><br><span class="line">        merged_patch1 = self.patch_merging1(sw_msa_output)</span><br><span class="line">        sw_msa_output_1 = self.block2(merged_patch1)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;block2_output&quot;</span>, sw_msa_output_1.shape)</span><br><span class="line"></span><br><span class="line">        merged_patch2 = self.patch_merging2(sw_msa_output_1)</span><br><span class="line">        sw_msa_output_2 = self.block3(merged_patch2)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;block3_output&quot;</span>, sw_msa_output_2.shape)</span><br><span class="line"></span><br><span class="line">        merged_patch3 = self.patch_merging3(sw_msa_output_2)</span><br><span class="line">        sw_msa_output_3 = self.block4(merged_patch3)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;block4_output&quot;</span>, sw_msa_output_3.shape)</span><br><span class="line"></span><br><span class="line">        bs, num_window, num_patch_in_window, patch_depth = sw_msa_output_3.shape</span><br><span class="line">        sw_msa_output_3 = sw_msa_output_3.reshape(bs, -<span class="number">1</span>, patch_depth)</span><br><span class="line"></span><br><span class="line">        pool_output = torch.mean(sw_msa_output_3, dim=<span class="number">1</span>)</span><br><span class="line">        logits = self.final_layer(pool_output)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;logits&quot;</span>,logits.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="模型测试代码">8.模型测试代码</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get parameters amount in the network</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_n_params</span>(<span class="params">model</span>):</span><br><span class="line">    pp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">list</span>(model.parameters()):</span><br><span class="line">        nn = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">list</span>(p.size()):</span><br><span class="line">            nn = nn * s</span><br><span class="line">        pp += nn</span><br><span class="line">    <span class="keyword">return</span> pp</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    bs, ic, image_h, image_w = <span class="number">4</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">256</span></span><br><span class="line">    patch_size = <span class="number">4</span></span><br><span class="line">    model_dim_C = <span class="number">8</span>  <span class="comment"># 一开始的patch embedding大小</span></span><br><span class="line">    max_num_token = <span class="number">16</span></span><br><span class="line">    num_classes = <span class="number">10</span></span><br><span class="line">    window_size = <span class="number">4</span></span><br><span class="line">    num_head = <span class="number">2</span></span><br><span class="line">    merge_size = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    patch_depth = patch_size * patch_size * ic</span><br><span class="line">    image = torch.randn(bs, ic, image_h, image_w)</span><br><span class="line"></span><br><span class="line">    model = SwinTransformerModel(ic, patch_size, model_dim_C, num_classes, window_size, num_head, merge_size)</span><br><span class="line"></span><br><span class="line">    model(image)</span><br><span class="line">    pp = get_n_params(model)</span><br><span class="line">    <span class="built_in">print</span>(pp)</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/daaec8c8.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch项目2-基于GCN(DNN)的文本分类模型(GPU)" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/ceb60e40.html">pytorch项目2-基于GCN(DNN)的文本分类模型(GPU)</a>
    </h2>
  

        
		
		  <a href="/post/ceb60e40.html" class="archive-article-date">
  	<time datetime="2023-04-15T11:19:44.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-15</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">581字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">2min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p>https://pytorch.org/tutorials/distributed/home.html</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304152009298.png" alt="image-20230415200908110" /><figcaption aria-hidden="true">image-20230415200908110</figcaption>
</figure>
<h2 id="单机单卡">1 单机单卡</h2>
<p>在 main 函数前加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    logging.warning(<span class="string">&quot;Cuda is available!&quot;</span>)</span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    logging.warning(<span class="string">&quot;Cuda is not available! Exit!&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在train函数中，第一次调用模型的地方加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.cuda() <span class="comment"># 拷贝到GPU上，模型拷贝</span></span><br></pre></td></tr></table></figure>
<p>在train函数中，每次使用到数据的地方加入(train and eval)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">token_index = token_index.cuda()  <span class="comment"># tensor cuda拷贝方法,数据拷贝</span></span><br><span class="line">target = target.cuda() <span class="comment"># 数据拷贝</span></span><br><span class="line">eval_target = eval_target.cuda()  <span class="comment"># tensor cuda拷贝方法,数据拷贝</span></span><br><span class="line">eval_token_index = eval_token_index.cuda()  <span class="comment"># 数据拷贝</span></span><br></pre></td></tr></table></figure>
<h2 id="单机多卡">2 单机多卡</h2>
<p>在 main 函数前加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    logging.warning(<span class="string">&quot;Cuda is available!&quot;</span>)</span><br><span class="line">    os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">        logging.warning(<span class="string">f&quot;find <span class="subst">&#123;torch.cuda.device_count()&#125;</span> GPUs!&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logging.warning(<span class="string">&quot;Too few GPU!&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    logging.warning(<span class="string">&quot;Cuda is not available! Exit!&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在train函数中，第一次调用模型的地方加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = nn.DataParallel(model.cuda(),device_ids=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) <span class="comment"># 拷贝到GPU上，模型拷贝,放入DataParallel</span></span><br></pre></td></tr></table></figure>
<p>在模型的保存中，修改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> step % save_step_interval == <span class="number">0</span>:</span><br><span class="line">    os.makedirs(save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    save_file = os.path.join(save_path, <span class="string">f&quot;step_<span class="subst">&#123;step&#125;</span>.pt&quot;</span>)</span><br><span class="line">    torch.save(&#123;</span><br><span class="line">		...</span><br><span class="line">        <span class="string">&quot;model_state_dict&quot;</span>: model.module.state_dict(),</span><br><span class="line">		...</span><br><span class="line">    &#125;, save_file)</span><br><span class="line">    logging.warning(<span class="string">f&quot;checkpoint has been saved in <span class="subst">&#123;save_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这种方式更加合理：</p>
<figure>
<img src="C:\Users\jyh\AppData\Roaming\Typora\typora-user-images\image-20230415211135334.png" alt="image-20230415211135334" /><figcaption aria-hidden="true">image-20230415211135334</figcaption>
</figure>
<h3 id="init_process_group">2.1 init_process_group</h3>
<p>This sets up the communication backend for distributed training (such as NCCL, Gloo, etc.) and initializes the process group.</p>
<h4 id="nccl">2.1.1 nccl</h4>
<p>https://developer.nvidia.com/nccl</p>
<h4 id="world_size">2.1.2 world_size</h4>
<p>当前节点上有多少张GPU</p>
<h4 id="local_rank">2.1.3 local_rank</h4>
<p>当前进程在某张确定的GPU卡上(因为这里采用了多线程，每个线程表示一张GPU)</p>
<h3 id="torch.cuda.set_deviceargs.local_rank">2.2 torch.cuda.set_device(args.local_rank)</h3>
<p>设定某张卡进行训练</p>
<h3 id="对模型进行包裹">2.3 对模型进行包裹</h3>
<p>类似DataParallel中的操作</p>
<h3 id="train_sampler">2.4 train_sampler</h3>
<p>https://pytorch.org/docs/stable/_modules/torch/utils/data/distributed.html#DistributedSampler</p>
<p>把dataset中的样本分配当不同的GPU上面，这是随机分配的</p>
<p>It is especially useful in <strong>conjunction</strong> with class:torch.nn.parallel.<strong>DistributedDataParallel</strong></p>
<p>每张卡上面的参数的总数量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.num_samples = math.ceil(<span class="built_in">len</span>(self.dataset) / self.num_replicas)  <span class="comment"># type: ignore[arg-<span class="built_in">type</span>]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[T_co]:</span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            <span class="comment"># deterministically shuffle based on epoch and seed</span></span><br><span class="line">            g = torch.Generator()</span><br><span class="line">            g.manual_seed(self.seed + self.epoch)  <span class="comment"># 不改变种子和epoch，顺序是相同的(显然不合理)</span></span><br><span class="line">            indices = torch.randperm(<span class="built_in">len</span>(self.dataset), generator=g).tolist()  <span class="comment"># type: </span></span><br></pre></td></tr></table></figure>
<p>显然在需要在每个训练之前对此进行修改，调用sampler.set_epoch方法，把epoch传入进来。</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304152228839.png" alt="image-20230415222851173" /><figcaption aria-hidden="true">image-20230415222851173</figcaption>
</figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">project</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/ceb60e40.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-pytorch项目1-基于GCN(DNN)的文本分类模型(CPU)" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/27f58942.html">pytorch项目1-基于GCN+DNN的文本分类模型</a>
    </h2>
  

        
		
		  <a href="/post/27f58942.html" class="archive-article-date">
  	<time datetime="2023-04-15T07:04:41.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-15</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">1.5k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">7min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <h2 id="项目介绍">1 项目介绍</h2>
<p>IMDB dataset having 50K movie reviews for natural language processing or Text analytics.</p>
<p>This is a dataset for <strong>binary</strong> sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of <strong>25,000</strong> highly polar movie reviews for training and <strong>25,000</strong> for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms.</p>
<p>代码构成：</p>
<ul>
<li>GCNN模型</li>
<li>简单版embeddingbag+DNN模型</li>
<li>yield_tokens: 对源 comment 进行分词处理</li>
<li>collate_fn： 对DataLoader所生成的mini-batch进行后处理</li>
<li>train</li>
<li>main函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data.dataloader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line"><span class="keyword">from</span> torchtext.datasets <span class="keyword">import</span> IMDB</span><br><span class="line"><span class="keyword">from</span> torchtext.datasets.imdb <span class="keyword">import</span> NUM_LINES</span><br><span class="line"><span class="keyword">from</span> torchtext.data <span class="keyword">import</span> get_tokenizer</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> build_vocab_from_iterator</span><br><span class="line"><span class="keyword">from</span> torchtext.data.functional <span class="keyword">import</span> to_map_style_dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.WARN, stream=sys.stdout,</span><br><span class="line">                    <span class="built_in">format</span>=<span class="string">&quot;%(asctime)s (%(module)s:%(lineno)d) %(levelname)s:%(message)s&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">VOCAB_SIZE = <span class="number">15000</span> <span class="comment"># 这里的统计是根据数据集进行处理后得到的</span></span><br><span class="line">train_data_iter = IMDB(root=<span class="string">&quot;.data&quot;</span>, split=<span class="string">&quot;train&quot;</span>)  <span class="comment"># Dataset类型的对象</span></span><br><span class="line">tokenizer = get_tokenizer(<span class="string">&quot;basic_english&quot;</span>) </span><br><span class="line">vocab = build_vocab_from_iterator(yield_tokens(train_data_iter, tokenizer), min_freq=<span class="number">20</span>, specials=[<span class="string">&quot;&lt;unk&gt;&quot;</span>]) <span class="comment"># 只把出现频率高于20个的词语取出来，其他的单词都变成&lt;unk&gt; # 构建词表</span></span><br><span class="line">vocab.set_default_index(<span class="number">0</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;单词表大小：<span class="subst">&#123;<span class="built_in">len</span>(vocab)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>如果长时间下载失败，建议直接在以下链接进行下载：</p>
<p>http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</p>
<p>之后把下载好的文件放在当前目录下的<code>.data</code>中</p>
<h2 id="gcnn模型">2 GCNN模型</h2>
<h3 id="介绍">2.1 介绍</h3>
<p>https://arxiv.org/pdf/1612.08083v3.pdf</p>
<p>门控卷积网络是一种将卷积网络与门控机制相结合的语言模型。使用零填充以确保未来的语境无法被观察。门控卷积层可以层次化地叠加在其他层之上。通过自适应softmax层来获取模型预测结果。</p>
<p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304151758805.png" alt="image-20230415175810671" style="zoom:67%;" /></p>
<h3 id="代码">2.2 代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocal_size=VOCAB_SIZE, embedding_dim=<span class="number">64</span>, num_class=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GCNN, self).__init__()  <span class="comment"># 对父类进行初始化</span></span><br><span class="line"></span><br><span class="line">        self.embedding_table = nn.Embedding(vocal_size, embedding_dim)</span><br><span class="line">        nn.init.xavier_uniform_(self.embedding_table.weight)</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;xavier_uniform的出现是为了训练过程中前后的方差稳定问题，正确的初始化有利于训练的稳定；</span></span><br><span class="line"><span class="string">        Xavier初始化表明，对于每⼀层，输出的⽅差不受输⼊数量的影响，任何梯度的⽅差不受输出数量的影响。&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.conv_A_1 = nn.Conv1d(embedding_dim, <span class="number">64</span>, <span class="number">15</span>, stride=<span class="number">7</span>)  <span class="comment"># input_dim,output_dim,kernel_Size</span></span><br><span class="line">        self.conv_B_1 = nn.Conv1d(embedding_dim, <span class="number">64</span>, <span class="number">15</span>, stride=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">        self.conv_A_2 = nn.Conv1d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">15</span>, stride=<span class="number">7</span>)</span><br><span class="line">        self.conv_B_2 = nn.Conv1d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">15</span>, stride=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">        self.output_linear1 = nn.Linear(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.output_linear2 = nn.Linear(<span class="number">128</span>, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, word_index</span>):</span><br><span class="line">        <span class="comment"># 定义GCN网络的算子操作流程，基于句子单词ID输入得到分类logits输出</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1.通过word_index得到word_embedding</span></span><br><span class="line">        <span class="comment"># word_index shape: [bs,max_seq_len]</span></span><br><span class="line"></span><br><span class="line">        word_embedding = self.embedding_table(word_index)  <span class="comment"># [bs,max_seq_len,embedding_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.编写第一层ID门卷积模块</span></span><br><span class="line">        word_embedding = word_embedding.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [bs,embedding_dim,max_seq_len]</span></span><br><span class="line">        A = self.conv_A_1(word_embedding)</span><br><span class="line">        B = self.conv_B_1(word_embedding)</span><br><span class="line">        H = A * torch.sigmoid(B)  <span class="comment"># [bs,64,max_seq_len]</span></span><br><span class="line"></span><br><span class="line">        A = self.conv_A_2(H)</span><br><span class="line">        B = self.conv_B_2(H)</span><br><span class="line">        H = A * torch.sigmoid(B)  <span class="comment"># [bs,64,max_seq_len]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.池化并进过全连接层</span></span><br><span class="line">        pool_output = torch.mean(H, dim=-<span class="number">1</span>)  <span class="comment"># 平均池化 得到 [bs,64]</span></span><br><span class="line">        linear1_output = self.output_linear1(pool_output)</span><br><span class="line">        logits = self.output_linear2(linear1_output)  <span class="comment"># [bs,2]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<h2 id="简单版embeddingbagdnn模型">3 简单版embeddingbag+DNN模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextClassificationModel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size=VOCAB_SIZE, embed_dim=<span class="number">64</span>, num_class=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TextClassificationModel, self).__init__()</span><br><span class="line">        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=<span class="literal">False</span>)</span><br><span class="line">        self.fc = nn.Linear(embed_dim, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, token_index</span>):</span><br><span class="line">        embedded = self.embedding(token_index)  <span class="comment"># shape: [bs,embedding_dim]</span></span><br><span class="line">        <span class="keyword">return</span> self.fc(embedded)</span><br></pre></td></tr></table></figure>
<p>通过embeddingbag可以省略平均池化层操作，变得更加简单</p>
<figure>
<img src="https://jamesmccaffrey.files.wordpress.com/2021/03/regular_embedding_vs_embedding_bag_diagram.jpg?w=1024" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="yield_tokens">4 yield_tokens</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">yield_tokens</span>(<span class="params">train_data_iter, tokenizer</span>):</span><br><span class="line">    <span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_iter):</span><br><span class="line">        label, comment = sample</span><br><span class="line">        <span class="keyword">yield</span> tokenizer(comment)  <span class="comment"># 把一句话转换成一个个token的列表</span></span><br></pre></td></tr></table></figure>
<h2 id="collate_fn">5 collate_fn</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>): </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;mini-batch 中最重要的就是对同一个批次内的数据进行统一处理，比如某些句子很短，需要padding，这样才能进行batch操作&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;对dataloader所生成的mini-batch进行后处理&quot;&quot;&quot;</span></span><br><span class="line">    target = []</span><br><span class="line">    token_index = []</span><br><span class="line">    max_length = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, (label, comment) <span class="keyword">in</span> <span class="built_in">enumerate</span>(batch):</span><br><span class="line">        tokens = tokenizer(comment)</span><br><span class="line">        token_index.append(vocab(tokens))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(tokens) &gt; max_length:</span><br><span class="line">            max_length = <span class="built_in">len</span>(tokens)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> label == <span class="string">&quot;pos&quot;</span>:</span><br><span class="line">            target.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target.append(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    token_index = [index + [<span class="number">0</span>] * (max_length - <span class="built_in">len</span>(index)) <span class="keyword">for</span> index <span class="keyword">in</span> token_index]</span><br><span class="line">    <span class="keyword">return</span> (torch.tensor(target).to(torch.int64), torch.tensor((token_index)).to(torch.int32))  <span class="comment"># target：pos/neg token_index</span></span><br></pre></td></tr></table></figure>
<h2 id="train">6 train</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">train_data_loader, eval_data_loader, model, optimizer, num_epoch, log_step_interval, save_step_interval,</span></span><br><span class="line"><span class="params">          eval_step_interval, save_path, resume=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;此处的data_loader是map-style dataset&quot;&quot;&quot;</span></span><br><span class="line">    start_epoch = <span class="number">0</span></span><br><span class="line">    start_step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> resume != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="comment"># 加载之前训练过的模型的参数文件</span></span><br><span class="line">        logging.warning(<span class="string">f&quot;loading from <span class="subst">&#123;resume&#125;</span>&quot;</span>)</span><br><span class="line">        checkpoint = torch.load(resume)</span><br><span class="line">        model.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])</span><br><span class="line">        start_epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line">        start_step = checkpoint[<span class="string">&#x27;step&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch_index <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, num_epoch):</span><br><span class="line">        ema_loss = <span class="number">0.</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;https://www.investopedia.com/terms/e/ema.asp&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        num_bathes = <span class="built_in">len</span>(train_data_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> batch_index, (target, token_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_loader):</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            step = num_bathes * epoch_index + batch_index + <span class="number">1</span></span><br><span class="line">            logits = model(token_index)</span><br><span class="line">            bce_loss = F.binary_cross_entropy(torch.sigmoid(logits),</span><br><span class="line">                                              F.one_hot(target, num_classes=<span class="number">2</span>).to(torch.float32))  <span class="comment"># 维度需要相同，把target转换</span></span><br><span class="line">            ema_loss = <span class="number">0.9</span> * ema_loss + <span class="number">0.1</span> * bce_loss  <span class="comment"># 指数平均loss</span></span><br><span class="line">            bce_loss.backward()  <span class="comment"># 梯度回传</span></span><br><span class="line">            nn.utils.clip_grad_norm(model.parameters(), <span class="number">0.1</span>)</span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;https://blog.csdn.net/Mikeyboi/article/details/119522689&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> step % log_step_interval == <span class="number">0</span>:</span><br><span class="line">                logging.warning(</span><br><span class="line">                    <span class="string">f&quot;epoch_index:<span class="subst">&#123;epoch_index&#125;</span>,batch_index:<span class="subst">&#123;batch_index&#125;</span>,ema_loss:<span class="subst">&#123;ema_loss.item()&#125;</span>&quot;</span>)  <span class="comment"># 避免使用张量的形式打印，而是使用python格式，防止印象性能</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> step % save_step_interval == <span class="number">0</span>:</span><br><span class="line">                os.makedirs(save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line">                save_file = os.path.join(save_path, <span class="string">f&quot;step_<span class="subst">&#123;step&#125;</span>.pt&quot;</span>)</span><br><span class="line">                torch.save(&#123;</span><br><span class="line">                    <span class="string">&quot;epoch&quot;</span>: epoch_index,</span><br><span class="line">                    <span class="string">&quot;step&quot;</span>: step,</span><br><span class="line">                    <span class="string">&quot;model_state_dict&quot;</span>: model.state_dict(),</span><br><span class="line">                    <span class="string">&quot;optimizer_state_dict&quot;</span>: optimizer.state_dict(),</span><br><span class="line">                    <span class="string">&quot;loss&quot;</span>: bce_loss</span><br><span class="line">                &#125;, save_file)</span><br><span class="line">                logging.warning(<span class="string">f&quot;checkpoint has been saved in <span class="subst">&#123;save_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> step % eval_step_interval == <span class="number">0</span>:</span><br><span class="line">                logging.warning(<span class="string">&quot;start to do evaluation...&quot;</span>)</span><br><span class="line">                model.<span class="built_in">eval</span>()  <span class="comment"># evaluation ,only forward calculation</span></span><br><span class="line">                eval_ema_loss = <span class="number">0</span></span><br><span class="line">                total_acc_account = <span class="number">0</span></span><br><span class="line">                total_account = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> eval_batch_index, (eval_target, eval_token_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(eval_data_loader):</span><br><span class="line">                    total_account += eval_target.shape[<span class="number">0</span>]</span><br><span class="line">                    eval_logits = model(eval_token_index)</span><br><span class="line">                    total_acc_account += (torch.argmax(eval_logits, dim=-<span class="number">1</span>) == eval_target).<span class="built_in">sum</span>().item()</span><br><span class="line">                    eval_bce_loss = F.binary_cross_entropy(torch.sigmoid(logits),</span><br><span class="line">                                                           F.one_hot(target, num_classes=<span class="number">2</span>).to(torch.float32))</span><br><span class="line">                    eval_ema_loss = <span class="number">0.9</span> * eval_ema_loss + <span class="number">0.1</span> * eval_bce_loss  <span class="comment"># 指数平均loss</span></span><br><span class="line">                    acc = total_acc_account / total_account  <span class="comment"># 精确度：一样的次数/总次数</span></span><br><span class="line">                logging.warning(</span><br><span class="line">                    <span class="string">f&quot;eval_ema_loss:<span class="subst">&#123;eval_ema_loss.item()&#125;</span>,eval_acc:<span class="subst">&#123;acc.item()&#125;</span>&quot;</span>)</span><br><span class="line">                model.train()</span><br></pre></td></tr></table></figure>
<h2 id="main">7 main</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = GCNN()</span><br><span class="line">    <span class="comment"># model = TextClassificationModel()</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型总参数&quot;</span>, <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()))</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    train_data_iter = IMDB(root=<span class="string">&quot;.data&quot;</span>, split=<span class="string">&quot;train&quot;</span>)  <span class="comment"># Dataset类型的对象</span></span><br><span class="line">    train_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(train_data_iter), batch_size=BATCH_SIZE,</span><br><span class="line">                                                    collate_fn=collate_fn, shuffle=<span class="literal">True</span>)</span><br><span class="line">    eval_data_iter = IMDB(root=<span class="string">&quot;.data&quot;</span>, split=<span class="string">&quot;test&quot;</span>)  <span class="comment"># Dataset类型的对象</span></span><br><span class="line">    eval_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(eval_data_iter), batch_size=<span class="number">8</span>,</span><br><span class="line">                                                   collate_fn=collate_fn) <span class="comment"># 变成map_style </span></span><br><span class="line">    resume = <span class="string">&#x27;F:\study\code\pytorch\logs_imdb_text_classification\step_500.pt&#x27;</span></span><br><span class="line">    train(train_data_loader, eval_data_loader, model, optimizer, num_epoch=<span class="number">10</span>, log_step_interval=<span class="number">20</span>,</span><br><span class="line">          save_step_interval=<span class="number">500</span>,</span><br><span class="line">          eval_step_interval=<span class="number">300</span>, save_path=<span class="string">&#x27;./logs_imdb_text_classification&#x27;</span>, resume=resume)</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">project</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/27f58942.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络6-GRU" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/f22b56ba.html">用pytorch实现基础网络6-GRU</a>
    </h2>
  

        
		
		  <a href="/post/f22b56ba.html" class="archive-article-date">
  	<time datetime="2023-04-14T09:47:29.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-14</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">566字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">3min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p>torch.nn.GRU(<strong>args<em>, </em></strong>kwargs*)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.GRU.html?highlight=gru#torch.nn.GRU <span class="math display">\[
\begin{aligned}
r_{t} &amp; =\sigma\left(W_{i r} x_{t}+b_{i r}+W_{h r} h_{(t-1)}+b_{h r}\right) \\
z_{t} &amp; =\sigma\left(W_{i z} x_{t}+b_{i z}+W_{h z} h_{(t-1)}+b_{h z}\right) \\
n_{t} &amp; =\tanh \left(W_{i n} x_{t}+b_{i n}+r_{t} *\left(W_{h n} h_{(t-1)}+b_{h n}\right)\right) \\
h_{t} &amp; =\left(1-z_{t}\right) * n_{t}+z_{t} * h_{(t-1)}
\end{aligned}
\]</span> 同等<code>hidden size</code>的参数量，GRU是LSTM的<span class="math inline">\(\frac{3}{4}\)</span></p>
<p>何时使用GRU，何时使用LSTM？</p>
<p>https://arxiv.org/pdf/1412.3555.pdf</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304141848732.png" alt="image-20230414180541344" /><figcaption aria-hidden="true">image-20230414180541344</figcaption>
</figure>
<h2 id="api">1 API</h2>
<h3 id="parameters">1.1 Parameters</h3>
<ul>
<li><strong>input_size</strong> – The number of expected features in the input x</li>
<li><strong>hidden_size</strong> – The number of features in the hidden state h</li>
<li><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code>num_layers=2</code> would mean stacking two GRUs together to form a stacked GRU, with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1</li>
<li><strong>bias</strong> – If <code>False</code>, then the layer does not use bias weights b_ih and b_hh. Default: <code>True</code></li>
<li><strong>batch_first</strong> – If <code>True</code>, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: <code>False</code></li>
<li><strong>dropout</strong> – If non-zero, introduces a Dropout layer on the outputs of each GRU layer except the last layer, with dropout probability equal to <code>dropout</code>. Default: 0</li>
<li><strong>bidirectional</strong> – If <code>True</code>, becomes a bidirectional GRU. Default: <code>False</code></li>
</ul>
<h2 id="实现">2 实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gru_forward</span>(<span class="params"><span class="built_in">input</span>,initial_states,w_ih,w_hh,b_ih,b_hh</span>):</span><br><span class="line">    prev_h = initial_states</span><br><span class="line">    bs,T,i_size = <span class="built_in">input</span>.shape</span><br><span class="line">    h_size = w_ih.shape[<span class="number">0</span>] // <span class="number">3</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对权重扩维，复制成batch_size倍</span></span><br><span class="line">    batch_w_ih = w_ih.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    batch_w_hh = w_hh.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    output = torch.zeros(bs,T,h_size) <span class="comment"># GRU网络的输出状态序列</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        x = <span class="built_in">input</span>[:,t,:] <span class="comment"># t时刻的GRU cell的输入特征向量 [bs,i_size]</span></span><br><span class="line">        w_time_x = torch.bmm(batch_w_ih,x.unsqueeze(-<span class="number">1</span>)) <span class="comment">#[bs,3*i_size,1]</span></span><br><span class="line">        w_time_x = w_time_x.squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        w_time_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-<span class="number">1</span>)) <span class="comment">#[bs,3*i_size,1]</span></span><br><span class="line">        w_time_h_prev = w_time_h_prev.squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        r_t = torch.sigmoid(w_time_x[:,:h_size] + w_time_h_prev[:,:h_size] + b_ih[:h_size] + b_hh[:h_size]) <span class="comment"># 重置门</span></span><br><span class="line">        z_t = torch.sigmoid(w_time_x[:,h_size:<span class="number">2</span>*h_size] + w_time_h_prev[:,h_size:<span class="number">2</span>*h_size] + b_ih[h_size:<span class="number">2</span>*h_size] + b_hh[h_size:<span class="number">2</span>*h_size]) <span class="comment"># 更新门</span></span><br><span class="line">        </span><br><span class="line">        n_t = torch.tanh(w_time_x[:,<span class="number">2</span>*h_size:<span class="number">3</span>*h_size]+b_ih[<span class="number">2</span>*h_size:<span class="number">3</span>*h_size]+</span><br><span class="line">                         r_t*(w_time_h_prev[:,<span class="number">2</span>*h_size: <span class="number">3</span>*h_size]+b_hh[<span class="number">2</span>*h_size: <span class="number">3</span>*h_size]))   <span class="comment"># 候选状态</span></span><br><span class="line">        </span><br><span class="line">        prev_h = (<span class="number">1</span>-z_t)*n_t + z_t*prev_h <span class="comment"># 增量更新得到当前时刻最新隐含状态</span></span><br><span class="line">        output[:,t,:] = prev_h</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> output,prev_h</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bs,T,i_size,h_size = <span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(bs,T,i_size)</span><br><span class="line">h0 = torch.randn(bs,h_size)</span><br><span class="line"></span><br><span class="line">gru_layer = nn.GRU(i_size,h_size,batch_first = <span class="literal">True</span>)</span><br><span class="line">output,h_final = gru_layer(<span class="built_in">input</span>,h0.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">output_custom,h_final_custom = gru_forward(<span class="built_in">input</span>,h0,gru_layer.weight_ih_l0,gru_layer.weight_hh_l0,gru_layer.bias_ih_l0,gru_layer.bias_hh_l0)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(h_final,h_final_custom))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(output,output_custom))</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/f22b56ba.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络5-LTSM" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/23f44fab.html">用pytorch实现基础网络5-LSTM</a>
    </h2>
  

        
		
		  <a href="/post/23f44fab.html" class="archive-article-date">
  	<time datetime="2023-04-13T10:13:13.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-13</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">1.5k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">8min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p>https://colah.github.io/posts/2015-08-Understanding-LSTMs/</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131816130.png" alt="image-20230413181558550" /><figcaption aria-hidden="true">image-20230413181558550</figcaption>
</figure>
<h2 id="整体介绍">1 整体介绍</h2>
<p><span class="math display">\[
\begin{array}{l}
i_{t}=\sigma\left(W_{i i} x_{t}+b_{i i}+W_{h i} h_{t-1}+b_{h i}\right) \\
f_{t}=\sigma\left(W_{i f} x_{t}+b_{i f}+W_{h f} h_{t-1}+b_{h f}\right) \\
g_{t}=\tanh \left(W_{i g} x_{t}+b_{i g}+W_{h g} h_{t-1}+b_{h g}\right) \\
o_{t}=\sigma\left(W_{i o} x_{t}+b_{i o}+W_{h o} h_{t-1}+b_{h o}\right) \\
c_{t}=f_{t} \odot c_{t-1}+i_{t} \odot g_{t} \\
h_{t}=o_{t} \odot \tanh \left(c_{t}\right)
\end{array}
\]</span></p>
<ul>
<li><p><span class="math inline">\(h_t\)</span>: hidden state at time <span class="math inline">\(t\)</span></p></li>
<li><p><span class="math inline">\(c_t\)</span>: cell state at time <span class="math inline">\(t\)</span></p></li>
<li><p><span class="math inline">\(x_t\)</span>: input at time <span class="math inline">\(t\)</span></p></li>
<li><p><span class="math inline">\(h_{t-1}\)</span>: hidden state of the layer at time <span class="math inline">\(t-1\)</span> or the initial hidden state at time o</p></li>
<li><p><span class="math inline">\(i_t\)</span>: input</p></li>
<li><p><span class="math inline">\(f_t\)</span>: forget</p></li>
<li><p><span class="math inline">\(g_t\)</span>: cell</p></li>
<li><p><span class="math inline">\(o_t\)</span>: output gates</p></li>
<li><p><span class="math inline">\(\sigma\)</span>: sigmoid function</p></li>
<li><p><span class="math inline">\(\odot\)</span>: Hadamard product</p></li>
<li><p><span class="math inline">\(N\)</span> = batch size</p></li>
<li><p><span class="math inline">\(L\)</span> = sequence length</p></li>
<li><p><span class="math inline">\(D\)</span> = 2 if bidirectional = True otherwise 1</p></li>
<li><p><span class="math inline">\(H_{in}\)</span> = input_size</p></li>
<li><p><span class="math inline">\(H_{cell}\)</span> = hidden_size</p></li>
<li><p><span class="math inline">\(H_{out}\)</span> = pro_size if pro_size &gt; 0 otherwise hidden_size</p></li>
</ul>
<h3 id="parameters">1.1 Parameters</h3>
<ul>
<li><strong>input_size</strong> – The number of expected features in the input x</li>
<li><strong>hidden_size</strong> – The number of features in the hidden state h</li>
<li><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code>num_layers=2</code> would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1</li>
<li><strong>bias</strong> – If <code>False</code>, then the layer does not use bias weights b_ih and b_hh. Default: <code>True</code></li>
<li><strong>batch_first</strong> – If <code>True</code>, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: <code>False</code></li>
<li><strong>dropout</strong> – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to <code>dropout</code>. Default: 0</li>
<li><strong>bidirectional</strong> – If <code>True</code>, becomes a bidirectional LSTM. Default: <code>False</code></li>
<li><strong>proj_size</strong> – If <code>&gt; 0</code>, will use LSTM with projections of corresponding size. Default: 0 减少LTSM的参数和计算量</li>
</ul>
<h3 id="inputs-input-h_0-c_0">1.2 Inputs: input, (h_0, c_0)</h3>
<ul>
<li>input：
<ul>
<li><span class="math inline">\((L,H_{in})\)</span>-&gt; unbatched input</li>
<li><span class="math inline">\((L,N,H_{in})\)</span>-&gt;<code>batch_first=False</code></li>
<li><span class="math inline">\((N,L,H_{in})\)</span>-&gt;<code>batch_first=True</code></li>
</ul></li>
<li>h_0: Defaults to zeros if (h_0, c_0) is not provided
<ul>
<li><span class="math inline">\((D*num\_layers,H_{out})\)</span> for unbatched input</li>
<li><span class="math inline">\((D*num\_layers,N,H_{out})\)</span> containing the initial hidden state for each element in the input sequence.</li>
</ul></li>
<li>c_0: Defaults to zeros if (h_0, c_0) is not provided
<ul>
<li><span class="math inline">\((D*num\_layers,H_{cell})\)</span> for unbatched input</li>
<li><span class="math inline">\((D*num\_layers,N,H_{cell})\)</span> containing the initial cell state for each element in the input sequence.</li>
</ul></li>
</ul>
<h3 id="outputs-output-h_n-c_n">1.3 Outputs: output, (h_n, c_n)</h3>
<ul>
<li>output:
<ul>
<li><span class="math inline">\((L,D*H_{out})\)</span>-&gt;unbatched input</li>
<li><span class="math inline">\((L,N,D*H_{out})\)</span>-&gt;<code>batch_first=False</code> containing the output features (h_t) from the last layer of the LSTM,for each t</li>
<li><span class="math inline">\((N,L,D*H_{out})\)</span>-&gt;<code>batch_first=True</code> containing the output features (h_t) from the last layer of the LSTM,for each t</li>
<li>If a <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence"><code>torch.nn.utils.rnn.PackedSequence</code></a> has been given as the input, the output will also be a packed sequence</li>
<li>When <code>bidirectional=True</code>, output will contain a concatenation of the forward and reverse hidden states at each time step in the sequence</li>
</ul></li>
<li>h_n:
<ul>
<li><span class="math inline">\((D*num\_layers,H_{out})\)</span>-&gt; unbatched input</li>
<li><span class="math inline">\((D*num\_layers,N,H_{out})\)</span>-&gt;containing the final hidden state for each element in the sequence.</li>
<li>When <code>bidirectional=True</code>, h_n will contain a concatenation of the final forward and reverse hidden states, respectively.</li>
</ul></li>
<li>c_n:
<ul>
<li><span class="math inline">\((D*num\_layers,H_{cell})\)</span>-&gt; unbatched input</li>
<li><span class="math inline">\((D*num\_layers,N,H_{cell})\)</span>-&gt;containing the final hidden state for each element in the sequence.</li>
<li>When <code>bidirectional=True</code>, h_n will contain a concatenation of the final forward and reverse hidden states, respectively.</li>
</ul></li>
</ul>
<h3 id="variables">1.4 Variables</h3>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131856525.png" alt="image-20230413185629132" /><figcaption aria-hidden="true">image-20230413185629132</figcaption>
</figure>
<h2 id="调用api">2 调用API</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 定义常量</span></span><br><span class="line">bs,T,i_size,h_size = <span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br><span class="line"><span class="comment"># proj_size = </span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(bs,T,i_size) <span class="comment"># 输入序列</span></span><br><span class="line">c0 = torch.randn(bs,h_size) <span class="comment"># 初始值，不需要训练</span></span><br><span class="line">h0 = torch.randn(bs,h_size) <span class="comment"># 初始值，不需要训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用官方LSTM API</span></span><br><span class="line">lstm_layer = nn.LSTM(i_size,h_size,batch_first=<span class="literal">True</span>)</span><br><span class="line">output,(h_final,c_final) = lstm_layer(<span class="built_in">input</span>,(h0.unsqueeze(<span class="number">0</span>),c0.unsqueeze(<span class="number">0</span>)))</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> lstm_layer.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(k,v.shape)</span><br></pre></td></tr></table></figure>
<h2 id="lstm-without-proj_size">3 LSTM without proj_size</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己写一个LSTM模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lstm_forward</span>(<span class="params"><span class="built_in">input</span>,inittal_states,w_ih,w_hh,b_ih,b_hh</span>):</span><br><span class="line">    h0,c0 = inittal_states <span class="comment"># 初始状态</span></span><br><span class="line">    bs,T,i_size = <span class="built_in">input</span>.shape</span><br><span class="line">    h_size = w_ih.shape[<span class="number">0</span>] // <span class="number">4</span></span><br><span class="line">    </span><br><span class="line">    prev_h = h0</span><br><span class="line">    prev_c = c0</span><br><span class="line">    batch_w_ih = w_ih.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># (bs,4*h_size,i_size)</span></span><br><span class="line">    batch_w_hh = w_hh.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># (bs,4*h_size,h_size)</span></span><br><span class="line">    </span><br><span class="line">    output_size = h_size</span><br><span class="line">    output = torch.zeros(bs,T,output_size) <span class="comment"># 输出序列</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        x = <span class="built_in">input</span>[:,t,:] <span class="comment"># 当前时刻的输入向量 (bs,i_size)</span></span><br><span class="line">        w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-<span class="number">1</span>)) <span class="comment"># [bs,4*h_size,1]</span></span><br><span class="line">        w_times_x = w_times_x.squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        w_times_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-<span class="number">1</span>)) <span class="comment"># [bs,4*h_size,1]</span></span><br><span class="line">        w_times_h_prev = w_times_h_prev.squeeze(-<span class="number">1</span>)   </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分別计算输入门(i)，遗忘门(f)，cell门(g)，输出门(o)</span></span><br><span class="line">        i_t = torch.sigmoid(w_times_x[:,:h_size] + w_times_h_prev[:,:h_size] + b_ih[:h_size] + b_hh[:h_size])</span><br><span class="line">        f_t = torch.sigmoid(w_times_x[:,h_size:<span class="number">2</span>*h_size] + w_times_h_prev[:,h_size:<span class="number">2</span>*h_size] + b_ih[h_size:<span class="number">2</span>*h_size] + b_hh[h_size:<span class="number">2</span>*h_size])</span><br><span class="line">        g_t = torch.tanh(w_times_x[:,<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + w_times_h_prev[:,<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + b_ih[<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + b_hh[<span class="number">2</span>*h_size:<span class="number">3</span>*h_size])</span><br><span class="line">        o_t = torch.sigmoid(w_times_x[:,<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + w_times_h_prev[:,<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + b_ih[<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + b_hh[<span class="number">3</span>*h_size:<span class="number">4</span>*h_size])</span><br><span class="line"></span><br><span class="line">        prev_c = f_t * prev_c + i_t * g_t</span><br><span class="line">        prev_h = o_t * torch.tanh(prev_c)</span><br><span class="line">        </span><br><span class="line">        output[:,t,:] = prev_h</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> output,(prev_h,prev_c)</span><br><span class="line">    </span><br><span class="line">custom_output,(custom_h_final,custom_c_final) = lstm_forward(<span class="built_in">input</span>,(h0,c0),lstm_layer.weight_ih_l0,lstm_layer.weight_hh_l0,lstm_layer.bias_ih_l0,lstm_layer.bias_hh_l0)    </span><br><span class="line"><span class="built_in">print</span>(torch.allclose(custom_output,output))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(h_final,custom_h_final))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(c_final,custom_c_final))</span><br></pre></td></tr></table></figure>
<h2 id="lstm-with-proj_size">4 LSTM with proj_size</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义常量</span></span><br><span class="line">bs,T,i_size,h_size = <span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br><span class="line">proj_size = <span class="number">3</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(bs,T,i_size) <span class="comment"># 输入序列</span></span><br><span class="line">c0 = torch.randn(bs,h_size) <span class="comment"># 初始值，不需要训练</span></span><br><span class="line">h0 = torch.randn(bs,proj_size) <span class="comment"># 初始值，不需要训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用官方LSTM API</span></span><br><span class="line">lstm_layer = nn.LSTM(i_size,h_size,batch_first=<span class="literal">True</span>,proj_size=proj_size)</span><br><span class="line">output,(h_final,c_final) = lstm_layer(<span class="built_in">input</span>,(h0.unsqueeze(<span class="number">0</span>),c0.unsqueeze(<span class="number">0</span>)))</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> lstm_layer.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(k,v)</span><br></pre></td></tr></table></figure>
<p>eight_ih_l0 torch.Size([20, 4]) h_size<em>4,i_size weight_hh_l0 torch.Size([20, 3]) h_size</em>4,proj_size bias_ih_l0 torch.Size([20]) h_size<em>4 bias_hh_l0 torch.Size([20]) h_size</em>4 weight_hr_l0 torch.Size([3, 5]) proj_size,h_size 只会对 h_state 进行改变，不会对 c_state 进行改变</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lstm_forward</span>(<span class="params"><span class="built_in">input</span>,inittal_states,w_ih,w_hh,b_ih,b_hh,w_hr=<span class="literal">None</span></span>):</span><br><span class="line">    h0,c0 = inittal_states <span class="comment"># 初始状态</span></span><br><span class="line">    bs,T,i_size = <span class="built_in">input</span>.shape</span><br><span class="line">    h_size = w_ih.shape[<span class="number">0</span>] // <span class="number">4</span></span><br><span class="line">    </span><br><span class="line">    prev_h = h0</span><br><span class="line">    prev_c = c0</span><br><span class="line">    batch_w_ih = w_ih.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># (bs,4*h_size,i_size)</span></span><br><span class="line">    batch_w_hh = w_hh.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># (bs,4*h_size,h_size)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> w_hr <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_size = w_hr.shape[<span class="number">0</span>]</span><br><span class="line">        output_size = p_size</span><br><span class="line">        batch_w_hr = w_hr.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># (bs,proj_size,h_size)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output_size = h_size</span><br><span class="line">    output = torch.zeros(bs,T,output_size) <span class="comment"># 输出序列</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        x = <span class="built_in">input</span>[:,t,:] <span class="comment"># 当前时刻的输入向量 (bs,i_size)</span></span><br><span class="line">        w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-<span class="number">1</span>)) <span class="comment"># [bs,4*h_size,1]</span></span><br><span class="line">        w_times_x = w_times_x.squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        w_times_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-<span class="number">1</span>)) <span class="comment"># [bs,4*h_size,1]</span></span><br><span class="line">        w_times_h_prev = w_times_h_prev.squeeze(-<span class="number">1</span>)   </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分別计算输入门(i)，遗忘门(f)，cell门(g)，输出门(o)</span></span><br><span class="line">        i_t = torch.sigmoid(w_times_x[:,:h_size] + w_times_h_prev[:,:h_size] + b_ih[:h_size] + b_hh[:h_size])</span><br><span class="line">        f_t = torch.sigmoid(w_times_x[:,h_size:<span class="number">2</span>*h_size] + w_times_h_prev[:,h_size:<span class="number">2</span>*h_size] + b_ih[h_size:<span class="number">2</span>*h_size] + b_hh[h_size:<span class="number">2</span>*h_size])</span><br><span class="line">        g_t = torch.tanh(w_times_x[:,<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + w_times_h_prev[:,<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + b_ih[<span class="number">2</span>*h_size:<span class="number">3</span>*h_size] + b_hh[<span class="number">2</span>*h_size:<span class="number">3</span>*h_size])</span><br><span class="line">        o_t = torch.sigmoid(w_times_x[:,<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + w_times_h_prev[:,<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + b_ih[<span class="number">3</span>*h_size:<span class="number">4</span>*h_size] + b_hh[<span class="number">3</span>*h_size:<span class="number">4</span>*h_size])</span><br><span class="line"></span><br><span class="line">        prev_c = f_t * prev_c + i_t * g_t</span><br><span class="line">        prev_h = o_t * torch.tanh(prev_c)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> w_hr <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 做projection</span></span><br><span class="line">            prev_h = torch.bmm(batch_w_hr,prev_h.unsqueeze(-<span class="number">1</span>)) <span class="comment"># bs,proj_size,1</span></span><br><span class="line">            prev_h = prev_h.squeeze(-<span class="number">1</span>) <span class="comment"># bs,proj_size</span></span><br><span class="line">            </span><br><span class="line">        output[:,t,:] = prev_h</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> output,(prev_h,prev_c)</span><br><span class="line">    </span><br><span class="line">custom_output,(custom_h_final,custom_c_final) = lstm_forward(<span class="built_in">input</span>,(h0,c0),lstm_layer.weight_ih_l0,lstm_layer.weight_hh_l0,</span><br><span class="line">                                                             lstm_layer.bias_ih_l0,lstm_layer.bias_hh_l0,lstm_layer.weight_hr_l0)    </span><br><span class="line"><span class="built_in">print</span>(torch.allclose(custom_output,output))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(h_final,custom_h_final))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(c_final,custom_c_final))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/23f44fab.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络4-RNN" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/b945630.html">用pytorch实现基础网络4-RNN</a>
    </h2>
  

        
		
		  <a href="/post/b945630.html" class="archive-article-date">
  	<time datetime="2023-04-13T06:29:13.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-13</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">896字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">5min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p>https://www.cs.toronto.edu/~graves/preprint.pdf</p>
<p>Supervised Sequence Labelling with Recurrent Neural Networks</p>
<p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131437010.png" alt="image-20230413143700100" style="zoom:67%;" /></p>
<p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131437818.png" alt="image-20230413143710020" style="zoom:67%;" /></p>
<p>delay: 能看到前几帧的信息，牺牲一定的时间，预测的更加准确。</p>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131448069.png" alt="image-20230413144847329" /><figcaption aria-hidden="true">image-20230413144847329</figcaption>
</figure>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304131502377.png" alt="image-20230413150234647" /><figcaption aria-hidden="true">image-20230413150234647</figcaption>
</figure>
<h2 id="api">1 API</h2>
<p>torch.nn.RNN(<strong>args<em>, </em></strong>kwargs*)</p>
<p>https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNN</p>
<p>Applies a multi-layer Elman RNN with tanh or ReLU non-linearity to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following function: <span class="math display">\[
h_t = tanh(x_tW_{ih}^T+b_{ih}+h_{t-1}W_{hh}^T+b_{hh})
\]</span> where <span class="math inline">\(h_t\)</span> is the hidden state at time t, <span class="math inline">\(x_t\)</span> is the input at time t, and <span class="math inline">\(h_{t-1}\)</span> is the hidden state of the previous layer at time t-1 or the inital hidden state at time 0. If nonlinearity is "relu", then ReLU is used instead of tanh.</p>
<ul>
<li><strong>input_size</strong> – The number of expected features in the input x</li>
<li><strong>hidden_size</strong> – The number of features in the hidden state h</li>
<li><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code>num_layers=2</code> would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</li>
<li><strong>nonlinearity</strong> – The non-linearity to use. Can be either <code>'tanh'</code> or <code>'relu'</code>. Default: <code>'tanh'</code></li>
<li><strong>bias</strong> – If <code>False</code>, then the layer does not use bias weights b_ih and b_hh. Default: <code>True</code></li>
<li><strong>batch_first</strong> – If <code>True</code>, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: <code>False</code></li>
<li><strong>dropout</strong> – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to <code>dropout</code>. Default: 0</li>
<li><strong>bidirectional</strong> – If <code>True</code>, becomes a bidirectional RNN. Default: <code>False</code></li>
</ul>
<p>Inputs: input, h_0</p>
<ul>
<li><p>inputs: tensor of shape <span class="math inline">\((L,H_{in})\)</span> for unbatched input, <span class="math inline">\((L,N,H_{in})\)</span> when <code>batch_first=False</code> or <span class="math inline">\((N,L,H_{in})\)</span> when <code>batch_first=True</code></p></li>
<li><p>h_0: tensor of shape <span class="math inline">\((D*num\_layer,H_{out})\)</span> for unbatched input or$ (D*num_layers,N,H_{out})$containing the initial hidden state for the input sequence batch. Defaults to zeros if not provided.</p></li>
</ul>
<p><span class="math display">\[
N=batch\ size \\
L = sequence\ length \\
D = 2\ if\ bidirectional = True\ otherwise\ 1 \\
H_{in} = input \_size \\
H_{out} = hidden\_size
\]</span></p>
<p>Outputs: output, h_n</p>
<h2 id="代码实现">2 代码实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 单向，单层RNN</span></span><br><span class="line">single_rnn = nn.RNN(<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>,batch_first=<span class="literal">True</span>) <span class="comment"># feature_size * hidden_size * layer_num</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>) <span class="comment"># batch_size*sequence_length*feature_size</span></span><br><span class="line">output,h_n = single_rnn(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output) <span class="comment"># batch_size*sequence_length*hidden_size</span></span><br><span class="line"><span class="built_in">print</span>(h_n) <span class="comment"># layer_num*batch_size*hidden_size</span></span><br><span class="line"><span class="comment"># 双向，单层RNN</span></span><br><span class="line">bidirectional_rnn = nn.RNN(<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>,batch_first=<span class="literal">True</span>,bidirectional=<span class="literal">True</span>)</span><br><span class="line">bi_output,bi_h_n = bidirectional_rnn(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(bi_output) <span class="comment"># batch_size*sequence_length*(2*hidden_size)</span></span><br><span class="line"><span class="built_in">print</span>(bi_h_n) <span class="comment"># (2*layer_num)*batch_size*hidden_size</span></span><br></pre></td></tr></table></figure>
<h2 id="实现单向单层rnn">3 实现单向单层RNN</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step2: 手写一个rnn_forward函数,实现单向rnn的计算原理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_forward</span>(<span class="params"><span class="built_in">input</span>,weight_ih,weight_hh,bias_ih,bias_hh,h_prev</span>):</span><br><span class="line">    bs,T,input_size = <span class="built_in">input</span>.shape</span><br><span class="line">    h_dim = weight_ih.shape[<span class="number">0</span>]</span><br><span class="line">    h_out = torch.zeros(bs,T,h_dim) <span class="comment"># 初始化一个输出(状态)矩阵</span></span><br><span class="line">    <span class="comment"># h_prev: bs*hidden_size</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        x = <span class="built_in">input</span>[:,t,:].unsqueeze(<span class="number">2</span>) <span class="comment">#获取当前时刻输入 # bs*input_size*1</span></span><br><span class="line">        w_ih_batch = weight_ih.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># bs*h_dim*input_size</span></span><br><span class="line">        w_hh_batch = weight_hh.unsqueeze(<span class="number">0</span>).tile(bs,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># bs*h_dim*h_dim</span></span><br><span class="line">        </span><br><span class="line">        w_time_x = torch.bmm(w_ih_batch,x).squeeze(-<span class="number">1</span>) <span class="comment"># bs*h_dim</span></span><br><span class="line">        w_time_h = torch.bmm(w_hh_batch,h_prev.unsqueeze(<span class="number">2</span>)).squeeze(-<span class="number">1</span>) <span class="comment">#bs*h_dim</span></span><br><span class="line">        h_prev = torch.tanh(w_time_x + bias_ih + w_time_h + bias_hh) <span class="comment"># t时刻的输出</span></span><br><span class="line">        </span><br><span class="line">        h_out[:,t,:] = h_prev</span><br><span class="line">    <span class="keyword">return</span> h_out,h_prev.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 验证一下rnn_forward的正确性</span></span><br><span class="line"><span class="comment"># for k,v in rnn.named_parameters():</span></span><br><span class="line"><span class="comment">#     print(k,v)</span></span><br><span class="line">custom_rnn_output,custom_state_final = run_forward(<span class="built_in">input</span>,rnn.weight_ih_l0,rnn.weight_hh_l0,rnn.bias_ih_l0,rnn.bias_hh_l0,h_prev)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(custom_rnn_output,rnn_output))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(custom_state_final,state_final))</span><br></pre></td></tr></table></figure>
<h2 id="实现双向单层rnn">4 实现双向单层RNN</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3: 手写一个bidirectional_rnn_forward函数，实现双向RNN的计算原理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bidirectional_run_forward</span>(<span class="params"><span class="built_in">input</span>,weight_ih,weight_hh,bias_ih,bias_hh,h_prev,</span></span><br><span class="line"><span class="params">                              weight_ih_reverse,weight_hh_reverse,bias_ih_reverse,bias_hh_reverse,h_prev_reverse</span>):</span><br><span class="line">    bs,T,input_size = <span class="built_in">input</span>.shape</span><br><span class="line">    h_dim = weight_ih.shape[<span class="number">0</span>]</span><br><span class="line">    h_out = torch.zeros(bs,T,h_dim*<span class="number">2</span>) <span class="comment"># 初始化一个输出(状态)矩阵</span></span><br><span class="line">    </span><br><span class="line">    forward_output = run_forward(<span class="built_in">input</span>,weight_ih,weight_hh,bias_ih,bias_hh,h_prev)[<span class="number">0</span>] <span class="comment"># forward layer</span></span><br><span class="line">    backward_output = run_forward(torch.flip(<span class="built_in">input</span>,[<span class="number">1</span>]),</span><br><span class="line">                      weight_ih_reverse,weight_hh_reverse,bias_ih_reverse,bias_hh_reverse,h_prev_reverse)[<span class="number">0</span>]  <span class="comment"># flip 对dim进行翻转, backward layer</span></span><br><span class="line">    </span><br><span class="line">    h_out[:,:,:h_dim] = forward_output</span><br><span class="line">    h_out[:,:,h_dim:] = torch.flip(backward_output,[<span class="number">1</span>]) <span class="comment"># 反向的结果需要在T维度上再次反向，才能与api结果相同</span></span><br><span class="line">    </span><br><span class="line">    h_n = torch.zeros(<span class="number">2</span>,bs,h_dim)</span><br><span class="line">    h_n[<span class="number">0</span>,:,:] = forward_output[:,-<span class="number">1</span>,:]</span><br><span class="line">    h_n[<span class="number">1</span>,:,:] = backward_output[:,-<span class="number">1</span>,:]</span><br><span class="line">        <span class="comment"># h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)</span></span><br><span class="line">    <span class="keyword">return</span> h_out, h_n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证一下 bidirectional_rnn_forward正确性</span></span><br><span class="line">bi_rnn = nn.RNN(input_size,hidden_size,batch_first=<span class="literal">True</span>,bidirectional=<span class="literal">True</span>)</span><br><span class="line">h_prev =torch.zeros(<span class="number">2</span>,bs,hidden_size)</span><br><span class="line">bi_rnn_output,bi_state_final = bi_rnn(<span class="built_in">input</span>,h_prev)</span><br><span class="line"></span><br><span class="line">custom_bi_rnn_output,custom_bi_state_final = bidirectional_run_forward(<span class="built_in">input</span>,</span><br><span class="line">                                                                       bi_rnn.weight_ih_l0,</span><br><span class="line">                                                                       bi_rnn.weight_hh_l0,</span><br><span class="line">                                                                       bi_rnn.bias_ih_l0,</span><br><span class="line">                                                                       bi_rnn.bias_hh_l0,</span><br><span class="line">                                                                       h_prev[<span class="number">0</span>],</span><br><span class="line">                                                                       bi_rnn.weight_ih_l0_reverse,</span><br><span class="line">                                                                       bi_rnn.weight_hh_l0_reverse,</span><br><span class="line">                                                                       bi_rnn.bias_ih_l0_reverse,</span><br><span class="line">                                                                       bi_rnn.bias_hh_l0_reverse,</span><br><span class="line">                                                                       h_prev[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(bi_rnn_output,custom_bi_rnn_output))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(bi_state_final,custom_bi_state_final))</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/b945630.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
    <article id="post-用pytorch实现基础网络1-卷积网络" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h2 itemprop="name">
      <a class="article-title_code_ant" href="/post/1229d3b9.html">用pytorch实现基础网络1-卷积网络</a>
    </h2>
  

        
		
		  <a href="/post/1229d3b9.html" class="archive-article-date">
  	<time datetime="2023-04-12T15:59:34.000Z" itemprop="datePublished">
	<!-- <i class="icon-calendar icon"></i> -->

	<i class="fa fa-calendar-check-o" aria-hidden="true"></i>
	&nbsp;
	2023-04-12</time>
	
	<!-- busuanzi阅读量统计
	
	-->
	
    <!-- waline阅读量统计 -->
	

</a>


        
		
		
		  <!-- 添加标题栏文字统计效果 -->
<div class="word-count">
	
      
        <span class="article-type" style="
          color: white;
          font-size: 14px;
          background: #0088CC;
          padding: 0 5px 1px 5px;
          margin-right: 5px;
          border-radius: 2px;">原创</span>
		  &nbsp; 
      
    
	
    <span class="post-time">
      <span class="post-meta-item-icon">
	    <i class="fa fa-bar-chart" aria-hidden="true"></i>
        <!-- <i class="fa fa-keyboard-o" aria-hidden="true"></i> -->
        <span class="post-meta-item-text">字数统计: </span>
        <span class="post-count">2.5k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
	    <i class="fa fa-pagelines" aria-hidden="true"></i>
        <span class="post-meta-item-text">阅读时长: </span>
        <span class="post-count">13min</span>
      </span>
    </span>
	

</div>
<!-- 添加标题栏文字统计效果结束 -->
		
      </header>
    
	
    <div class="article-entry" itemprop="articleBody">
	  <!-- 添加分类与标签 -->
	  
		  
		  <p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101930110.png" alt="image-20230410193006020" style="zoom:80%;" /></p>
<h2 id="卷积的api">1 卷积的API</h2>
<h3 id="conv2d">1.1 CONV2D</h3>
<p>torch.nn.Conv2d(<em>in_channels</em>, <em>out_channels</em>, <em>kernel_size</em>, <em>stride=1</em>, <em>padding=0</em>, <em>dilation=1</em>, <em>groups=1</em>, <em>bias=True</em>, <em>padding_mode='zeros'</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</p>
<p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101932268.png" alt="image-20230410193201892" style="zoom:67%;" /></p>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</li>
<li><strong>padding_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li>
</ul>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304111953529.png" alt="image-20230411195325050" /><figcaption aria-hidden="true">image-20230411195325050</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">in_channels = <span class="number">1</span></span><br><span class="line">out_channels = <span class="number">1</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">bias = <span class="literal">False</span></span><br><span class="line">input_size = [in_channels,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">conv_layer = nn.Conv2d(in_channels,out_channels,kernel_size,bias=bias)</span><br><span class="line">input_feature_map = torch.randn(input_size)</span><br><span class="line">output_feature_map = conv_layer(input_feature_map) <span class="comment"># 直接调用卷积这个方法</span></span><br><span class="line"><span class="built_in">print</span>(input_feature_map,<span class="string">&#x27;\n&#x27;</span>,output_feature_map)</span><br><span class="line"><span class="built_in">print</span>(conv_layer.weight) <span class="comment"># 1*1*3*3 out_channels*in_channels*height*width</span></span><br></pre></td></tr></table></figure>
<h3 id="functional.conv2d">1.2 FUNCTIONAL.CONV2D</h3>
<p>torch.nn.functional.conv2d(<em>input</em>, <em>weight</em>, <em>bias=None</em>, <em>stride=1</em>, <em>padding=0</em>, <em>dilation=1</em>, <em>groups=1</em>) → <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></p>
<p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304112015956.png" alt="image-20230411201534888" style="zoom:67%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight) <span class="comment"># functional,需要传入卷积的weight</span></span><br><span class="line"><span class="built_in">print</span>(output_feature_map)</span><br><span class="line"><span class="built_in">print</span>(output_feature_map1)</span><br></pre></td></tr></table></figure>
<h2 id="padding-and-stride">2 padding and stride</h2>
<p>https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html</p>
<h3 id="padding">2.1 padding</h3>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304112028509.png" alt="image-20230411202806742" /><figcaption aria-hidden="true">image-20230411202806742</figcaption>
</figure>
<p>In general, if we add a total of <span class="math inline">\(p_h\)</span> rows of padding (roughly half on top and half on bottom) and a total of <span class="math inline">\(p_w\)</span> columns of padding (roughly half on the left and half on the right), the output shape will be <span class="math display">\[
(n_k - k_h + p_h + 1)\times (n_w - k_w + p_w + 1)
\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We define a helper function to calculate convolutions. It initializes the</span></span><br><span class="line"><span class="comment"># convolutional layer weights and performs corresponding dimensionality</span></span><br><span class="line"><span class="comment"># elevations and reductions on the input and output</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span><br><span class="line">    <span class="comment"># (1, 1) indicates that batch size and the number of channels are both 1</span></span><br><span class="line">    X = X.reshape((<span class="number">1</span>, <span class="number">1</span>) + X.shape)</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="comment"># Strip the first two dimensions: examples and channels</span></span><br><span class="line">    <span class="keyword">return</span> Y.reshape(Y.shape[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 row and column is padded on either side, so a total of 2 rows or columns</span></span><br><span class="line"><span class="comment"># are added</span></span><br><span class="line">conv2d = nn.LazyConv2d(<span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">X = torch.rand(size=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<p>When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We use a convolution kernel with height 5 and width 3. The padding on either</span></span><br><span class="line"><span class="comment"># side of the height and width are 2 and 1, respectively</span></span><br><span class="line">conv2d = nn.LazyConv2d(<span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<h3 id="stride">2.2 stride</h3>
<p>In general, when the stride for the height is <span class="math inline">\(s_h\)</span> and the stride for the width is <span class="math inline">\(s_w\)</span>, the output shape is <span class="math display">\[
[(n_h-k_h+p_h+s_h)/s_h] \times [((n_w-k_w+p_w+s_w)/s_w)]
\]</span> f we set<span class="math inline">\(p_h =k_h -1\)</span> and <span class="math inline">\(p_w = k_w -1\)</span>, then the output shape can be simplified to <span class="math inline">\([(n_h+s_h-1)/s_h\times (n_w+s_w-1)/s_w]\)</span>. Going a step further, if the input height and width are divisible by the strides on the height and width, then the output shape will be <span class="math inline">\((n_h/s_h)\times (n_w/s_w)\)</span></p>
<p>note: the [] means floor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv2d = nn.LazyConv2d(<span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), padding=(<span class="number">0</span>, <span class="number">1</span>), stride=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
<h3 id="demo">2.3 demo</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With square kernels and equal stride</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># non-square kernels and unequal stride and with padding and dilation</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>
<h2 id="multiple-input-and-multiple-output-channels">3 Multiple Input and Multiple Output Channels</h2>
<h3 id="multiple-input-channels">3.1 Multiple Input Channels</h3>
<figure>
<img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304112057860.png" alt="image-20230411205730182" /><figcaption aria-hidden="true">image-20230411205730182</figcaption>
</figure>
<h3 id="multiple-output-channels">3.2 Multiple Output Channels</h3>
<p>we actually increase the channel dimension as we go deeper in the neural network, typically downsampling to trade off spatial resolution for greater <em>channel depth</em>. Intuitively, you could think of each channel as responding to a different set of features.</p>
<p>把每个输出通道都看做一个单独的操作，最后stack起来得到结果</p>
<h2 id="矩阵运算实现卷积操作">4 矩阵运算实现卷积操作</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">5</span>,<span class="number">5</span>) <span class="comment"># 卷积的输入特征图</span></span><br><span class="line">kernel = torch.randn(<span class="number">3</span>,<span class="number">3</span>) <span class="comment"># 卷积核</span></span><br><span class="line">bias = torch.randn(<span class="number">1</span>) <span class="comment"># 卷积偏置，默认输出通道数目等于1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 用原始的矩阵运算来实现二维卷积,先不考虑 batchsize 维度和 channel 维度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_multiplication_for_conv2d</span>(<span class="params"><span class="built_in">input</span>,kernel,bias = <span class="number">0</span>,stride = <span class="number">1</span>,padding = <span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">input</span> = F.pad(<span class="built_in">input</span>,(padding,padding,padding,padding))</span><br><span class="line">        </span><br><span class="line">    input_h,input_w = <span class="built_in">input</span>.shape</span><br><span class="line">    kernel_h,kernel_w = kernel.shape</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    output_h = math.floor((input_h - kernel_h)/stride) + <span class="number">1</span> <span class="comment"># 输出高度</span></span><br><span class="line">    output_w = math.floor((input_w - kernel_w)/stride) + <span class="number">1</span> <span class="comment"># 输出宽度</span></span><br><span class="line">    output = torch.zeros((output_h,output_w))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_h - kernel_h + <span class="number">1</span>,stride):  <span class="comment"># 对高度遍历</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_w - kernel_w + <span class="number">1</span>,stride): <span class="comment"># 对宽度遍历</span></span><br><span class="line">            region = <span class="built_in">input</span>[i:i+kernel_h,j:j+kernel_w] <span class="comment"># 取出被核滑动到的区域</span></span><br><span class="line">            output[<span class="built_in">int</span>(i/stride)][<span class="built_in">int</span>(j/stride)] = torch.<span class="built_in">sum</span>(region * kernel) + bias <span class="comment"># 点乘，并赋值给输出位置的元素</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">mat_mul_conv_output = matrix_multiplication_for_conv2d(<span class="built_in">input</span>,kernel,bias=bias,padding=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(mat_mul_conv_output)</span><br><span class="line">pytorch_api_conv_output = F.conv2d(<span class="built_in">input</span>.reshape(<span class="number">1</span>,<span class="number">1</span>,<span class="built_in">input</span>.shape[<span class="number">0</span>],<span class="built_in">input</span>.shape[<span class="number">1</span>]),kernel.reshape(<span class="number">1</span>,<span class="number">1</span>,kernel.shape[<span class="number">0</span>],kernel.shape[<span class="number">1</span>]),bias=bias,padding=<span class="number">1</span>).squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(pytorch_api_conv_output)</span><br></pre></td></tr></table></figure>
<h2 id="向量内积实现卷积操作">5 向量内积实现卷积操作</h2>
<h3 id="flatten">5.1 flatten</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step2 用原始的矩阵运算来实现二维卷积,先不考虑 batchsize 维度和 channel 维度, flatten 版本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_multiplication_for_conv2d_flatten</span>(<span class="params"><span class="built_in">input</span>,kernel,bias = <span class="number">0</span>,stride = <span class="number">1</span>,padding = <span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">input</span> = F.pad(<span class="built_in">input</span>,(padding,padding,padding,padding))</span><br><span class="line">        </span><br><span class="line">    input_h,input_w = <span class="built_in">input</span>.shape</span><br><span class="line">    kernel_h,kernel_w = kernel.shape</span><br><span class="line">    </span><br><span class="line">    output_h = math.floor((input_h - kernel_h)/stride) + <span class="number">1</span> <span class="comment"># 输出高度</span></span><br><span class="line">    output_w = math.floor((input_w - kernel_w)/stride) + <span class="number">1</span> <span class="comment"># 输出宽度</span></span><br><span class="line">    output = torch.zeros((output_h,output_w))</span><br><span class="line">    region_matrix = torch.zeros(output.numel(),kernel.numel()) <span class="comment"># 存储所有的拉平后的特征区域</span></span><br><span class="line">    kernel_matrix = kernel.reshape((kernel.numel(),<span class="number">1</span>)) <span class="comment"># 变为列向量,kernel的列向量形式</span></span><br><span class="line">    row_index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_h - kernel_h + <span class="number">1</span>,stride):  <span class="comment"># 对高度遍历</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_w - kernel_w + <span class="number">1</span>,stride): <span class="comment"># 对宽度遍历</span></span><br><span class="line">            region = <span class="built_in">input</span>[i:i+kernel_h,j:j+kernel_w] <span class="comment"># 取出被核滑动到的区域</span></span><br><span class="line">            region_vetor = torch.flatten(region) </span><br><span class="line">            region_matrix[row_index] = region_vetor</span><br><span class="line">            row_index += <span class="number">1</span></span><br><span class="line">    output_matrix = region_matrix @ kernel_matrix</span><br><span class="line">    output = output_matrix.reshape((output_h,output_w)) + bias</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># flatten input</span></span><br><span class="line">pytorch_api_conv_output = F.conv2d(<span class="built_in">input</span>.reshape(<span class="number">1</span>,<span class="number">1</span>,<span class="built_in">input</span>.shape[<span class="number">0</span>],<span class="built_in">input</span>.shape[<span class="number">1</span>]),</span><br><span class="line">                                   kernel.reshape(<span class="number">1</span>,<span class="number">1</span>,kernel.shape[<span class="number">0</span>],kernel.shape[<span class="number">1</span>]),</span><br><span class="line">                                   bias=bias,padding=<span class="number">1</span>).squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line">mat_mul_conv_output_flatten = matrix_multiplication_for_conv2d_flatten(<span class="built_in">input</span>,kernel,bias=bias,padding=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(pytorch_api_conv_output,mat_mul_conv_output_flatten))</span><br></pre></td></tr></table></figure>
<p>这里可以使用torch.unfold实现flatten操作</p>
<p>torch.nn.Unfold(<em>kernel_size</em>, <em>dilation=1</em>, <em>padding=0</em>, <em>stride=1</em>)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html</p>
<h3 id="考虑batchsize维度和channel维度">5.2 考虑batchsize维度和channel维度</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3 用原始的矩阵运算来实现二维卷积，考虑batchsize维度和channel维度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_multiplication_for_conv2d_full</span>(<span class="params"><span class="built_in">input</span>,kernel,bias=<span class="number">0</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span></span>):</span><br><span class="line">    <span class="comment"># input和kernel 都是4维张量 </span></span><br><span class="line">    <span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">input</span> = F.pad(<span class="built_in">input</span>,(padding,padding,padding,padding,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)) <span class="comment"># w,h,input_channel,batchsize</span></span><br><span class="line">        </span><br><span class="line">    bs,in_channel,input_h,input_w = <span class="built_in">input</span>.shape <span class="comment"># batchsize,in_channel,input_h,input_w</span></span><br><span class="line">    out_channel,in_channel,kernel_h,kernel_w = kernel.shape</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        bias = torch.zeros(out_channel)</span><br><span class="line">    </span><br><span class="line">    output_h = math.floor((input_h - kernel_h)/stride) + <span class="number">1</span> <span class="comment"># 输出高度</span></span><br><span class="line">    output_w = math.floor((input_w - kernel_w)/stride) + <span class="number">1</span> <span class="comment"># 输出宽度</span></span><br><span class="line">    output = torch.zeros(bs,out_channel,output_h,output_w)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">        <span class="keyword">for</span> oc <span class="keyword">in</span> <span class="built_in">range</span>(out_channel):</span><br><span class="line">            <span class="keyword">for</span> ic <span class="keyword">in</span> <span class="built_in">range</span>(in_channel):</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_h - kernel_h + <span class="number">1</span>,stride):  <span class="comment"># 对高度遍历</span></span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_w - kernel_w + <span class="number">1</span>,stride): <span class="comment"># 对宽度遍历</span></span><br><span class="line">                        region = <span class="built_in">input</span>[ind,ic,i:i+kernel_h,j:j+kernel_w] <span class="comment"># 取出被核滑动到的区域</span></span><br><span class="line">                        output[ind,oc,<span class="built_in">int</span>(i/stride),<span class="built_in">int</span>(j/stride)] += torch.<span class="built_in">sum</span>(region * kernel[oc,ic]) <span class="comment"># 点乘，并赋值给输出位置的元素</span></span><br><span class="line">            output[ind,oc] += bias[oc]</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">2</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">5</span>) <span class="comment"># 卷积的输入特征图(batchsize,in_channel,in_h,in_w)</span></span><br><span class="line">kernel = torch.randn(<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>) <span class="comment"># 卷积核(out_channel,in_channel,kernel_h,kernel_w)</span></span><br><span class="line">bias = torch.randn(<span class="number">3</span>) <span class="comment"># 卷积偏置，默认输出通道数目等于1</span></span><br><span class="line">pytorch_conv2d_api_output = F.conv2d(<span class="built_in">input</span>,kernel,bias=bias,padding=<span class="number">1</span>,stride=<span class="number">2</span>)</span><br><span class="line">mm_conv2d_full_output = matrix_multiplication_for_conv2d_full(<span class="built_in">input</span>,kernel,bias=bias,padding=<span class="number">1</span>,stride=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(pytorch_conv2d_api_output,mm_conv2d_full_output))</span><br></pre></td></tr></table></figure>
<h2 id="转置卷积">6 转置卷积</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step4 通过对kernel进行展开来实现二维卷积，并推导出转置卷积</span></span><br><span class="line"><span class="comment"># 把input 和 kernel 都 resize 列向量(把kernel空缺的位置用0填充) 不考虑padding,假设stride=1</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_kernel_matrix</span>(<span class="params">kernel,input_size,stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;基于kernel和输入特征图的大小来得到填充拉直后的kernel堆叠后的矩阵&quot;&quot;&quot;</span></span><br><span class="line">    kernel_h, kernel_w = kernel.shape</span><br><span class="line">    input_h,input_w = input_size</span><br><span class="line">    num_out_feature_map = (math.floor((input_h - kernel_h)/stride) + <span class="number">1</span>) * (math.floor((input_w - kernel_w)/stride) + <span class="number">1</span>)</span><br><span class="line">    result = torch.zeros((num_out_feature_map,input_h*input_w)) <span class="comment"># 初始化结果矩阵，输出特征图元素个数*输入特征图元素个数</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_h-kernel_h+<span class="number">1</span>,stride):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_w-kernel_w+<span class="number">1</span>,stride):</span><br><span class="line">            padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j),) <span class="comment"># 上下左右</span></span><br><span class="line">            result[count] = padded_kernel.flatten()</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">kernel = torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">kernel_matrix = get_kernel_matrix(kernel,<span class="built_in">input</span>.shape) <span class="comment"># 4*16</span></span><br><span class="line"><span class="built_in">print</span>(kernel)</span><br><span class="line"><span class="built_in">print</span>(kernel_matrix)</span><br></pre></td></tr></table></figure>
<h3 id="验证二维卷积">6.1 验证二维卷积</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试1：验证二维卷积</span></span><br><span class="line">pytorch_conv2d_output = F.conv2d(<span class="built_in">input</span>.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>),kernel.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)) <span class="comment"># output 2*2</span></span><br><span class="line"><span class="comment"># 因为计算得到的 mm_conv2d_output 是列向量，所以需要reshape为大小一致的矩阵，再进行比较</span></span><br><span class="line">mm_conv2d_output = (kernel_matrix @ <span class="built_in">input</span>.reshape((-<span class="number">1</span>,<span class="number">1</span>))).reshape(pytorch_conv2d_output.shape).transpose(<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 通过矩阵乘积来计算卷积</span></span><br><span class="line"><span class="built_in">print</span>(torch.allclose(mm_conv2d_output,pytorch_conv2d_output))</span><br></pre></td></tr></table></figure>
<h3 id="验证二维转置卷积">6.2 验证二维转置卷积</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试2：验证二维转置卷积</span></span><br><span class="line"><span class="comment"># 2*2 -&gt; 4*4 一般用于上采样过程 output 的 feature map 恢复到输入的 feature map 的 size</span></span><br><span class="line"><span class="comment"># 卷积的梯度,后项传播实现 √</span></span><br><span class="line"><span class="comment"># 使用填充的方式实现 ×</span></span><br><span class="line"><span class="comment"># kernel_matrix 转置(16*4) * mm_conv2d_output(4*1)</span></span><br><span class="line">pytorch_transposed_conv2d_output = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)) <span class="comment"># API</span></span><br><span class="line">mm_transposed_conv2d_output = kernel_matrix.transpose(-<span class="number">1</span>,-<span class="number">2</span>) @ mm_conv2d_output <span class="comment"># 通过矩阵乘积来计算卷积(反卷积)</span></span><br><span class="line"><span class="built_in">print</span>(torch.allclose(pytorch_transposed_conv2d_output,mm_transposed_conv2d_output.reshape(pytorch_transposed_conv2d_output.shape)))</span><br></pre></td></tr></table></figure>
<p>torch.nn.ConvTranspose2d(<em>in_channels</em>, <em>out_channels</em>, <em>kernel_size</em>, <em>stride=1</em>, <em>padding=0</em>, <em>output_padding=0</em>, <em>groups=1</em>, <em>bias=True</em>, <em>dilation=1</em>, <em>padding_mode='zeros'</em>, <em>device=None</em>, <em>dtype=None</em>)</p>
<p>https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#ConvTranspose2d</p>
<p>torch.nn.functional.conv_transpose2d(<em>input</em>, <em>weight</em>, <em>bias=None</em>, <em>stride=1</em>, <em>padding=0</em>, <em>output_padding=0</em>, <em>groups=1</em>, <em>dilation=1</em>)</p>
<p>https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose2d.html</p>
<h2 id="group">7 group</h2>
<ul>
<li><strong>groups</strong> (int,optional) – Number of blocked connections from input channels to output channels. Default: 1</li>
</ul>
<h2 id="dilation">8 dilation</h2>
<ul>
<li><strong>dilation</strong> (int or tuple,optional) – Spacing between kernel elements. Default: 1</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">7</span>,<span class="number">7</span>)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>:<span class="number">3</span>,<span class="number">0</span>:<span class="number">3</span>])     <span class="comment"># dilation=1</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>:<span class="number">5</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">5</span>:<span class="number">2</span>]) <span class="comment"># dilation=2</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>:<span class="number">7</span>:<span class="number">3</span>,<span class="number">0</span>:<span class="number">7</span>:<span class="number">3</span>]) <span class="comment"># dilation=3</span></span><br></pre></td></tr></table></figure>
<h2 id="最终版本">9 最终版本</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_multiplication_for_conv2d_final</span>(<span class="params"><span class="built_in">input</span>,kernel,bias=<span class="literal">None</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>,dilation=<span class="number">1</span>,groups=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">if</span> padding &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">input</span> = F.pad(<span class="built_in">input</span>,(padding,padding,padding,padding,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    bs, in_channel, input_h, input_w = <span class="built_in">input</span>.shape</span><br><span class="line">    out_channel,_, kernel_h, kernel_w = kernel.shape</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span> out_channel % groups == <span class="number">0</span> <span class="keyword">and</span> in_channel % groups == <span class="number">0</span>, <span class="string">&quot;group必须要同时被输入通道数和输出通道数整除！&quot;</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.reshape((bs, groups, in_channel//groups, input_h, input_w))</span><br><span class="line">    kernel = kernel.reshape((groups, out_channel//groups, in_channel//groups, kernel_h, kernel_w))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># dilation (往原来的kernel中加入空洞)</span></span><br><span class="line">    kernel_h = (kernel_h - <span class="number">1</span>) * (dilation - <span class="number">1</span>) + kernel_h</span><br><span class="line">    kernel_w = (kernel_w - <span class="number">1</span>) * (dilation - <span class="number">1</span>) + kernel_w    </span><br><span class="line">    <span class="comment"># 输出结果的 feature map</span></span><br><span class="line">    output_h = math.floor((input_h - kernel_h) / stride) + <span class="number">1</span></span><br><span class="line">    output_w = math.floor((input_w - kernel_w) / stride) + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    output_shape = (bs,groups,out_channel//groups,output_h,output_w)</span><br><span class="line">    output = torch.zeros(output_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        bias = torch.zeros(out_channel)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(bs):                                                                           <span class="comment"># 对 batchsize进行遍历</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> <span class="built_in">range</span>(groups):                                                                     <span class="comment"># 对群组进行遍历</span></span><br><span class="line">            <span class="keyword">for</span> oc <span class="keyword">in</span> <span class="built_in">range</span>(out_channel // groups):                                                 <span class="comment"># 对分组后的输出通道进行遍历</span></span><br><span class="line">                <span class="keyword">for</span> ic <span class="keyword">in</span> <span class="built_in">range</span>(in_channel // groups):                                              <span class="comment"># 对分组厚的输入通道进行遍历</span></span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_h-kernel_h+<span class="number">1</span>,stride):                                    <span class="comment"># 对kernel高度遍历</span></span><br><span class="line">                        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,input_w-kernel_w+<span class="number">1</span>,stride):                                <span class="comment"># 对kernel宽度遍历</span></span><br><span class="line">                            region = <span class="built_in">input</span>[ind, g, ic, i:i+kernel_h:dilation,j:j+kernel_w:dilation]   <span class="comment"># 特征区域</span></span><br><span class="line">                            output[ind,g,oc,<span class="built_in">int</span>(i/stride),<span class="built_in">int</span>(j/stride)] += torch.<span class="built_in">sum</span>(region * kernel[g,oc,ic])</span><br><span class="line">                output[ind,g,oc] += bias[g*(out_channel//groups)+oc]                                <span class="comment"># 考虑偏置</span></span><br><span class="line">    output = output.reshape((bs,out_channel,output_h,output_w))                                     <span class="comment"># 还原成4维</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">bs, in_channel, input_h, input_w = <span class="number">2</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">5</span></span><br><span class="line">out_channel = <span class="number">4</span></span><br><span class="line">groups, dilation, stride, padding = <span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(bs, in_channel, input_h, input_w)</span><br><span class="line">kernel = torch.randn(out_channel,in_channel//groups,kernel_size,kernel_size)</span><br><span class="line">bias = torch.randn(out_channel)</span><br><span class="line"></span><br><span class="line">pytorch_conv2d_api_output = F.conv2d(<span class="built_in">input</span>,kernel,bias=bias,padding=padding,stride=stride,dilation=dilation,groups=groups)</span><br><span class="line">mm_conv2d_final_output = matrix_multiplication_for_conv2d_final(<span class="built_in">input</span>,kernel,bias=bias,stride=stride,padding=padding,dilation=dilation,groups=groups)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(pytorch_conv2d_api_output,mm_conv2d_final_output))</span><br></pre></td></tr></table></figure>

				  
	  
      
	  <!-- 添加打赏 -->
	  
	
	  <!-- 添加版权声明 -->
      
	  
	</div>
	
	<!-- 添加置顶 -->
    <div class="article-info article-info-index">
      
	  
	  <!-- 分类页 -->
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">network</a>
        		</li>
      		
		</ul>
	</div>

      

	  
	  <!-- 添加展开全文 -->
      
        <p class="article-more-link">
          <a class="article-more-a" href="/post/1229d3b9.html">展开全文 >></a>
        </p>
      
	  
	  <!-- 添加分享 -->
      
	  
      <div class="clearfix"></div>
	  
    </div>
  </div>
</article>



<!-- 添加回到顶部和文章目录 -->
<aside class="wrap-side-operation">
  <div class="mod-side-operation">
    
      <div class="jump-container" id="js-jump-container" style="display:none;">
        <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
          <i class="icon-font icon-back"></i>
        </a>
      </div>
    
    
  </div>
</aside>

<!-- 添加评论 -->


<!-- 文章页添加mathjax公式 -->

  

<!-- 文章页添加mathjax公式 -->
  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&lt;&lt; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/">下一页 &gt;&gt;</a>
    </nav>
  


<!-- 主页添加mathjax公式 -->

  <!-- mathjax http://docs.mathjax.org/en/latest/web/start.html -->
<script>
window.MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true
  },
  chtml: {
    scale: 1,                      // global scaling factor for all expressions
    minScale: .5,                  // smallest scaling factor to use
    mtextInheritFont: false,       // true to make mtext elements use surrounding font
    merrorInheritFont: false,      // true to make merror text use surrounding font
    mtextFont: '',                 // font to use for mtext, if not inheriting (empty means use MathJax fonts)
    merrorFont: 'serif',           // font to use for merror, if not inheriting (empty means use MathJax fonts)
    unknownFamily: 'serif',        // font to use for character that aren't in MathJax's fonts
    mathmlSpacing: false,          // true for MathML spacing rules, false for TeX rules
    skipAttributes: {},            // RFDa and other attributes NOT to copy to the output
    exFactor: .5,                  // default size of ex in em units
    displayAlign: 'center',        // default for indentalign when set to 'auto'
    displayIndent: '0'             // default for indentshift when set to 'auto'
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
};
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<!-- 主页添加mathjax公式 -->

          </div>
        </div>
      </div>
	  
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: false,
		root: "/",
		innerArchive: false,
		showTags: true
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev"><< 上一页</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">下一页 >></a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/js/main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/js/slider.e37972.js")}()</script>

<!--添加鼠标特效-->
<!-- https://blog.csdn.net/weixin_41287260/article/details/103050877 -->



<!--添加鼠标特效结束-->
    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="搜一搜">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">pytorch</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">aboutme</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">tools</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">project</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">tips</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">network</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
			<pre style="font-size: 12px;" q-show="jsonFail">
			  jsonContent:
				meta: false
				pages: false
				posts:
				  title: true
				  date: true
				  path: true
				  text: false
				  raw: false
				  content: false
				  slug: false
				  updated: false
				  comments: false
				  link: false
				  permalink: false
				  excerpt: false
				  categories: false
				  tags: true
			</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://chat.openai.com/auth/login/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>chatgpt</a>
            </li>
          
            <li class="search-li">
              <a href="https://xs.scqylaw.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>google scholar</a>
            </li>
          
            <li class="search-li">
              <a href="https://pytorch.org/tutorials/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>pytorch</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.latexlive.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>在线latex公式编辑器</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接4</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接5</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接6</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
		<div class="aboutme-wrap"> 
			<div style="display:;color:LightSkyBlue;"> 
				
					<p id="hitokoto" style="margin:0 20px 0 20px;color:GreenYellow;"></p>
					<div style="margin:0 20px 0 20px;">
						<p id="from" style="margin:10px;text-align:right;color:Salmon;"></p>
					</div>	
					<script>
						var xmlhttp = new XMLHttpRequest();
						xmlhttp.onreadystatechange = function() {
								if (this.readyState == 4 && this.status == 200) {
									yiyan = JSON.parse(this.responseText);
									document.getElementById("hitokoto").innerHTML =yiyan.hitokoto;
								document.getElementById("from").innerHTML ="——《"+ yiyan.from+"》";
							 }
						};
						xmlhttp.open("GET", "https://v1.hitokoto.cn/?c=a&c=d&c=c", true);
						xmlhttp.send();
					</script>
				
			
				<br>
				  
					<p id="js-aboutme" style="margin:0 20px 0 20px;">just for fun</p>
				
			</div> 
		</div> 
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
  
  <!-- 代码块复制功能 -->
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.js"></script>
  <script type="text/javascript" src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
  <script type="text/javascript" src="/js/clipboard_use.js"></script>
  <!-- 代码块复制功能结束 -->
  
  <!--全局添加雪花特效 -->
  
  <!--全局添加雪花特效结束 -->

  <!--全局添加 aplayer播放器 https://aplayer.js.org/#/zh-Hans/ -->
  
  <!-- aplayer播放器功能结束 -->
  
</body>
