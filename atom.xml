<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jyh blog</title>
  
  
  <link href="https://wangtongyouwen.github.io/atom.xml" rel="self"/>
  
  <link href="https://wangtongyouwen.github.io/"/>
  <updated>2023-06-05T05:18:52.647Z</updated>
  <id>https://wangtongyouwen.github.io/</id>
  
  <author>
    <name>jyh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>优雅的使用rss打破信息茧房</title>
    <link href="https://wangtongyouwen.github.io/post/3e9dbae2.html"/>
    <id>https://wangtongyouwen.github.io/post/3e9dbae2.html</id>
    <published>2023-06-05T01:54:30.000Z</published>
    <updated>2023-06-05T05:18:52.647Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>当今世界信息错综复杂，获取信息的渠道也很多。我曾是一个忠实的b站用户，但是不得不说现在的b站变了味，似乎可能会出现下一个全新的信息源。打破信息茧房的最好方式，并不是找到一个单独的平台，而是找到那些独立的信息提供方，也就是说，我们需要一个跨平台，无广告，无推荐算法的全新方式获取更有广度，更有深度的信息。</p><p>最近看到了一个老但是又重新鲜活起来的新技术——RSS，详细的技术细节，可以自行百度。重点是这项技术能够实现以下几点：</p><ul><li>多平台信息源：各种信息源(微信公众号,b站,Twitter,blogs)</li><li>跨平台：windows,linux,os,etc</li><li>方便易用可拓展</li><li>能够充分利用碎片化时间</li></ul><p>你可以帮这项技术当做一个记事本，这个记事本能够定时刷新最新资讯：</p><ol type="1"><li>这个资讯不是推荐算法给你的，而是你自己订阅的</li><li>不局限于单个平台</li></ol><figure><img src="https://pic3.zhimg.com/80/v2-caf461e861957f5f2ecf6b654d989752_720w.webp" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h1 id="前置准备">前置准备</h1><ol type="1"><li><p>需要亿点点科学上网：知名在线 RSS 服务 Feedly（2018.11）、Inoreader（2020.4） 先后被墙，打着万物皆可RSS大旗的 RssHub 官方域名也被墙了（2020.3）</p></li><li><p>一个github账号(vercel搭建服务)</p></li><li><p>Google play 用于安装移动端软件</p></li><li><p>vercel 用于配置 RssHub 服务(后文详解)</p></li></ol><h1 id="基础玩法">基础玩法</h1><ol type="1"><li>找到RSS源</li></ol><p>https://github.com/weekend-project-space/top-rss-list</p><p>https://github.com/ChanceYu/front-end-rss</p><p>公共的RSS源很多，但是大部分都很老旧，国内的源质量不够，国外的源检索和阅读有一定障碍。</p><ol start="2" type="1"><li>找到一个合适的RSS阅读器</li></ol><p>https://www.inoreader.com/ 推荐</p><p>https://feedly.com/</p><h1 id="进阶玩法">进阶玩法</h1><h2 id="前置准备-1">1 前置准备</h2><p>1 RssHub生成源服务器配置 https://github.com/DIYgod/RSSHub</p><p>2 vercel 账号(github)可以直接登陆</p><p>3 RssHub-Radar 嗅取网页中存在的rss订阅 https://github.com/DIYgod/RSSHub-Radar</p><p>4 RSSAid 安卓端嗅取rss订阅 https://github.com/LeetaoGoooo/RSSAid</p><h2 id="rsshub">2 RssHub</h2><p>RSSHub 是一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源。RSSHub 借助于开源社区的力量快速发展中，目前已适配数百家网站的上千项内容</p><p>可以配合浏览器扩展 <a href="https://github.com/DIYgod/RSSHub-Radar">RSSHub Radar</a> 和 移动端辅助 App <a href="https://github.com/Cay-Zhang/RSSBud">RSSBud</a> (iOS) 与 <a href="https://github.com/LeetaoGoooo/RSSAid">RSSAid</a> (Android) 食用</p><p>首先介绍一下为什么需要自己部署RssHub服务？</p><p>Rss这种服务打击商业行为，所以许多网页会将其原本的域名直接屏蔽(本质也是一种爬虫)，所以只有使用自己的服务才不会被屏蔽，而且自己搭建的数据更加安全</p><ul><li>如何部署？</li></ul><p>https://docs.rsshub.app/install/</p><ul><li>如何使用vercel部署？(想象成一个云服务器，能够直接部署github上面的任何项目)</li></ul><ol type="1"><li>点击下面链接</li></ol><p>https://vercel.com/import/project?template=https://github.com/DIYgod/RSSHub</p><ol start="2" type="1"><li>完成一系列的注册后，一键部署(fork到自己的github仓库即可)</li><li>想要自动更新？</li></ol><p>https://github.com/apps/pull</p><ul><li>不会自己部署？提供下面的域名</li></ul><p><code>服务器1</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frsshub.rssforever.com%2F">https://rsshub.rssforever.com</a> <code>服务器2</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.qiuyuair.com%2F">https://rss.qiuyuair.com</a> <code>服务器3</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.injahow.cn%2F">https://rss.injahow.cn</a> <code>服务器4</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.feiyuyu.net%2F">https://rss.feiyuyu.net</a> <code>服务器5</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.shab.fun%2F">https://rss.shab.fun</a> <code>服务器6</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.itggg.cn%2F">https://rss.itggg.cn</a> <code>服务器7</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frsshub.uneasy.win%2F">https://rsshub.uneasy.win</a> <code>服务器8</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frss.injahow.cn%2F">https://rss.injahow.cn</a> <code>服务器9</code> ：<a href="https://sspai.com/link?target=https%3A%2F%2Frsshub.anyant.xyz%2F">https://rsshub.anyant.xyz</a></p><h2 id="rsshub-radar">3 RssHub-Radar</h2><ul><li>为什么需要构建RssHub服务器？</li></ul><p>配合Radar浏览器插件能够直接嗅探任何存在的RSS订阅(真的应有尽有)：RssHub提供路由，这个域名就由你自己搭建的服务来提供咯！</p><ul><li>如何使用Radar？</li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202306051249350.png" alt="image-20230605124920895" /><figcaption aria-hidden="true">image-20230605124920895</figcaption></figure><blockquote><p>注意这里只需要填入域名即可！</p></blockquote><p>以b站为例：</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202306051316754.png" alt="image-20230605125151705" /><figcaption aria-hidden="true">image-20230605125151705</figcaption></figure><p>你可以选择复制这个链接，或者直接subscribe, 注意这个subscribe必须要先登陆(在设置中找到目标网站，登陆后即可)</p><h2 id="feeddd订阅微信公众号">4 Feeddd订阅微信公众号</h2><p>由于微信自建生态，所以其中的信息比较难以获取rss订阅，但是通过<a href="https://hamibot.com/">Hamibot</a>能够动态获取推文(人工采集)</p><p>https://github.com/feeddd/feeds</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202306051316326.png" alt="image-20230605130927842" /><figcaption aria-hidden="true">image-20230605130927842</figcaption></figure><p>其实还有大量的公众号没有动态更新，所以单单微信这个生态而言，使用RSS是不方便的。</p><h1 id="end">end</h1><p>如果觉得RSS方便的话，一定要去star一下以上提到的所有项目，因为这是反商业化的，也是互联网精神的所在。</p><blockquote><p>rss才是真正的互联网精神的产物，正如开源一样，如何破除现有的信息茧房？并不是找到更多获取信息的渠道，而是打通blogger与user之间的通道！</p><p>less is more...</p></blockquote><p>more links:</p><p>https://sspai.com/post/75340</p><p>https://zhuanlan.zhihu.com/p/349349861</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;前言&lt;/h1&gt;
&lt;p&gt;当今世界信息错综复杂，获取信息的渠道也很多。我曾是一个忠实的b站用户，但是不得不说现在的b站变了味，似乎可能会出现下一个全新的信息源。打破信息茧房的最好方式，并不是找到一个单独的平台，而是找到那些独立的信息提供方，也就是说，我们需要</summary>
      
    
    
    
    <category term="tools" scheme="https://wangtongyouwen.github.io/categories/tools/"/>
    
    
    <category term="tools" scheme="https://wangtongyouwen.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>tips:github自动fork</title>
    <link href="https://wangtongyouwen.github.io/post/3627c7a8.html"/>
    <id>https://wangtongyouwen.github.io/post/3627c7a8.html</id>
    <published>2023-05-21T04:30:16.000Z</published>
    <updated>2023-05-23T15:50:54.453Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>在fork后的项目中新建：</li></ol><p>.github/workflows/main.yml</p><ol start="2" type="1"><li>在main.yml中输入：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Upstream</span> <span class="string">Sync</span></span><br><span class="line"></span><br><span class="line"><span class="attr">permissions:</span></span><br><span class="line">  <span class="attr">contents:</span> <span class="string">write</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">schedule:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">cron:</span> <span class="string">&quot;0 */12 * * *&quot;</span> <span class="comment"># every 12 hours</span></span><br><span class="line">  <span class="attr">workflow_dispatch:</span> <span class="comment"># manual sync</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">sync:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span> <span class="string">repo</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">ref:</span> <span class="string">master</span> <span class="comment"># [branch name]</span></span><br><span class="line">        <span class="attr">fetch-depth:</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configure</span> <span class="string">Git</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">        git config user.name &quot;GitHub Actions Bot&quot;</span></span><br><span class="line"><span class="string">        git config user.email &quot;email@xxx.com&quot;  # send email to you </span></span><br><span class="line"><span class="string"></span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Sync</span> <span class="string">with</span> <span class="string">upstream</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">        git remote add upstream https://github.com/[https locations]</span></span><br><span class="line"><span class="string">        git fetch upstream</span></span><br><span class="line"><span class="string">        git merge upstream/master --no-edit</span></span><br><span class="line"><span class="string">        git push</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;在fork后的项目中新建：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;.github/workflows/main.yml&lt;/p&gt;
&lt;ol start=&quot;2&quot; type=&quot;1&quot;&gt;
&lt;li&gt;在main.yml中输入：&lt;/li&gt;
&lt;/ol&gt;
&lt;fi</summary>
      
    
    
    
    <category term="tips" scheme="https://wangtongyouwen.github.io/categories/tips/"/>
    
    <category term="github" scheme="https://wangtongyouwen.github.io/categories/tips/github/"/>
    
    
    <category term="tips" scheme="https://wangtongyouwen.github.io/tags/tips/"/>
    
    <category term="github" scheme="https://wangtongyouwen.github.io/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>pytorch项目6-语音合成</title>
    <link href="https://wangtongyouwen.github.io/post/2b566acf.html"/>
    <id>https://wangtongyouwen.github.io/post/2b566acf.html</id>
    <published>2023-05-06T11:09:28.000Z</published>
    <updated>2023-05-07T14:45:27.541Z</updated>
    
    <content type="html"><![CDATA[<h1 id="conditional-variational-autoencoder-with-adversarial-learning-for-end-to-end-text-to-speech">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</h1><p>http://proceedings.mlr.press/v139/kim21f/kim21f.pdf</p><h2 id="论文概述">1 论文概述</h2><p>在这项工作中，作者提出了一种并行的<strong>端到端文本到语音</strong>（TTS）方法，其生成的音频比当前的两阶段TTS系统更自然。这种方法采用了增强正规化流的变分推断和对抗训练过程，从而提高了生成建模的表达能力。此外，作者还提出了一种随机持续时间预测器，用于从输入文本合成具有多样节奏的语音。</p><p>通过对潜在变量的不确定性建模和随机持续时间预测器，该方法表达了自然的一对多关系，即输入文本可以以不同的音高和节奏以多种方式发音。在LJ语音（单一发音者数据集）上进行的主观人类评估（平均意见分数，MOS）表明，该方法优于目前最好的公开可用TTS系统，并实现了与基准真实数据相当的MOS。</p><p>总之，作者提出了一种端到端的TTS方法，采用<strong>变分推断</strong>、<strong>正规化流</strong>和<strong>对抗训练</strong>过程，生成更自然的音频。通过<strong>随机持续时间预测器</strong>和隐变量的不确定性建模，该方法能够实现文本到语音的<strong>自然一对多关系</strong>。实验结果表明，该方法在性能上优于现有的TTS系统，并在主观评估中取得了令人满意的成绩。</p><ul><li>过去研究：文本-&gt;频谱-&gt;波形</li><li>现在：文本-&gt;波形</li></ul><p>提出的方法主要在前三个小节中描述：条件变分自编码器（VAE）的公式化；从变分推断中得出的对齐估计；用于提高合成质量的对抗性训练。</p><ol type="1"><li><strong>条件变分自编码器</strong>（Conditional VAE）公式化：VITS模型采用了条件变分自编码器作为基本框架，通过引入潜在变量来捕捉输入文本的多样性，并进行端到端训练。</li><li><strong>变分推断中的对齐估计</strong>（Alignment Estimation）：VITS模型利用变分推断方法推导出与语音特征对齐的潜在变量表示，这有助于在生成过程中更好地捕捉文本与语音之间的对应关系。</li><li><strong>改进合成质量的对抗训练</strong>（Adversarial Training）：为了提高合成语音的质量，VITS模型采用了对抗训练方法，在生成过程中对抗性地优化生成器和判别器。</li></ol><p>整体架构包括文本编码器、持续时间预测器、潜在变量推断器、语音解码器和对抗性判别器等组件。通过联合训练这些组件，<strong>VITS</strong>模型可以在端到端的设置下实现高质量的文本到语音合成。</p><h2 id="method">2 method</h2><h3 id="conditional-vae">2.1 conditional VAE</h3><p><span class="math display">\[\log p_\theta(x|c)\ge\mathbb{E}_{q_\phi(z|x)}\Big[\log p_\theta(x|z)-\log\frac{q_\phi(z|x)}{p_\theta(z|c)}\Big]\]</span></p><p>左边：需要最大化的目标似然 x:目标(语音波形)，c:条件(text，说话人的音色)</p><p>右边：elbo(evidence lower bound) 如果是纯flow是能够得到解析式的 【重构器-KL散度:后验分布/先验分布】</p><p>最大化elbo：1. 解码器(重构器)在给定隐变量z的情况下，x对应的最大似然</p><ol start="2" type="1"><li>最小化KL散度：后验与先验之间的距离，<span class="math inline">\(\phi\)</span>模型在给定目标的条件下的分布与<span class="math inline">\(\theta\)</span>模型在给定条件下的分布越接近越好</li></ol><h4 id="一般的vae目标函数推导">一般的VAE目标函数推导</h4><ol type="1"><li><span class="math inline">\(P(X)=\int_{z} P(X|z)\times P(z)\)</span> <span class="math inline">\(X\)</span>为目标函数，<span class="math inline">\(Z\)</span>为隐变量，此处为对联合分布进行积分得到边缘分布</li><li>对于大部分<span class="math inline">\(z\)</span>,我们计算出来的<span class="math inline">\(P(X|z)\)</span>为0，因此需要缩小<span class="math inline">\(z\)</span>的样本空间，此处借用另外一个分布<span class="math inline">\(Q(z|X)\)</span>来缩小<span class="math inline">\(z\)</span>的样本空间(或者说增大<span class="math inline">\(z\)</span>产生<span class="math inline">\(X\)</span>的可能性)，并且当<span class="math inline">\(z\)</span>服从分布<span class="math inline">\(Q(z|X)\)</span>时，再计算<span class="math inline">\(P(X|z)\)</span>的期望值比较简单</li><li>那么，当<span class="math inline">\(z\)</span>服从分布<span class="math inline">\(Q(z|X)\)</span>时，<span class="math inline">\(P(X|z)\)</span>的期望值与目标数据的分布<span class="math inline">\(P(X)\)</span>之间是什么关系呢？可以用一个KL散度公式算起：<span class="math inline">\(D[Q(z|X)||P(z|X)]\)</span></li></ol><p><span class="math display">\[D[Q(z|X)||P(z|X)] = \mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X)-\log P(z|X)]\]</span></p><ol start="4" type="1"><li>为了引出<span class="math inline">\(P(X)\)</span>，可以基于贝叶斯公式来改写<span class="math inline">\(P(z|X)\)</span></li></ol><p><span class="math display">\[p(z|X)=\frac{P(z,X)}{P(X)}=\frac{P(X|z)\times P(z)}{P(X)}\]</span></p><ol start="5" type="1"><li>这时KL散度可以重新写成:</li></ol><p><span class="math display">\[D[Q(z|X)||P(z|X)]=\mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X)-\log P(X|z) -\log P(z)+\log P(X)]\]</span></p><ol start="6" type="1"><li><p>因为其中的<span class="math inline">\(P(X)\)</span>与<span class="math inline">\(z\sim Q(z|X)\)</span>无关，因此可以移到期望公式外面;同时，由于: <span class="math display">\[D[Q(z|X)||P(z)]=\mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X)-\log P(z)]\]</span></p><ol start="7" type="1"><li>KL散度进一步改写成</li></ol></li></ol><p><span class="math display">\[D[Q(z|X)||P(z|X)]=-\mathbb{E}_{z\sim Q(z|X)}[\log P(X|z)] + D[Q(z|X)||P(z)]+\log P(X)\]</span></p><ol start="8" type="1"><li>因此</li></ol><p><span class="math display">\[\log P(X)-\textcolor{red}{D[Q(z|X)||P(z|X)]} =\mathbb{E}_{z\sim Q(z|X)}[\log P(X|z)] - D[Q(z|X)||P(z)]\]</span></p><ol start="9" type="1"><li>红色部分恒大于0，故</li></ol><p><span class="math display">\[\log P(X) \ge \mathbb{E}_{z\sim Q(z|X)}[\log P(X|z)] - D[Q(z|X)||P(z)]\]</span></p><p>​ 当且仅当<span class="math inline">\(Q(z|X)\)</span>可以逼近<span class="math inline">\(P(z|X)\)</span>等式成立</p><ol start="10" type="1"><li><p>目标数据的对数似然公式下界如式(8)所示，并且右边第一项是解码器，第二项是先验分布<span class="math inline">\(P(z)\)</span>与后验分布<span class="math inline">\(Q(z|X)\)</span>之间的距离</p></li><li><p>如果希望<span class="math inline">\(\log P(X)\)</span>越大越好，也就是相当于希望解码器基于<span class="math inline">\(z\)</span>分布预测<span class="math inline">\(X\)</span>的概率越大越好，同时先验分布<span class="math inline">\(P(z)\)</span>与后验分布<span class="math inline">\(Q(z|X)\)</span>之间的距离越小越好</p></li></ol><h4 id="vits中的条件vae目标函数推导">VITS中的条件VAE目标函数推导</h4><ol type="1"><li>在本文中，我们可以从KL散度公式算起</li></ol><p><span class="math display">\[D[Q(z|X)||P(z|X,c)] = \mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X) - log P(z|X,c)]\]</span></p><ol start="2" type="1"><li>类似的，我们可以yoga贝叶斯公式来改写$ P(z|X,c)$</li></ol><p><span class="math display">\[P(z|X,c) = \frac{P(z,X|c)}{P(X|c)}=\frac{P(X|z)\times P(z|c)}{P(X|c)}\]</span></p><ol start="3" type="1"><li>于是KL散度可以重新写成:</li></ol><p><span class="math display">\[D[Q(z|X)||P(z|X,c)] = \mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X) - log P(X|z)-\log P(z|c)] + \log P(X|c)\]</span></p><p>​ 因为<span class="math inline">\(P(X|c)\)</span>与<span class="math inline">\(z\sim Q(z|X)\)</span>无关，因此可以移到期望公式之外</p><ol start="4" type="1"><li>同时，由于：</li></ol><p><span class="math display">\[D[Q(z|X)||P(z|c)] = \mathbb{E}_{z\sim Q(z|X)}[\log Q(z|X) -\log P(z|c)]\]</span></p><p>​ KL散度式(9)可以进一步化解为： <span class="math display">\[D[Q(z|X)||P(z|X,c)] = -\mathbb{E}_{z\sim Q(z|X)}[log P(X|z)] + D[Q(z|X)||P(z|c)] + \log P(X|c)\]</span></p><ol start="5" type="1"><li>因此</li></ol><p><span class="math display">\[\log P(X|c) -\textcolor{red}{D[Q(z|X)||P(z|X,c)]} = \mathbb{E}_{z\sim Q(z|X)}[log P(X|z)] -D[Q(z|X)||P(z|c)]\]</span></p><p>红色部分是恒大于0，所以得到: <span class="math display">\[\log P(X|c)  \ge \mathbb{E}_{z\sim Q(z|X)}[log P(X|z)] -D[Q(z|X)||P(z|c)]\]</span> 当且仅当<span class="math inline">\(Q(z|X)\)</span>可以逼近<span class="math inline">\(P(z|X,c)\)</span>时，等式成立</p><ol start="6" type="1"><li>VITS的目标数据的对数似然公式下界中：</li></ol><ul><li><span class="math inline">\(X\)</span>表示音频的梅尔频谱</li><li><span class="math inline">\(c\)</span>表示<strong>文本信息和对其信息</strong>，<span class="math inline">\(z\)</span>表示隐含变量。其中，对齐信息是一个<span style="color:olive">硬对齐矩阵，形状为[|text|,|z|]</span><span class="math inline">\(\textcolor{olive}{}\)</span></li><li>文中提到，发现在<span class="math inline">\(P(z|c)\)</span>表示成简单的高斯分布之后再加一个flow变换，音质效果更好</li></ul><h4 id="重构loss右边等式第一项">重构loss(右边等式第一项)</h4><p>在重构损失中，作者使用了梅尔频谱图（mel-spectrogram）作为目标数据点，而不是原始波形。梅尔频谱图用<span class="math inline">\(X_{mel}\)</span>表示</p><p>这里的关键点是：</p><ol type="1"><li>使用梅尔频谱图作为目标数据点，而不是原始波形。</li><li>将潜在变量<span class="math inline">\(z\)</span>上采样到波形域<span class="math inline">\(\hat y\)</span>。</li><li>将波形域<span class="math inline">\(\hat y\)</span>转换为梅尔频谱图域<span class="math inline">\(\hat X_{mel}\)</span>。</li><li>使用预测和目标梅尔频谱图之间的<span class="math inline">\(L1\)</span>损失作为重构损失。</li></ol><p><span class="math display">\[L_{\text{recon}} = ||X_{mel}-\hat X_{mel}||\]</span></p><p>这可以看作是在假设数据分布为拉普拉斯分布的情况下进行的<strong>最大似然估计</strong>，同时忽略了常数项。通过使用近似于人类听觉系统响应的<strong>梅尔刻度</strong>，将<strong>重构损失定义在梅尔频谱图域以提高感知质量</strong>。注意，从原<strong>始波形估计梅尔频谱图不需要可训练参数</strong>，因为它只使用STFT和线性投影到梅尔刻度。此外，估计仅在训练期间使用，而不是在推理期间使用。在实践中，我们不会对整个潜在变量<span class="math inline">\(z\)</span>进行上采样，而是将部分序列用作解码器的输入，这是用于高效端到端训练的窗口生成器训练。</p><p>这段话的关键点包括：</p><ol type="1"><li>重构损失可以看作是在假设拉普拉斯分布的情况下进行的最大似然估计。</li><li>在梅尔频谱图域定义重构损失，以提高感知质量。</li><li>从原始波形估计梅尔频谱图不需要可训练参数。</li><li>在实践中，仅将部分潜在变量序列用作解码器的输入，以实现高效的端到端训练。</li></ol><h4 id="kl散度右边等式第二项">KL散度(右边等式第二项)</h4><ol type="1"><li>先验编码器的输入条件<span class="math inline">\(c\)</span>由音素<span class="math inline">\(c_{text}\)</span>和音素与潜在变量之间的对齐<span class="math inline">\(A\)</span>组成。(因为文本和音素之间不可能是一一对应的，单个文本可能存在多个音素)</li><li>对齐是一个硬单调注意力矩阵，表示每个输入音素扩展的长度以便与目标语音进行时间对齐。</li><li>在训练迭代中需要估计对齐。</li><li>为了提供更高分辨率的信息，使用线性刻度频谱图<span class="math inline">\(X_{lin}\)</span>作为输入，而不是<strong>梅尔频谱图</strong>。修改后的输入并不违反变分推断的属性。</li></ol><p><span class="math display">\[L_{kl}=\log q_{\phi} (z|X_{lin}) - \log p_{\theta} (z|c_{text},A) \\z \sim q_{\phi}(z|X_{lin}) = N (z;\mu_{\phi}(X_{lin}),\sigma_{\phi}(X_{lin}))\]</span></p><p><span class="math inline">\(z\)</span>是从后验分布中采样得到的，这是一个高斯分布。</p><p><span class="math inline">\(X\)</span>没有用波形频谱(复杂)，也没有用梅尔谱(相对简单)，而是采用了线性刻度频谱</p><p>我们使用因子化正态分布来参数化先验和后验编码器。我们发现增加先验分布的表达能力对于生成逼真的样本很重要。因此，我们在因子化正态先验分布的基础上应用<strong>归一化流</strong>，它允许将一个简单分布通过可逆变换转换成一个更复杂的分布，遵循变量变换规则： <span class="math display">\[p_\theta(z|c)=N(f_\theta(z);\mu_{\theta}(c))\left|\text{det}\frac{\partial f_\theta(z)}{\partial z}\right| \\c=[c_{text},A]\]</span></p><h3 id="alignment-estimation">2.2 Alignment Estimation</h3><h5 id="mas">MAS</h5><p>为了在输入文本和目标语音之间估计对齐关系A，我们采用了<strong>单调对齐搜索</strong>(Monotonic Alignment Search，MAS)，这是一种通过正则化流参数化的数据似然最大化来搜索对齐关系的方法。 <span class="math display">\[\begin{aligned}A &amp; =\underset{\hat{A}}{\arg \max } \log p\left(X \mid c_{\text {text }}, \hat{A}\right) \\&amp; =\underset{\hat{A}}{\arg \max } \log N\left(f(x) ; \mu\left(c_{\text {text }}, \hat{A}\right), \sigma\left(c_{\text {text }}, \hat{A}\right)\right)\end{aligned}\]</span> MAS利用了单调性假设，即输入文本中的字符和目标语音中的帧之间的对齐关系是单调的。这使得搜索过程更加高效，因为只需要在单调增加的路径上搜索。</p><ul><li>monotonic(单调)</li><li>non-skipping</li></ul><p>在我们的设置中直接应用MAS是困难的，因为我们的目标是ELBO（变分下界），而不是精确的对数似然。因此，我们重新定义MAS，使其寻找最大化ELBO的对齐关系，这可以简化为寻找最大化潜变量对数似然的对齐关系。</p><p>为了实现这一目标，我们可以在训练过程中根据<strong>当前模型参数来迭代更新对齐关系</strong>。在每次迭代过程中，我们通过最大化ELBO来调整对齐关系，并相应地更新模型参数。</p><p>这种方法允许我们在优化变分下界的同时，学习输入文本与目标语音之间的对齐关系。通过这种方式，我们可以在训练过程中逐渐改进模型的性能，并在推理阶段生成更自然的语音样本。</p><p><span class="math display">\[\begin{array}{l}\underset{\hat{A}}{\arg \max } \log p_{\theta}\left(X_{\text {mel }} \mid z\right)-\log \frac{q_{\phi}\left(z \mid x_{\text {lin }}\right)}{p_{\theta}\left(z \mid c_{\text {text }}, \hat{A}\right)} =\underset{\hat{A}}{\arg \max } \log p_{\theta}\left(z \mid c_{\text {text }}, \hat{A}\right)=\log N\left(f_{\theta}(z) ; \mu_{\theta}\left(c_{\text {text }}, \hat{A}\right), \sigma_{\theta}\left(c_{\text {text }}, \hat{A}\right)\right)\end{array}\]</span></p><h5 id="duration-prediction-from-text--时长模型">DURATION PREDICTION FROM TEXT--时长模型</h5><p>我们可以通过对估计对齐矩阵 <span class="math inline">\(A\)</span> 的每一行中的所有列求和来计算每个输入令牌的持续时间 <span class="math inline">\(d_i\)</span>：<span class="math inline">\(\sum_j A_{i,j}\)</span>. 该持续时间可以用来训练一个确定性的持续时间预测器，如之前的工作所提出的（Kim et al., 2020），但它不能表达一个人每次以不同语速发音的方式。为了生成类似于人类的语音节奏，我们设计了一个随机持续时间预测器，使其样本遵循给定条件变分自编码器在对抗学习环境下进行端到端文本转语音的音素持续时间分布。随机持续时间预测器是一个基于流的生成模型，通常通过最大似然估计进行训练。然而，直接应用最大似然估计是困难的，因为每个输入音素的持续时间是1）一个离散的整数，需要进行去量化以使用连续的归一化流，以及2）一个标量，由于可逆性限制了高维变换。我们应用变分去量化（Flow++）和变分数据增强（VFlow）来解决这些问题。</p><p>具体来说，我们引入了两个随机变量 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(\nu\)</span>，它们具有与持续时间序列 d 相同的时间分辨率和维度，用于变分去量化和变分数据增强。我们将 <span class="math inline">\(u\)</span> 的支持限制在 [0, 1) 之间，以使差值 d−u 变成一组正实数，并将 <span class="math inline">\(\nu\)</span> 和 d 逐通道地连接，以形成更高维的潜在表示。我们通过近似后验分布 <span class="math inline">\(q_{\phi}(u,\nu|d,c_{text})\)</span> 对这两个变量进行采样。所得到的目标是音素持续时间对数似然的变分下界： <span class="math display">\[\begin{gathered}\log p_{\theta}(d|c_{t e x t})\ge \mathbb{E}_{q_{\phi}(u,\nu|d,c_{t e x t})}\Big[\operatorname{log}\frac{p_{\theta}(d-u,\nu|c_{t e x t})}{q_{\phi}(u,\nu|d,c_{t e x t})}\Big] \end{gathered}\]</span> 持续时间训练损失 <span class="math inline">\(L_{dur}\)</span> 是负变分下界。我们将停止梯度运算符应用于输入条件，以防止将输入的梯度反向传播，从而使持续时间预测器的训练不影响其他模块的训练。</p><p>采样过程相对简单；通过随机噪声经过随机持续时间预测器的逆变换，对音素持续时间进行采样，然后将其转换为整数。</p><h3 id="adversarial-training">2.3 Adversarial Training</h3><p>为了在我们的学习系统中采用对抗性训练，我们添加了一个鉴别器<span class="math inline">\(D\)</span>，用于区分生成器<span class="math inline">\(G\)</span>生成的输出和真实波形<span class="math inline">\(y\)</span>。在这项工作中，我们使用了两种在语音合成中成功应用的损失类型；用于对抗性训练的最小平方损失函数，以及用于训练生成器的额外特征匹配损失：</p><p><span class="math display">\[\begin{gathered}L_{adv}(D) =\mathbb{E}_{(y,z)}\Big[(D(y)-1)^{2}+(D(G(z)))^{2}\Big],  \\L_{adv}(G) =\mathbb{E}_z\Big[(D(G(z))-1)^2\Big],  \\L_{fm}(G) =\mathbb{E}_{(y,z)}\Big[\sum\limits_{l=1}^T\frac{1}{N_l}\|D^l(y)-D^l(G(z))\|_1\Big]\end{gathered}\]</span></p><h3 id="final-loss">2.4 final loss</h3><p><span class="math display">\[L_{vae} = L_{recon} +L_{kl} +L_{dur} +L_{adv}(G) +L_{fm}(G)\]</span></p><h2 id="architecture">3 architecture</h2><p>整个建议模型的架构包括后验编码器、先验编码器、解码器、鉴别器和随机持续时间预测器。后验编码器和鉴别器仅用于训练，而不是用于推理。</p><h3 id="后验编码器">3.1 后验编码器</h3><p>对于后验编码器，使用 WaveGlow 和 Glow-TTS 中使用的非因果 WaveNet 残差块。</p><p>WaveNet 残差块由带有门控激活单元和跳过连接的膨胀卷积层组成。块上方的线性投影层产生正态后验分布的均值和方差。对于多说话者情况，我们在残差块中使用全局条件化添加说话者嵌入。</p><h3 id="先验编码器">3.2 先验编码器</h3><p>先验编码器由处理输入音素 <span class="math inline">\(c_{text}\)</span> 的文本编码器和改善先验分布灵活性的归一化流 <span class="math inline">\(f_\theta\)</span> 组成。文本编码器是一个变压器编码器，它使用相对位置表示而不是绝对位置编码。我们可以通过文本编码器从 <span class="math inline">\(c_{text}\)</span> 获取隐藏表示 <span class="math inline">\(h_{text}\)</span>，并通过文本编码器上方的线性投影层产生用于构造先验分布的均值和方差。归一化流是由 WaveNet 残差块堆叠组成的仿射耦合层的堆叠)。为简化起见，我们设计归一化流为具有雅可比行列式为一的体积保持变换。对于多说话者设置，我们通过全局调节将说话者嵌入添加到归一化流中的残差块。</p><h3 id="解码器">3.3 解码器</h3><p>解码器本质上是 HiFi-GAN V1 生成器。它由一堆转置卷积组成，每个转置卷积后面都跟着一个多感受野融合模块（MRF）。MRF 的输出是具有不同接收字段大小的残差块输出的和。对于多说话者设置，我们添加一个线性层，将说话者嵌入转换并将其添加到输入潜变量<span class="math inline">\(z\)</span>。</p><h3 id="判别器">3.4 判别器</h3><p>我们遵循 HiFi-GAN 提出的<strong>多周期鉴别器的鉴别器架构</strong>。多周期鉴别器是一种马尔可夫窗口为基础的子鉴别器的混合，每一个子鉴别器都在不同周期模式的输入波形上操作。</p><h3 id="随机时长预测器">3.5 随机时长预测器</h3><p>随机持续时间预测器根据条件输入 <span class="math inline">\(h_{text}\)</span> 估计<strong>音素持续时间</strong>的分布。为了有效地参数化随机持续时间预测器，我们堆叠具有<strong>膨胀和深度可分离卷积层</strong>的残差块。我们还将神经样条流应用于耦合层，这些神经样条流采用单调有理二次样条实现可逆非线性变换。与常用的仿射耦合层相比，神经样条流在参数数量相似的情况下提高了变换的表达能力。对于多说话者设置，我们添加一个线性层，将说话者嵌入转换并将其添加到输入 <span class="math inline">\(h_{text}\)</span> 中。</p><h2 id="code">4 code</h2><p>https://github.com/jaywalnut310/vits</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;conditional-variational-autoencoder-with-adversarial-learning-for-end-to-end-text-to-speech&quot;&gt;Conditional Variational Autoencoder wit</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/categories/pytorch/project/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络13-Glow</title>
    <link href="https://wangtongyouwen.github.io/post/c5690277.html"/>
    <id>https://wangtongyouwen.github.io/post/c5690277.html</id>
    <published>2023-05-06T10:56:32.000Z</published>
    <updated>2023-05-07T14:45:27.545Z</updated>
    
    <content type="html"><![CDATA[<h1 id="glow-generative-flow-with-invertible-11-convolutions">Glow: Generative Flow with Invertible 11 Convolutions</h1><p>https://proceedings.neurips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf</p><p>在这篇论文中，作者提出了一种名为Glow的流式生成模型。流式生成模型（Flow-based generative models）在计算精确对数似然（log-likelihood）、进行精确的潜在变量推断以及并行化训练和合成方面具有概念上的吸引力。Glow模型采用了一种可逆的 1×1 卷积操作，该方法相对简单。</p><p>通过使用Glow模型，作者在标准基准测试中实现了对数似然的显著改进。更令人瞩目的是，作者证明了优化纯对数似然目标的基于流的生成模型能够高效地生成和操作大型图像，且生成的图像具有逼真的外观。这表明，Glow这种类型的流式生成模型在生成逼真图像方面具有很大的潜力。</p><ul><li>显式表示目标分布</li><li>可逆</li></ul><p>数据的分布：得到对应的似然(给定模型下，数据的似然)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;glow-generative-flow-with-invertible-11-convolutions&quot;&gt;Glow: Generative Flow with Invertible 11 Convolutions&lt;/h1&gt;
&lt;p&gt;https://proceed</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>pytorch项目5-CLIP搭建相似图像检索系统</title>
    <link href="https://wangtongyouwen.github.io/post/342f7c36.html"/>
    <id>https://wangtongyouwen.github.io/post/342f7c36.html</id>
    <published>2023-05-05T11:22:46.000Z</published>
    <updated>2023-05-06T07:13:23.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备工作">1 准备工作</h2><h3 id="clip模型的调用">1.1 clip模型的调用</h3><p>https://github.com/openai/CLIP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda install --<span class="built_in">yes</span> -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install ftfy regex tqdm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install git+https://github.com/openai/CLIP.git</span></span><br></pre></td></tr></table></figure><p><code>clip.available_models()</code> Returns the names of the available CLIP models.</p><h3 id="准备数据集">1.2 准备数据集</h3><p>与项目三中使用相同的数据集，这个数据集的划分代码略 <a href="https://wangtongyouwen.github.io/post/4627104a.html">[pytorch项目3-基于ResNet的水果蔬菜分类](https://wangtongyouwen.github.io/post/4627104a.html)</a></p><h2 id="train.py">2 train.py</h2><h3 id="get_args_parser">2.1 get_args_parser()</h3><p>这部分是为了能够接收从命令行中读取的参数，其中最关键的是几个数据的路径：训练样本，测试样本，输出的结果照片以及推断出的模型feature_dict</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_args_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;image search task&#x27;</span>, add_help=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># Model parameters</span></span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_size&#x27;</span>, default=<span class="number">128</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;images input size&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dateset_dir&#x27;</span>, default=<span class="string">&#x27;./dataset_fruit_veg/train&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to load images &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--test_image_dir&#x27;</span>, default=<span class="string">&#x27;./dataset_fruit_veg/val_images&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;images to test, split by comma &quot;,&quot;&#x27;</span>)  <span class="comment"># split from the test dataset, there is no Crossover</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_dir&#x27;</span>, default=<span class="string">&#x27;./output_di&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to save, empty for no saving&#x27;</span>) <span class="comment"># 相似照片</span></span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--model_name&#x27;</span>,default=<span class="string">&#x27;resnet50&#x27;</span>, <span class="comment"># resnet50,resnet152,clip</span></span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;model name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--feature_dict_file&#x27;</span>,default=<span class="string">&#x27;corpus_feature_dict,npy&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;filename where to save image representations&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--topk&#x27;</span>,default=<span class="number">7</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;k most similar image representations&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mode&#x27;</span>,default=<span class="string">&#x27;extract&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;extract or predict, for extracting features or predicting similar images from corpus&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser</span><br></pre></td></tr></table></figure><h3 id="main">2.2 main</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model_names = timm.list_models(pretrained=<span class="literal">True</span>)</span><br><span class="line">    args = get_args_parser()</span><br><span class="line">    args = args.parse_args()</span><br><span class="line"></span><br><span class="line">    model = <span class="literal">None</span></span><br><span class="line">    preprocess = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.model_name != <span class="string">&quot;clip&quot;</span>:</span><br><span class="line">        model = timm.create_model(args.model_name, pretrained=<span class="literal">True</span>)  <span class="comment"># resnet50 resnet152</span></span><br><span class="line">        n_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;number of trainable params (M): %.2f&quot;</span> % (n_parameters / <span class="number">1.e6</span>))</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model, preprocess = clip.load(<span class="string">&quot;ViT-B/32&quot;</span>, device=device)  <span class="comment"># preprocess就是已经归一化后的结果，无需再进行归一化操作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&quot;extract&quot;</span>:</span><br><span class="line">        <span class="comment"># 第一阶段：图像表征提取</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;use pretrained model <span class="subst">&#123;args.model_name&#125;</span> to extract features&quot;</span>)</span><br><span class="line">        allVectors = extract_features(args, model, image_path=args.dataset_dir, preprocess=preprocess)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 第二阶段：图像检索</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;use pretrained model <span class="subst">&#123;args.model_name&#125;</span> to search <span class="subst">&#123;args.topk&#125;</span> similar images from corpus&quot;</span>)</span><br><span class="line"></span><br><span class="line">        test_images = glob.glob(os.path.join(args.test_image_dir, <span class="string">&quot;*.png&quot;</span>))</span><br><span class="line">        test_images += glob.glob(os.path.join(args.test_image_dir, <span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">        test_images += glob.glob(os.path.join(args.test_image_dir, <span class="string">&quot;*.jpeg&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># loading image representation dictionary</span></span><br><span class="line">        allVectors = np.load(<span class="string">f&quot;<span class="subst">&#123;args.save_dir&#125;</span>/<span class="subst">&#123;args.model_name&#125;</span>/<span class="subst">&#123;args.feature_dict_file&#125;</span>&quot;</span>, allow_pickle=<span class="literal">True</span>)  <span class="comment"># 导入字典</span></span><br><span class="line">        allVectors = allVectors.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reading test images</span></span><br><span class="line">        <span class="keyword">for</span> image_file <span class="keyword">in</span> tqdm.tqdm(test_images):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;image_file&#125;</span>...&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> args.model_name == <span class="string">&quot;clip&quot;</span>:</span><br><span class="line">                <span class="comment"># CLIP model</span></span><br><span class="line">                allVectors[image_file] = extract_feature_by_CLIP(model, preprocess, image_file)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># resnet50, resnet152</span></span><br><span class="line">                allVectors[image_file] = extract_feature_single(args, model, image_file)</span><br><span class="line"></span><br><span class="line">        sim, keys = getSimilarityMatrix(allVectors)</span><br><span class="line">        <span class="built_in">print</span>(keys)</span><br><span class="line">        result = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> image_file <span class="keyword">in</span> tqdm.tqdm(test_images):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;sorting most similar images as <span class="subst">&#123;image_file&#125;</span>...&quot;</span>)</span><br><span class="line">            index = keys.index(image_file)</span><br><span class="line">            sim_vec = sim[index]</span><br><span class="line"></span><br><span class="line">            indexs = np.argsort(sim_vec)[::-<span class="number">1</span>][<span class="number">1</span>:args.topk]  <span class="comment"># 排序：从小到大的索引</span></span><br><span class="line">            simImages, simScores = [], []</span><br><span class="line">            <span class="keyword">for</span> ind <span class="keyword">in</span> indexs:</span><br><span class="line">                simImages.append(keys[ind])</span><br><span class="line">                simScores.append(sim_vec[ind])</span><br><span class="line">            result[image_file] = (simImages, simScores)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;starting to show similar images...&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> image_file <span class="keyword">in</span> test_images:</span><br><span class="line">            plotSimilarImages(args, image_file, result[image_file][<span class="number">0</span>], result[image_file][<span class="number">1</span>], numRow=<span class="number">1</span>,</span><br><span class="line">                              numCol=args.topk)</span><br></pre></td></tr></table></figure><ul><li>判断模型是resnet50，resnet152 or clip</li><li>判断模式是否是 extract or predict</li></ul><p>predict: 部分代码的步骤：</p><ol type="1"><li>读取图片，判断模型类型，读取特征字典</li><li>将目标图片与特征图片中的所有值做余弦相似度比较，得到的结果矩阵：allvector</li><li>排序，取出前n个目标</li><li>把图片地址和图片计算得到的score储存，最后进行输出</li></ol><h2 id="extract">3 extract</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_feature_single</span>(<span class="params">args, model, file</span>):</span><br><span class="line">    img_rgb = Image.<span class="built_in">open</span>(file).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">    image = img_rgb.resize((args.input_size, args.input_size), Image.LANCZOS)</span><br><span class="line">    image = torchvision.transforms.ToTensor()(image)</span><br><span class="line"></span><br><span class="line">    trainset_mean = [<span class="number">0.4729932</span>, <span class="number">0.43474569</span>, <span class="number">0.3264319</span>]</span><br><span class="line">    trainset_std = [<span class="number">0.37707761</span>, <span class="number">0.36121109</span>, <span class="number">0.34872371</span>]</span><br><span class="line"></span><br><span class="line">    image = torchvision.transforms.Normalize(mean=trainset_mean, std=trainset_std)(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        features = model.forward_features(image)</span><br><span class="line">        vec = model.global_pool(features)</span><br><span class="line">        vec = vec.squeeze().numpy()</span><br><span class="line"></span><br><span class="line">    img_rgb.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vec</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>这部分代码将先对图像进行归一化，然后在模型的forward_features层输出特征，在进入池化层最后得到代表图片的字典信息。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_feature_by_CLIP</span>(<span class="params">model, preprocess, file</span>):</span><br><span class="line">    image = preprocess(Image.<span class="built_in">open</span>(file)).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        vec = model.encode_image(image)</span><br><span class="line">        vec = vec.squeeze().cpu().numpy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vec</span><br></pre></td></tr></table></figure><ul><li>使用CLIP中的encode_image输出特征信息</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">args, model, image_path=<span class="string">&quot;&quot;</span>, preprocess=<span class="literal">None</span></span>):</span><br><span class="line">    allVectors = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image_file <span class="keyword">in</span> tqdm.tqdm(glob.glob(os.path.join(image_path, <span class="string">&quot;*&quot;</span>, <span class="string">&quot;*.jpg&quot;</span>))):  <span class="comment"># image_path:train # tqdm:进度条</span></span><br><span class="line">        <span class="keyword">if</span> args.model_name == <span class="string">&quot;clip&quot;</span>:</span><br><span class="line">            allVectors[image_file] = extract_feature_by_CLIP(model, preprocess, image_file)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            allVectors[image_file] = extract_feature_single(args, model, image_file)</span><br><span class="line"></span><br><span class="line">    os.makedirs(<span class="string">f&quot;<span class="subst">&#123;args.save_dir&#125;</span>/<span class="subst">&#123;args.model_name&#125;</span>&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    np.save(<span class="string">f&quot;<span class="subst">&#123;args.save_dir&#125;</span>/<span class="subst">&#123;args.model_name&#125;</span>/<span class="subst">&#123;args.feature_dict_file&#125;</span>&quot;</span>, allVectors)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> allVectors</span><br></pre></td></tr></table></figure><h2 id="计算余弦相似度">4 计算余弦相似度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算余弦相似度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getSimilarityMatrix</span>(<span class="params">vectors_dict</span>):</span><br><span class="line">    v = np.array(<span class="built_in">list</span>(vectors_dict.values()))  <span class="comment"># [NUM,H]</span></span><br><span class="line">    numerator = np.matmul(v, v.T)  <span class="comment"># [NUM,NUM]</span></span><br><span class="line">    denominator = np.matmul(np.linalg.norm(v, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>),</span><br><span class="line">                            np.linalg.norm(v, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>).T)  <span class="comment"># [NUM,NUM]</span></span><br><span class="line"></span><br><span class="line">    sim = numerator / denominator</span><br><span class="line">    keys = <span class="built_in">list</span>(vectors_dict.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sim, keys</span><br></pre></td></tr></table></figure><h2 id="绘制结果">5 绘制结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">setAxes</span>(<span class="params">ax, image, query=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    value = kwargs.get(<span class="string">&quot;value&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> query:</span><br><span class="line">        ax.set_xlabel(<span class="string">&quot;Query Image\n&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(image), fontsize=<span class="number">12</span>)</span><br><span class="line">        ax.xaxis.label.set_color(<span class="string">&quot;red&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ax.set_xlabel(<span class="string">&quot;score=&#123;1:1.3f&#125;\n&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(image, value), fontsize=<span class="number">12</span>)</span><br><span class="line">        ax.xaxis.label.set_color(<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotSimilarImages</span>(<span class="params">args, image, simImages, simValues, numRow=<span class="number">1</span>, numCol=<span class="number">4</span></span>):</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="comment"># set width and height in inches</span></span><br><span class="line"></span><br><span class="line">    fig.set_size_inches(<span class="number">18.5</span>, <span class="number">10.5</span>)</span><br><span class="line">    fig.suptitle(<span class="string">f&quot;use engine model: <span class="subst">&#123;args.model_name&#125;</span>&quot;</span>, fontsize=<span class="number">35</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, numCol * numRow):</span><br><span class="line">        ax = []</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            img = Image.<span class="built_in">open</span>(image)</span><br><span class="line">            ax = fig.add_subplot(numRow, numCol, <span class="number">1</span>)</span><br><span class="line">            setAxes(ax, image.split(os.sep)[-<span class="number">1</span>], query=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            img = Image.<span class="built_in">open</span>(simImages[j - <span class="number">1</span>])</span><br><span class="line">            ax.append(fig.add_subplot(numRow,numCol,j+<span class="number">1</span>))</span><br><span class="line">            setAxes(ax[-<span class="number">1</span>],<span class="string">&quot;_&quot;</span>.join(simImages[j-<span class="number">1</span>].split(os.sep)[-<span class="number">2</span>:]),value=simValues[j-<span class="number">1</span>])</span><br><span class="line">            <span class="comment"># truncated_filename = &quot;&quot;.join(simImages[j - 1].split(os.sep)[-2:])</span></span><br><span class="line">            <span class="comment"># truncated_filename = truncated_filename[:15]  # 只显示前 15 个字符</span></span><br><span class="line">            <span class="comment"># setAxes(ax[-1], truncated_filename, value=simValues[j - 1])</span></span><br><span class="line">        img = img.convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        plt.imshow(img)</span><br><span class="line">        img.close()</span><br><span class="line">    fig.savefig(<span class="string">f&quot;<span class="subst">&#123;args.save_dir&#125;</span>/<span class="subst">&#123;args.model_name&#125;</span>_search_top_<span class="subst">&#123;args.topk-<span class="number">1</span>&#125;</span>_<span class="subst">&#123;image.split(os.sep)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]&#125;</span>.png&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><ul><li>这部分展示代码具有参考性，可以用来动态显示结果。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;准备工作&quot;&gt;1 准备工作&lt;/h2&gt;
&lt;h3 id=&quot;clip模型的调用&quot;&gt;1.1 clip模型的调用&lt;/h3&gt;
&lt;p&gt;https://github.com/openai/CLIP&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;ta</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/categories/pytorch/project/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>pytorch进阶2-autoregressive diffusion model</title>
    <link href="https://wangtongyouwen.github.io/post/954ae01.html"/>
    <id>https://wangtongyouwen.github.io/post/954ae01.html</id>
    <published>2023-05-04T09:59:09.000Z</published>
    <updated>2023-05-05T11:57:57.886Z</updated>
    
    <content type="html"><![CDATA[<p>Improved Denoising Diffusion Probabilistic Models</p><p>http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf</p><p>Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting</p><p>http://proceedings.mlr.press/v139/rasul21a/rasul21a.pdf</p><p>Denoising Diffusion Probabilistic Models</p><p>https://arxiv.org/pdf/2006.11239.pdf</p><h2 id="回顾">回顾</h2><h3 id="如何将扩散模型与自回归模型结合">1 如何将扩散模型与自回归模型结合？</h3><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041925965.png" alt="image-20230504192539224" /><figcaption aria-hidden="true">image-20230504192539224</figcaption></figure><p>目标函数发生了变化： <span class="math display">\[\mathbb{E}_{\mathbf{x}^0_t,\epsilon,n}\left[\|\epsilon-\epsilon_\theta(\sqrt{\bar{\alpha}_n}\mathbf{x}^0_t+\sqrt{1-\bar{\alpha}_n}\epsilon,\mathbf{h}_{t-1},n)\|^2\right],\]</span> <img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041930347.png" alt="image-20230504192959481" /></p><ul><li><p>为什么使用采样？而不是按照顺序</p><p>这是与随机梯度下降算法相同，目的是为了使训练更加鲁棒</p></li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041932387.png" alt="image-20230504193228721" /><figcaption aria-hidden="true">image-20230504193228721</figcaption></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041943539.png" alt="image-20230504194302000" /><figcaption aria-hidden="true">image-20230504194302000</figcaption></figure><h3 id="improved-denoising-diffusion-probabilistic-models">2 Improved Denoising Diffusion Probabilistic Models</h3><ul><li>可学习的方差<span class="math inline">\(\sum_\theta(x_t,t)\)</span></li><li>噪声方案的改进</li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041946113.png" alt="image-20230504194648255" /><figcaption aria-hidden="true">image-20230504194648255</figcaption></figure><ul><li>损失函数的改进</li></ul><p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305041948618.png" alt="image-20230504194753966" /> <span class="math display">\[L_{hybrid} = L_{simple} + \lambda L_{vlb}\]</span></p><h3 id="思维导图">3 思维导图</h3><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305042024133.png" alt="image-20230504202447257" /><figcaption aria-hidden="true">image-20230504202447257</figcaption></figure><h2 id="代码分析">代码分析</h2><p>https://github.com/openai/improved-diffusion</p><h3 id="image_train.py">1 image_train.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_argparser</span>():</span><br><span class="line">    defaults = <span class="built_in">dict</span>(</span><br><span class="line">        data_dir=<span class="string">&quot;&quot;</span>,</span><br><span class="line">        schedule_sampler=<span class="string">&quot;uniform&quot;</span>,</span><br><span class="line">        lr=<span class="number">1e-4</span>,</span><br><span class="line">        weight_decay=<span class="number">0.0</span>,</span><br><span class="line">        lr_anneal_steps=<span class="number">0</span>,</span><br><span class="line">        batch_size=<span class="number">1</span>,</span><br><span class="line">        microbatch=-<span class="number">1</span>,  <span class="comment"># -1 disables microbatches</span></span><br><span class="line">        ema_rate=<span class="string">&quot;0.9999&quot;</span>,  <span class="comment"># comma-separated list of EMA values</span></span><br><span class="line">        log_interval=<span class="number">10</span>,</span><br><span class="line">        save_interval=<span class="number">10000</span>,</span><br><span class="line">        resume_checkpoint=<span class="string">&quot;&quot;</span>,</span><br><span class="line">        use_fp16=<span class="literal">False</span>,</span><br><span class="line">        fp16_scale_growth=<span class="number">1e-3</span>,</span><br><span class="line">    )</span><br><span class="line">    defaults.update(model_and_diffusion_defaults())</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    add_dict_to_argparser(parser, defaults)</span><br><span class="line">    <span class="keyword">return</span> parser</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_dict_to_argparser</span>(<span class="params">parser, default_dict</span>):</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> default_dict.items():</span><br><span class="line">        v_type = <span class="built_in">type</span>(v)</span><br><span class="line">        <span class="keyword">if</span> v <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            v_type = <span class="built_in">str</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(v, <span class="built_in">bool</span>):</span><br><span class="line">            v_type = str2bool</span><br><span class="line">        parser.add_argument(<span class="string">f&quot;--<span class="subst">&#123;k&#125;</span>&quot;</span>, default=v, <span class="built_in">type</span>=v_type)</span><br></pre></td></tr></table></figure><ul><li>这一部分的代码可以在命令行中传参进行简化：传入一个字典自动解析。从字典中自动生成argument parser</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    args = create_argparser().parse_args()</span><br><span class="line"></span><br><span class="line">    dist_util.setup_dist()</span><br><span class="line">    logger.configure()</span><br><span class="line"></span><br><span class="line">    logger.log(<span class="string">&quot;creating model and diffusion...&quot;</span>)</span><br><span class="line">    model, diffusion = create_model_and_diffusion(</span><br><span class="line">        **args_to_dict(args, model_and_diffusion_defaults().keys())</span><br><span class="line">    )</span><br><span class="line">    model.to(dist_util.dev())</span><br><span class="line">    schedule_sampler = create_named_schedule_sampler(args.schedule_sampler, diffusion)</span><br><span class="line"></span><br><span class="line">    logger.log(<span class="string">&quot;creating data loader...&quot;</span>)</span><br><span class="line">    data = load_data(</span><br><span class="line">        data_dir=args.data_dir,</span><br><span class="line">        batch_size=args.batch_size,</span><br><span class="line">        image_size=args.image_size,</span><br><span class="line">        class_cond=args.class_cond,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    logger.log(<span class="string">&quot;training...&quot;</span>)</span><br><span class="line">    TrainLoop(</span><br><span class="line">        model=model,</span><br><span class="line">        diffusion=diffusion,</span><br><span class="line">        data=data,</span><br><span class="line">        batch_size=args.batch_size,</span><br><span class="line">        microbatch=args.microbatch,</span><br><span class="line">        lr=args.lr,</span><br><span class="line">        ema_rate=args.ema_rate,</span><br><span class="line">        log_interval=args.log_interval,</span><br><span class="line">        save_interval=args.save_interval,</span><br><span class="line">        resume_checkpoint=args.resume_checkpoint,</span><br><span class="line">        use_fp16=args.use_fp16,</span><br><span class="line">        fp16_scale_growth=args.fp16_scale_growth,</span><br><span class="line">        schedule_sampler=schedule_sampler,</span><br><span class="line">        weight_decay=args.weight_decay,</span><br><span class="line">        lr_anneal_steps=args.lr_anneal_steps,</span><br><span class="line">    ).run_loop()</span><br></pre></td></tr></table></figure><p>传参-&gt;获得模型-&gt;获得数据-&gt;训练</p><p>...improved-diffusion-main_diffusion_util.py</p><h3 id="create_model_and_diffusion">2 create_model_and_diffusion</h3><h4 id="create_gaussian_diffusion">2.1 create_gaussian_diffusion</h4><ul><li>生成扩散过程的模型框架</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_gaussian_diffusion</span>(<span class="params"></span></span><br><span class="line"><span class="params">    *,</span></span><br><span class="line"><span class="params">    steps=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">    learn_sigma=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    sigma_small=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    noise_schedule=<span class="string">&quot;linear&quot;</span>,</span></span><br><span class="line"><span class="params">    use_kl=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    predict_xstart=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    rescale_timesteps=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    rescale_learned_sigmas=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    timestep_respacing=<span class="string">&quot;&quot;</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    betas = gd.get_named_beta_schedule(noise_schedule, steps)</span><br><span class="line">    <span class="keyword">if</span> use_kl:</span><br><span class="line">        loss_type = gd.LossType.RESCALED_KL</span><br><span class="line">    <span class="keyword">elif</span> rescale_learned_sigmas:</span><br><span class="line">        loss_type = gd.LossType.RESCALED_MSE</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_type = gd.LossType.MSE</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> timestep_respacing:</span><br><span class="line">        timestep_respacing = [steps]</span><br><span class="line">    <span class="keyword">return</span> SpacedDiffusion(</span><br><span class="line">        use_timesteps=space_timesteps(steps, timestep_respacing),</span><br><span class="line">        betas=betas,</span><br><span class="line">        model_mean_type=(</span><br><span class="line">            gd.ModelMeanType.EPSILON <span class="keyword">if</span> <span class="keyword">not</span> predict_xstart <span class="keyword">else</span> gd.ModelMeanType.START_X</span><br><span class="line">        ),</span><br><span class="line">        model_var_type=(</span><br><span class="line">            (</span><br><span class="line">                gd.ModelVarType.FIXED_LARGE</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> sigma_small</span><br><span class="line">                <span class="keyword">else</span> gd.ModelVarType.FIXED_SMALL</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> learn_sigma</span><br><span class="line">            <span class="keyword">else</span> gd.ModelVarType.LEARNED_RANGE</span><br><span class="line">        ),</span><br><span class="line">        loss_type=loss_type,</span><br><span class="line">        rescale_timesteps=rescale_timesteps,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ol type="1"><li>get_named_beta_schedule 生成betas的策略 linear increasing/cosine</li><li>class SpacedDiffusion(GaussianDiffusion)</li><li>GaussianDiffusion</li></ol><p>:param betas: a 1-D numpy array of betas for each diffusion timestep,starting at T and going to 1. :param model_mean_type: a ModelMeanType determining what the model outputs. :param model_var_type: a ModelVarType determining how variance is output. :param loss_type: a LossType determining the loss function to use. :param rescale_timesteps: if True, pass floating point timesteps into the model so that they are always scaled like in the original paper (0 to 1000).</p><ol start="4" type="1"><li>p_mean_variance</li><li>_vb_terms_bpd</li><li>training_losses</li></ol><h4 id="unet">2.2 Unet</h4><p>详见Unet(笔记)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Improved Denoising Diffusion Probabilistic Models&lt;/p&gt;
&lt;p&gt;http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf&lt;/p&gt;
&lt;p&gt;Autoregressiv</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="diffusion model" scheme="https://wangtongyouwen.github.io/categories/pytorch/diffusion-model/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="diffusion model" scheme="https://wangtongyouwen.github.io/tags/diffusion-model/"/>
    
  </entry>
  
  <entry>
    <title>pytorch进阶1-DDPM</title>
    <link href="https://wangtongyouwen.github.io/post/8c9cf490.html"/>
    <id>https://wangtongyouwen.github.io/post/8c9cf490.html</id>
    <published>2023-05-03T11:07:37.000Z</published>
    <updated>2023-05-05T11:57:57.889Z</updated>
    
    <content type="html"><![CDATA[<p>Denoising Diffusion Probabilistic Models</p><p>https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf</p><p>Deep Unsupervised Learning using Nonequilibrium Thermodynamics</p><p>http://proceedings.mlr.press/v37/sohl-dickstein15.pdf</p><h2 id="生成模型">1 生成模型</h2><ul><li>seq2seq</li><li>gan</li><li>flow（数学推理严谨）</li><li>VAE</li><li>diffusion model</li></ul><h2 id="条件概率公式与高斯分布的kl散度">2 条件概率公式与高斯分布的KL散度</h2><h3 id="条件概率的一般形式">2.1 条件概率的一般形式</h3><p><span class="math display">\[P(A,B,C)=P(C|B,A)P(B,A) = P(C|B,A)P(B|A)P(A) \\P(B,C|A) = P(B|A)P(C|A,B)\]</span></p><h3 id="基于马尔科夫假设的条件概率">2.2 基于马尔科夫假设的条件概率</h3><p>如果满足马尔科夫链关系 A-&gt;B-&gt;C,那么有： <span class="math display">\[P(A,B,C)=P(C|B,A)P(B,A)=P(C|B)P(B|A)P(A) \\P(B,C|A)=P(B|A)P(C|B)\]</span></p><h3 id="高斯分布的kl散度公式">2.3 高斯分布的KL散度公式</h3><p>对于两个单一变量的高斯分布p和q而言，他们的KL散度为 <span class="math display">\[KL(p,q) = log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}\]</span></p><h3 id="参数重整化">2.4 参数重整化</h3><p>若希望从高斯分布<span class="math inline">\(N(\mu,\sigma^2)\)</span>中采样，可以先从标准分布<span class="math inline">\(N(0,1)\)</span>采样出<span class="math inline">\(z\)</span>，再得到<span class="math inline">\(\sigma*z+\mu\)</span>。这样做的好处是将随机性转移到了<span class="math inline">\(z\)</span>这个变量上，而<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma\)</span>则当做仿射变换网络的一部分</p><h2 id="vae与多层vae回顾">3 VAE与多层VAE回顾</h2><p>https://zhuanlan.zhihu.com/p/34998569</p><h3 id="单层vae的原理公式与置信下界">3.1 单层VAE的原理公式与置信下界</h3><p><span class="math display">\[p(x)=\int_z p_{\theta}(x|z)p(z)\\p(x)=\int_z q_{\phi}(z|x) \frac{p_{\theta}(x|z)p(z)}{q_{\phi}(z|x)} \\\log p(x)=\log \mathbb{E}_{z \sim q_{\phi}(z \mid x)}\left[\frac{p_{\theta}(x \mid z) p(z)}{q_{\phi}(z \mid x)}\right] \\\log p(x) \geq \mathbb{E}_{z \sim q_{\phi}(z \mid x)}\left[\log \frac{p_{\theta}(x \mid z) p(z)}{q_{\phi}(z \mid x)}\right]\]</span></p><h3 id="多层vae的原理公式与置信下界">3.2 多层VAE的原理公式与置信下界</h3><p><span class="math display">\[\begin{array}{c}p(x)=\int_{z_{1}} \int_{z_{2}} p_{\theta}\left(x, z_{1}, z_{2}\right) d z_{1}, d z_{2} \\p(x)=\iint q_{\phi}\left(z_{1}, z_{2} \mid x\right) \frac{p_{\theta}\left(x, z_{1}, z_{2}\right)}{q_{\phi}\left(z_{1}, z_{2} \mid x\right)} \\p(x)=\mathbb{E}_{z_{1}, z_{2} \sim q_{\phi}\left(z_{1}, z_{2} \mid x\right)}\left[\frac{p_{\theta}\left(x, z_{1}, z_{2}\right)}{q_{\phi}\left(z_{1}, z_{2} \mid x\right)}\right] \\\log p(x) \geq \mathbb{E}_{z_{1}, z_{2} \sim q_{\phi}\left(z_{1}, z_{2} \mid x\right)}\left[\log \frac{p_{\theta}\left(x, z_{1}, z_{2}\right)}{q_{\phi}\left(z_{1}, z_{2} \mid x\right)}\right] \\p\left(x, z_{1}, z_{2}\right)=p\left(x \mid z_{1}\right) p\left(z_{1} \mid z_{2}\right) p\left(z_{2}\right) \\q\left(z_{1}, z_{2} \mid x\right)=q\left(z_{1} \mid x\right) q\left(z_{2} \mid z_{1}\right) \\\mathcal{L}(\theta, \phi)=\mathbb{E}_{q(21,2 q \mid x)}\left[\log p\left(x \mid z_{1}\right)-\log q\left(z_{1} \mid x\right)+\log p\left(z_{1} \mid z_{2}\right)-\log q\left(z_{2} \mid z_{1}\right)+\log p\left(z_{2}\right)\right]\end{array}\]</span></p><h2 id="diffusion-model">4 diffusion model</h2><p>从目标分布中，希望能找到逆扩散过程的规律，然后利用这个规律将任意噪声恢复。</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305032040155.png" alt="image-20221112164034826" /><figcaption aria-hidden="true">image-20221112164034826</figcaption></figure><h3 id="前向过程">4.1 前向过程</h3><p>不断往数据中加入噪声，最后得到了纯噪声（扩散过程）</p><p>每个时刻都要添加高斯噪声，后一时刻都是有前一时刻增加噪声得到的；</p><p>其实这个过程可以看作不断<strong>构建标签</strong>（噪声）的过程</p><ol type="1"><li>给定初始数据分布<span class="math inline">\(x_0 \thicksim q(x)\)</span>,可以不断向分布中添加高斯噪声，该噪声的标准差是以固定值<span class="math inline">\(\beta_t\)</span>而确定的，均值是以固定值值<span class="math inline">\(\beta_t\)</span>和当前t时刻的数据<span class="math inline">\(x_t\)</span>决定的。这个过程是一个马尔科夫链过程。</li><li>随着t的不断增大，最终数据分布<span class="math inline">\(x_T\)</span>变成了一个各向独立的高斯分布。</li></ol><p>Given a data point sampled from a real data distribution <span class="math inline">\(x_0 \thicksim q(x)\)</span>,let us define a forward diffusion process in which we add small amount of Gaussian noise to the sample in <span class="math inline">\(T\)</span> steps, producing a sequence of noisy samples <span class="math inline">\(x_1,\dots,x_T\)</span>. The step sizes are controlled by a variance schedule <span class="math inline">\({\beta_t \in (0,1)}^t_{t=1}\)</span></p><p>给定一个从真实数据分布中采样的数据点<span class="math inline">\(x_0 \thicksim q(x)\)</span>，让我们定义一个向前扩散过程，在该过程中，我们在<span class="math inline">\(T\)</span>步中向样本添加少量的高斯噪声，产生一系列噪声样本<span class="math inline">\(x_1，\dots，x_T\)</span>。步长由方差时间表<span class="math inline">\({\beta_t \in (0,1)}^t_{t=1}\)</span>控制。 <span class="math display">\[q(X_t|X_{t-1})=\N(X_t;\sqrt{1-\beta_t}X_{t-1},\beta_t I) \\q(X_{1:T}|X_0) = \prod^T_{t=1} q(X_t|X_{t-1})\]</span> The data sample <span class="math inline">\(x_0\)</span> gradually loses its distinguishable features as the step <span class="math inline">\(t\)</span> becomes larger. Eventually when <span class="math inline">\(T \rightarrow \infty,X_T\)</span> is euivalent to an isotropic Gaussian distribution</p><p>随着步骤<span class="math inline">\(t\)</span>变得更大，数据样本<span class="math inline">\(x_0\)</span>逐渐失去其可区分的特征。最终当<span class="math inline">\(T \rightarrow \infty\)</span>时，<span class="math inline">\(X_T\)</span>等同于各向同性的高斯分布。</p><ol start="3" type="1"><li>任何时刻的<span class="math inline">\(q(X_t)\)</span>推导也可以完全基于<span class="math inline">\(x_0\)</span>和<span class="math inline">\(\beta _t\)</span>来计算出来，而不需要做迭代</li></ol><p>注意这里，两个正态分布 <span class="math inline">\(X\thicksim N(\mu_1,\sigma_1)\)</span> 和 <span class="math inline">\(Y\thicksim N(\mu_2,\sigma_2)\)</span>的叠加后的分布<span class="math inline">\(aX+bY\)</span>的均值为<span class="math inline">\(a\mu_1+b\mu_2\)</span>，方差为<span class="math inline">\(a^2\sigma_1^2+b^2\sigma_2^2\)</span>，所以<span class="math inline">\(\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}z_{t-2}+\sqrt{1-\alpha_tz_{t-1}}z_{t-1}\)</span>可以参数重整化为只含有一个随机变量<span class="math inline">\(z\)</span>构成的<span class="math inline">\(\sqrt{1-\alpha_t\alpha_{t-1}}z\)</span>的形式</p><h4 id="第一个公式如何得到x_t时刻的分布前向过程">第一个公式，如何得到<span class="math inline">\(X_t\)</span>时刻的分布（前向过程）？</h4><p><span class="math display">\[\alpha _t = 1- \beta_t\]</span></p><p>式（6）中<span class="math inline">\(\beta_t\)</span>表示图像的加入噪声的程度，随着训练的进行要逐渐增大，论文中从0.0001到0.002扩大。 <span class="math display">\[x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}z_1\]</span> 式(7)中<span class="math inline">\(z_1\)</span>表示噪声（高斯噪声） <span class="math display">\[\begin{align}          x_t &amp; = \sqrt{\alpha _t}(\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}z_{2})+\sqrt{1-\alpha_t}z_1 \\           &amp; = \sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\bar z_2 \\           &amp; = \sqrt{\bar \alpha_t}x_0+\sqrt{1-\bar \alpha_t} z_t          \end{align}\]</span> 其中<span class="math inline">\(z_1和z_2\)</span>分别表示<span class="math inline">\(N(0,1-\alpha_t)和N(0,\alpha_t(1-\alpha_{t-1}))\)</span>，独立同分布可相加得到，最后的<span class="math inline">\(\bar z_2\)</span></p><p>其中<span class="math inline">\(\bar \alpha_t\)</span>表示累乘<span class="math inline">\(\bar \alpha_t=\alpha_1\cdot \alpha_2 \cdot \dots \alpha_{t-1}\cdot \alpha_{t}\)</span> <span class="math display">\[q(X_t|X_0) = \N(X_t;\sqrt{\bar \alpha_t}X_0,(1-\bar \alpha_t)I)\]</span> Usually, we can afford a larger update step when the sample gets noisier, so <span class="math inline">\(\beta_1&lt;\beta_2&lt;...&lt;\beta_T\)</span> and therfore <span class="math inline">\(\bar \alpha_1 &gt; \dots \bar \alpha_T\)</span></p><h3 id="逆向过程">4.2 逆向过程</h3><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305032044361.png" alt="image-20221112171756756" /><figcaption aria-hidden="true">image-20221112171756756</figcaption></figure><p>逆过程是从高斯噪声中恢复原始数据，我们可以假设它也是一个高斯分布，但是无法逐步地去拟合分布，所以需要构建一个参数分布来去做估计。逆扩散过程仍然是一个马尔科夫链过程。 <span class="math display">\[p_\theta(X_{0:T}) = p(X_T)\prod^T_{t=1}p_\theta(X_{t-1}|X_t)\\p_\theta(X_{t-1}|X_t) = \N (X_{t-1};\mu_{\theta}(X_t,t),\Sigma_{\theta}(x_t,t))\]</span> If we can reverse the above process and sample from <span class="math inline">\(q(X_{t-1}|X_t)\)</span>, we will be able to recreate the true sample from a Gaussian noise input, <span class="math inline">\(X_T \thicksim \mathcal{N}(0,I)\)</span>. Note that if <span class="math inline">\(\beta_t\)</span> is small enough, <span class="math inline">\(q(X_{t-1}|X_t)\)</span> will also be Gaussian. Unfortunately, we cannot easily estimate <span class="math inline">\(q(X_{t-1}|X_t)\)</span> because it needs to use the entire dataset adn therefore we need to learn a model <span class="math inline">\(p_\theta\)</span> to approximate these conditional probabilities in order to run reverse diffusion process.</p><p>如果我们能够逆转上述过程并从<span class="math inline">\(q(X_{t-1}|X_t)\)</span>中抽样，我们将能够从高斯噪声输入<span class="math inline">\(X_T \thicksim \mathcal{N}(0,I)\)</span>中重建真实样本。请注意，如果<span class="math inline">\(\beta_t\)</span>足够小，<span class="math inline">\(q(X_{t-1}|X_t)\)</span>也将是高斯分布。不幸的是，我们无法轻易估计<span class="math inline">\(q(X_{t-1}|X_t)\)</span>，因为它需要使用整个数据集，因此我们需要学习一个模型<span class="math inline">\(p_\theta\)</span>来逼近这些条件概率，以便运行反向扩散过程。</p><h3 id="后验的扩散条件概率">4.3 后验的扩散条件概率</h3><p><span class="math inline">\(q(X_{t-1}|X_t,X_0)\)</span>分布式可以用公式表示的，可就是说给定<span class="math inline">\(X_t,X_0\)</span>，就能够计算出<span class="math inline">\(X_{t-1}\)</span> <span class="math display">\[q(X_{t-1}|X_t) = \N(X_{t-1};\bar \mu(X_t,X_0),\bar \beta_t I)\]</span></p><p><span class="math display">\[q(X_{t-1}|X_t,X_0)=q(X_t|X_{t-1},X_0)\frac{q(X_{t-1}|X_0)}{q((X_t|X_0))}\]</span></p><p><span class="math display">\[q(X_{t-1}|X_0)\Longrightarrow    \sqrt{\bar \alpha_{t-1}}x_0+\sqrt{1-\bar \alpha_{t-1}}z \sim N(\sqrt{\bar \alpha_{t-1}}x_0,1-\bar \alpha_{t-1})\]</span></p><p><span class="math display">\[q(X_{t}|X_0)\Longrightarrow  \sqrt{\bar \alpha_{t}}x_0+\sqrt{1-\bar \alpha_{t}}z \sim N(\sqrt{\bar \alpha_{t}}x_0,1-\bar \alpha_{t})\]</span></p><p><span class="math display">\[q(X_{t}|X_{t-1},X_0)\Longrightarrow  \sqrt{ \alpha_{t}}x_{t-1}+\sqrt{1- \alpha_{t}}z \sim N(\sqrt{ \alpha_{t}}x_0,1- \alpha_{t})\]</span></p><p>将式(16~18)代入式(15)得： <span class="math display">\[q(X_{t-1}|X_t,X_0)\propto \exp \left(-\frac{1}{2}\left(\frac{\left(\mathbf{x}_{t}-\sqrt{\alpha_{t}} \mathbf{x}_{t-1}\right)^{2}}{\beta_{t}}+\frac{\left(\mathbf{x}_{t-1}-\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0}\right)^{2}}{1-\bar{\alpha}_{t-1}}-\frac{\left(\mathbf{x}_{t}-\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}\right)^{2}}{1-\bar{\alpha}_{t}}\right)\right)\]</span></p><p><span class="math display">\[\begin{array}{l}=\exp \left(-\frac{1}{2}\left(\frac{\mathbf{x}_{t}^{2}-2 \sqrt{\alpha_{t}} \mathbf{x}_{t} \mathbf{x}_{t-1}+\alpha_{t} \mathbf{x}_{t-1}^{2}}{\beta_{t}}+\frac{\mathbf{x}_{t-1}^{2}-2 \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0} \mathbf{x}_{t-1}+\bar{\alpha}_{t-1} \mathbf{x}_{0}^{2}}{1-\bar{\alpha}_{t-1}}-\frac{\left(\mathbf{x}_{t}-\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}\right)^{2}}{1-\bar{\alpha}_{t}}\right)\right) \\=\exp \left(-\frac{1}{2}\left(\left(\frac{\alpha_{t}}{\beta_{t}}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) \mathbf{x}_{t-1}^{2}-\left(\frac{2 \sqrt{\alpha_{t}}}{\beta_{t}} \mathbf{x}_{t}+\frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_{0}\right) \mathbf{x}_{t-1}+C\left(\mathbf{x}_{t}, \mathbf{x}_{0}\right)\right)\right) \end{array}\]</span></p><p><span class="math display">\[\exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)=\exp \left(-\frac{1}{2}\left(\frac{1}{\sigma^{2}} x^{2}-\frac{2 \mu}{\sigma^{2}} x+\frac{\mu^{2}}{\sigma^{2}}\right)\right)\]</span></p>由式(20)可知： $$<span class="math display">\[\begin{cases}\bar \beta_t = \frac{1}{\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar \alpha_{t-1}}} = \frac{1-\bar \alpha_{t-1}}{1-\bar \alpha_t} \cdot \beta_t  \\\bar\mu_t(X_t,X_0)=\frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_{t}} \mathbf{x}_{t}+\frac{\sqrt{\bar{\alpha}_{t-1}} \beta_{t}}{1-\bar{\alpha}_{t}} \mathbf{x}_{0} \\\end{cases}\]</span><p>$$</p><p>其中: <span class="math display">\[x_0=\frac{1}{\sqrt{\bar\alpha_t}}(x_t-\sqrt{1-\bar \alpha_t}z_t)\]</span> 将<span class="math inline">\(x_0\)</span>代入式（22）最终得到<span class="math inline">\(\tilde{\mu}_{t}\)</span></p><p><span class="math display">\[\tilde{\mu}_{t}=\frac{1}{\sqrt{a_{t}}}\left(x_{t}-\frac{\beta_{t}}{\sqrt{1-\bar{a}_{t}}} {z}_{t}\right)\]</span> 其中<span class="math inline">\(z_t\)</span>是什么？是估计的每个时刻的噪声，即<span class="math inline">\(X_T\)</span>时刻的噪声</p><ul><li>虽然无法直接求解，但是能通过训练一个模型进行计算</li><li>采用Unet模型</li><li>模型的输入参数为当前时刻的分布和时刻t</li><li>模型的真实结果其实是由前向过程中添加的noise标签（显然是已知的）</li></ul><h3 id="目标数据分布的似然函数">4.4 目标数据分布的似然函数</h3><p>我们可以在负对数似然函数的基础上加上一个KL散度，于是就构成了负对数似然的上界，上界越小，负对数似然自然也就越小，那么对数似然就越大了 <span class="math display">\[\begin{aligned}-\log p_{\theta}({\mathbf x}_{0})&amp; \leq-\log p_\theta(\mathbf{x}_0)+D_{\mathrm{KL}}(q(\mathbf{x}_{1:T}|\mathbf{x}_0)\|p_\theta(\mathbf{x}_{1:T}|\mathbf{x}_0))  \\&amp;=-\log p_\theta(\mathbf{x}_0)+\mathbb{E}_{\mathbf{x}_1:T\sim q(\mathbf{x}_1:T|\mathbf{x}_0)}\left[\log\dfrac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})/p_\theta(\mathbf{x}_0)}\right] \\&amp;=-\log p_\theta\mathfrak{(x}_0)+\mathbb{E}_q\Big[\log\dfrac{q(\mathbf{x}_1:T|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0:T)}+\log p_\theta(\mathbf{x}_0)\Big] \\&amp;=\mathbb{E}_q\Big[\log\dfrac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})}\Big] \\\mathrm{Let}~L_{\mathrm{VLB}}&amp; =\mathbb{E}_{q(\mathbf{x}_0:T)}\Big[\log\dfrac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0:T)}\Big]\geq-\mathbb{E}_{q(\mathbf{x}_0)}\log p_\theta(\mathbf{x}_0) \end{aligned}\]</span> 进一步可以写出如上公式的交叉熵的上界，接下来，对交叉熵的上界进行化简 <span class="math display">\[q(X_t|X_{t-1}) =q(X_t|X_{t-1},X_0) = \frac{q(X_t,X_{t-1},X_0)}{q(X_{t-1},X_0)}=\frac{q(X_{t-1}|X_t,X_0)q(X_t|X_0)q(X_0)}{q(X_{t-1},X_0)}=\frac{q(X_{t-1}|X_t,X_0)q(X_t|X_0)}{q(X_{t-1}|X_0)}\]</span></p><p><span class="math display">\[\begin{aligned}L_{\mathrm{VLB}}&amp; =\mathbb{E}_{q(\mathbf{x}_{0:T)}}\Big[\log\frac{q(\mathbf{x}_{1:T}|\mathbf{x}_{0})}{p_{\theta}(\mathbf{x}_{0:T})}\Big]  \\&amp;=\mathbb{E}_{q}\Big[\log{\frac{\prod_{t=1}^{T}q(\mathbf{x}_{t}|\mathbf{x}_{t-1})}{p_{\theta}(\mathbf{x}_{T})\prod_{t=1}^{T}p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}}\Big] \\&amp;=\mathbb{E}_q\Big[-\log p_\theta(\mathbf{x}_T)+\sum_{t=1}^T\log\dfrac{q(\mathbf{x}_t|\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}\Big] \\&amp;=\mathbb{E}_q\Big[-\log p_\theta(\mathbf{x}_T)+\sum_{t=2}^T\log\dfrac{q(\mathbf{x}_t|\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}+\log\dfrac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x_k})}\Big] \\&amp;=\mathbb{E}_q\Big[-\log p_\theta(\mathbf{x}_T)+\sum_{t=2}^T\log\Big(\dfrac{q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}\cdot\dfrac{q(\mathbf{x}_t|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)}\Big)+\log\dfrac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)}\Big] \\&amp;=\mathbb{E}_q\Big[-\log p_\theta(\mathbf{x}_T)+\sum_{t=2}^T\log\dfrac{q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}+\sum_{t=2}^T\log\dfrac{q(\mathbf{x}_t|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)}+\log\dfrac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)}\Big] \\&amp;=\mathbb{E}_q\Big[-\log p_\theta(\mathbf{x}_T)+\sum\limits_{=2}^T\log\dfrac{q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}+\log\dfrac{q(\mathbf{x}_T|\mathbf{x}_0)}{q(\mathbf{x}_1|\mathbf{x}_0)}+\log\dfrac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)}\Big] \\&amp;=\mathbb{E}_q\Big[\log\dfrac{q(\mathbf{x}_T|\mathbf{x}_0)}{p_\theta(\mathbf{x}_T)}+\sum\limits_{t=2}^T\log\dfrac{q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}-\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)\Big] \\&amp;=\mathbb{E}_q[\underbrace{D_{\mathrm{KL}}(q(\mathbf{x}_T|\mathbf{x}_0)\parallel p_\theta(\mathbf{x}_T))}_{L_T}+\sum_{t=2}^T\underbrace{D_{\mathrm{KL}}(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\parallel p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))}_{L_{t-1}}-\underbrace{\log p_0(\mathbf{x}_0|\mathbf{x}_1)]}_{L_0}\end{aligned}\]</span></p><p>这里论文将<span class="math inline">\(p_{\theta}(X_{t-1}|X_t)\)</span>分布的方差设置为一个与<span class="math inline">\(\beta\)</span>相关的常数，因此可训练的参数值存在于其均值中</p><p>对于两个单一变量的高斯分布p和q而言，他们的kl散度如式（3） <span class="math display">\[KL(p,q) = log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}\]</span></p><p><span class="math display">\[\begin{gathered}L_{t-1}=\mathbb{E}_{q}\left[{\frac{1}{2\sigma_{t}^{2}}}\|{\tilde{\mu}}_{t}(\mathbf{x}_{t},\mathbf{x}_{0})-{\boldsymbol{\mu}}_{\theta}(\mathbf{x}_{t},t)\|^{2}\right]+C \\ r_{t-1}-C=E_{x_{0},\kappa}\left[{\frac{1}{2\sigma_{t}^{2}}}\left\|{\tilde{\mu}}_{t}\left(\mathbf{x}_{t}(\mathbf{x}_{0},\epsilon),{\frac{1}{\sqrt{\alpha t}}}(\mathbf{x}_{0},\epsilon)-{\sqrt{1-{\bar{\alpha}}_{t}}}\epsilon)\right)-\mu_{0}(\mathbf{x_t}(\mathbf{x}_{0},\epsilon),t)\right\|^{2}\right] \\=\mathbb{E}_{\mathbf{x}_{0},\epsilon}\left[\dfrac{1}{2\sigma_{t}^{2}}\left\|\dfrac{1}{\sqrt{\alpha_{t}}}\left(\mathbf{x}_{t}(\mathbf{x}_{0},\epsilon)-\dfrac{\beta_{t}}{\sqrt{1-\bar{\alpha}_{t}}}\epsilon\right)-\mu_{\theta}(\mathbf{x}_{t}(\mathbf{x}_{0},\epsilon),t)\right\|^{2}\right] \\ \mu_{\theta}(\mathbf{x}_{t},t)={\bar{\mu}}_{t}\left(\mathbf{x}_{t},{\frac{1}{\sqrt{\bar{\alpha}t}}}(\mathbf{x}_{t}-{\sqrt{1-{\bar{\alpha}}_{t}}}\epsilon_{\theta}(\mathbf{x}_{t}))\right)={\frac{1}{\sqrt{\alpha_{t}}}}\left(\mathbf{x}_{t}-{\frac{\beta_{t}}{\sqrt{1-{\bar{\alpha}}_{t}}}}\epsilon_{\theta}(\mathbf{x}_{t},t)\right) \\\mathbb{E}_{\mathbf{x}_{0},\epsilon}\left[\frac{\beta_{t}^{2}}{2\sigma_{t}^{2}\alpha_{t}(1-\bar{\alpha}_{t})}\left\|\epsilon-\epsilon_{\theta}(\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,t)\right\|^{2}\right] \\L_{\mathrm{simple}}(\theta):=\mathbb{E}_{t,\mathbf{x}_{0},\epsilon}\Big[\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\boldsymbol{\epsilon},t)\right\|^{2}\Big] \end{gathered}\]</span></p><ul><li><span class="math inline">\(\tilde{\mu}_{t}\)</span>是可以计算得到的，所以可以用<span class="math inline">\(\mu_{\theta}\)</span>去预测<span class="math inline">\(\tilde{\mu}_{t}\)</span>网络，进而得到 loss function</li><li>预测均值的方法不太合理，预测噪声的方式更加合理。预测目标转移成了<span class="math inline">\(\varepsilon\)</span></li></ul><p><span class="math display">\[\mathbf x_t(\mathbf x_0,\varepsilon ) = \sqrt {\bar {\alpha_n} } \mathbf x_0 + \sqrt{1-\bar{\alpha_n}}\varepsilon \\ \varepsilon \sim\mathcal{N}(0,I)\]</span></p><p>然后式（24）可以转换为： <span class="math display">\[{\mu}_{\theta}(\mathbf x_t,t)=\frac{1}{\sqrt{a_{t}}}\left(x_{t}-\frac{\beta_{t}}{\sqrt{1-\bar{a}_{t}}} \varepsilon_{\theta}(\mathbf x_t,t)\right)\]</span></p><h2 id="算法代码介绍">5 算法代码介绍</h2><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202305032258822.png" alt="image-20230503225817264" /><figcaption aria-hidden="true">image-20230503225817264</figcaption></figure><p>使用jupyter notebook 进行演示</p><h3 id="选择一个数据集">5.1 选择一个数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_s_curve</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">s_curve, _ = make_s_curve(<span class="number">10</span>**<span class="number">4</span>,noise=<span class="number">0.1</span>)</span><br><span class="line">s_curve = s_curve[:,[<span class="number">0</span>,<span class="number">2</span>]] / <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;shape of moons:&quot;</span>,np.shape(s_curve))</span><br><span class="line"></span><br><span class="line">data = s_curve.T</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(*data,color=<span class="string">&quot;red&quot;</span>,edgecolor=<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">datasets = torch.Tensor(s_curve).<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure><h3 id="确定超参数的值">5.2 确定超参数的值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">num_steps = <span class="number">100</span> <span class="comment"># 对于步骤，一开始可以由beta，分布的均值和标准差来共同确定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定每一步的beta</span></span><br><span class="line">betas = torch.linspace(-<span class="number">6</span>,<span class="number">6</span>,num_steps)</span><br><span class="line">betas = torch.sigmoid(betas) * (<span class="number">0.5e-2</span> - <span class="number">1e-5</span>) + <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 alpha，alpha_prod,alpha_prod_previous,alpha_bar_sqrt等变量的值</span></span><br><span class="line">alphas = <span class="number">1</span> - betas</span><br><span class="line">alphas_prod = torch.cumprod(alphas,<span class="number">0</span>)</span><br><span class="line">alphas_prod_p = torch.cat([torch.tensor([<span class="number">1</span>]).<span class="built_in">float</span>(),alphas_prod[:-<span class="number">1</span>]], <span class="number">0</span>) <span class="comment"># p表示previous</span></span><br><span class="line">alphas_bar_sqrt = torch.sqrt(alphas_prod)</span><br><span class="line">one_minus_alphas_bar_log = torch.log(<span class="number">1</span> - alphas_prod)</span><br><span class="line">one_minus_alphas_bar_sqrt = torch.sqrt(<span class="number">1</span> - alphas_prod)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> alphas.shape == alphas_prod.shape == alphas_prod_p.shape == \</span><br><span class="line">alphas_bar_sqrt.shape == one_minus_alphas_bar_log.shape == one_minus_alphas_bar_sqrt.shape</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;all the same shape:&quot;</span>,betas.shape)</span><br></pre></td></tr></table></figure><h3 id="确定扩散过程任意时刻的采样值">5.3 确定扩散过程任意时刻的采样值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算任意时刻的x的采样值，基于x_0和参数重整化技巧</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">q_x</span>(<span class="params">x_0,t</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;可以基于x[0]得到任意时刻t的x[t]&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    noise = torch.randn_like(x_0) <span class="comment"># noise 是从正态分布中生成的随机噪声</span></span><br><span class="line">    alphas_t = alphas_bar_sqrt[t]</span><br><span class="line">    alphas_1_m_t = one_minus_alphas_bar_sqrt[t]</span><br><span class="line">    <span class="keyword">return</span> (alphas_t * x_0 + alphas_1_m_t * noise) <span class="comment"># 在x[0]的基础上添加噪声</span></span><br></pre></td></tr></table></figure><h3 id="演示原始数据分布加噪100步后的效果">5.4 演示原始数据分布加噪100步后的效果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">num_shows = <span class="number">20</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>,<span class="number">10</span>,figsize=(<span class="number">28</span>,<span class="number">3</span>))</span><br><span class="line">plt.rc(<span class="string">&quot;text&quot;</span>,color=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 共有10000个点，每个点包含两个坐标</span></span><br><span class="line"><span class="comment"># 生成100步以内每隔5步加噪声后的图像</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_shows):</span><br><span class="line">    j = i // <span class="number">10</span></span><br><span class="line">    k = i % <span class="number">10</span></span><br><span class="line">    q_i = q_x(datasets,torch.tensor([i*num_steps // num_shows])) <span class="comment"># 生成t时刻的采样数据</span></span><br><span class="line"></span><br><span class="line">    axs[j,k].scatter(q_i[:,<span class="number">0</span>],q_i[:,<span class="number">1</span>],color=<span class="string">&quot;red&quot;</span>,edgecolor=<span class="string">&quot;white&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    axs[j,k].set_axis_off()</span><br><span class="line">    axs[j,k].set_title(<span class="string">&quot;$q(\mathbf&#123;x&#125;_&#123;&quot;</span>+<span class="built_in">str</span>(i*num_steps//num_shows)+<span class="string">&quot;&#125;)$&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="编写拟合逆扩散过程高斯分布的模型">5.5 编写拟合逆扩散过程高斯分布的模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLPDiffusion</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_steps,num_units=<span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MLPDiffusion,self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.linears = nn.ModuleList(</span><br><span class="line">        [</span><br><span class="line">            nn.Linear(<span class="number">2</span>,num_units),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(num_units,num_units),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(num_units,num_units),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(num_units,<span class="number">2</span>),</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        self.step_embeddings = nn.ModuleList([</span><br><span class="line">            nn.Embedding(n_steps,num_units),</span><br><span class="line">            nn.Embedding(n_steps,num_units),</span><br><span class="line">            nn.Embedding(n_steps,num_units),</span><br><span class="line">        ])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x_0,t</span>):</span><br><span class="line">        x = x_0</span><br><span class="line">        <span class="keyword">for</span> idx,embedding_layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.step_embeddings):</span><br><span class="line">            t_embedding = embedding_layer(t)</span><br><span class="line">            x = self.linears[<span class="number">2</span>*idx](x)</span><br><span class="line">            x += t_embedding</span><br><span class="line">            x = self.linears[<span class="number">2</span>*idx+<span class="number">1</span>](x)</span><br><span class="line">            </span><br><span class="line">        x = self.linears[-<span class="number">1</span>](x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="编写训练的误差函数">5.6 编写训练的误差函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">diffusion_loss_fn</span>(<span class="params">model,x_0,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,n_steps</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;对任意时刻t进行采样计算&quot;&quot;&quot;</span></span><br><span class="line">    batch_size = x_0.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 随机CIA杨一个时刻t，为了提高训练速度，这里我确保t不重复</span></span><br><span class="line">    </span><br><span class="line">    t = torch.randint(<span class="number">0</span>,n_steps,size=(batch_size//<span class="number">2</span>,))</span><br><span class="line">    t = torch.cat([t,n_steps-<span class="number">1</span>-t],dim=<span class="number">0</span>)</span><br><span class="line">    t = t.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x0的系数</span></span><br><span class="line">    a = alphas_bar_sqrt[t]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># eps的系数</span></span><br><span class="line">    am1 = one_minus_alphas_bar_sqrt[t]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成随机噪声eps</span></span><br><span class="line">    e = torch.randn_like(x_0)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构造模型的输入</span></span><br><span class="line">    x = x_0 * a + e * am1</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 送入模型，得到t时刻的随机噪声预测值</span></span><br><span class="line">    output = model(x,t.squeeze(-<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 与真实噪声一起计算误差，求平均值</span></span><br><span class="line">    <span class="keyword">return</span> (e - output).square().mean()</span><br></pre></td></tr></table></figure><h3 id="编写逆扩散采样函数inference过程">5.7 编写逆扩散采样函数(inference过程)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">p_sample_loop</span>(<span class="params">model,shape,n_steps,betas,one_minus_alphas_bar_sqrt</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从x[T]恢复x[T-1],x[T-2],...,x[0]&quot;&quot;&quot;</span></span><br><span class="line">    cur_x = torch.randn(shape)</span><br><span class="line">    x_seq = [cur_x]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(n_steps)):</span><br><span class="line">        cur_x = p_sample(model,cur_x,i,betas,one_minus_alphas_bar_sqrt)</span><br><span class="line">        x_seq.append(cur_x)</span><br><span class="line">    <span class="keyword">return</span> x_seq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_sample</span>(<span class="params">model,x,t,betas,one_minus_alphas_bar_sqrt</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从x[T]采样t时刻的重构值&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    t = torch.tensor([t])</span><br><span class="line">    coeff = betas[t] / one_minus_alphas_bar_sqrt[t]</span><br><span class="line">    eps_theta = model(x,t)</span><br><span class="line">    mean = (<span class="number">1</span> / (<span class="number">1</span>-betas[t]).sqrt() * (x - (coeff * eps_theta)))</span><br><span class="line">    </span><br><span class="line">    z = torch.randn_like(x)</span><br><span class="line">    sigma_t = betas[t].sqrt()</span><br><span class="line">    sample = mean + sigma_t * z</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (sample)</span><br></pre></td></tr></table></figure><h3 id="开始训练模型并打印loss及中间的重构效果">5.8开始训练模型，并打印loss及中间的重构效果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">seed = 42</span><br><span class="line">class EMA():</span><br><span class="line">    &quot;&quot;&quot;构建一个参数平滑器&quot;&quot;&quot;</span><br><span class="line">    def __init__(self,mu=0.01):</span><br><span class="line">        self.mu = mu</span><br><span class="line">        self.shadow = &#123;&#125;</span><br><span class="line">    def register(self,name,val):</span><br><span class="line">        self.shadow[name] = val.clone()</span><br><span class="line">        </span><br><span class="line">    def __cell__(self,name,x):</span><br><span class="line">        assert name in self.shadow</span><br><span class="line">        new_average = self.mu * x + (1.0 - self.mu) * self.shadow[name]</span><br><span class="line">        self.shadow[name] = new_average.clone()</span><br><span class="line">        return new_average</span><br><span class="line">    </span><br><span class="line">print(&quot;training model...&quot;)</span><br><span class="line"></span><br><span class="line">batch_size = 128</span><br><span class="line">dataloader = torch.utils.data.DataLoader(datasets,batch_size=batch_size,shuffle=True)</span><br><span class="line">dataloader = dataloader.cuda()</span><br><span class="line">num_epoch = 4000</span><br><span class="line">plt.rc(&quot;text&quot;,color=&quot;blue&quot;)</span><br><span class="line"></span><br><span class="line">model = MLPDiffusion(num_steps).cuda() # 输出维度是2，输入是x和step</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)</span><br><span class="line"></span><br><span class="line">for t in range(num_epoch):</span><br><span class="line">    for idx,batch_x in enumerate(dataloader):</span><br><span class="line">        loss = diffusion_loss_fn(model,batch_x,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,num_steps)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(model.parameters(),1.)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    # print loss</span><br><span class="line">    if (t % 100 == 0):</span><br><span class="line">        print(loss)</span><br><span class="line">        x_seq = p_sample_loop(model,datasets.shape,num_steps,betas,one_minus_alphas_bar_sqrt) #共有100个元素</span><br><span class="line">        </span><br><span class="line">        fig, axs = plt.subplots(1,10,figsize=(28,3))</span><br><span class="line">        for i in range(1,11):</span><br><span class="line">            cur_x = x_seq[i * 10].detach()</span><br><span class="line">            axs[i-1].scatter(cur_x[:,0],cur_x[:,1],color=&quot;red&quot;,edgecolor=&quot;white&quot;)</span><br><span class="line">            axs[i-1].set_axis_off()</span><br><span class="line">            axs[i-1].set_title(&quot;$q(\mathbf&#123;x&#125;_&#123;&quot;+str(i*10)+&quot;&#125;)$&quot;)</span><br></pre></td></tr></table></figure><h3 id="动画演示">5.9 动画演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generating the forward image sequence 生成前向过程，也就是逐步加噪声</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">imgs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    plt.clf()</span><br><span class="line">    q_i = q_x(datasets,torch.tensor([i]))</span><br><span class="line">    plt.scatter(q_i[:,<span class="number">0</span>],q_i[:,<span class="number">1</span>],color=<span class="string">&quot;red&quot;</span>,edgecolor=<span class="string">&quot;white&quot;</span>,s=<span class="number">5</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    img_buf = io.BytesIO()</span><br><span class="line">    plt.savefig(img_buf,<span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_buf)</span><br><span class="line">    imgs.append(img)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># generating the reverse diffusion sequence</span></span><br><span class="line">reverse = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    plt.clf()</span><br><span class="line">    cur_x = x_seq[i].detach() <span class="comment"># 拿到训练末尾阶段生成的x_seq</span></span><br><span class="line">    plt.scatter(q_i[:,<span class="number">0</span>],q_i[:,<span class="number">1</span>],color=<span class="string">&quot;red&quot;</span>,edgecolor=<span class="string">&quot;white&quot;</span>,s=<span class="number">5</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    img_buf = io.BytesIO()</span><br><span class="line">    plt.savefig(img_buf,<span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_buf)</span><br><span class="line">    reverse.append(img)</span><br><span class="line">    </span><br><span class="line"> imgs = imgs + reverse</span><br><span class="line"> imgs[<span class="number">0</span>].save(<span class="string">&quot;diffusion.gif&quot;</span>,<span class="built_in">format</span>=<span class="string">&quot;GIF&quot;</span>,append_images=imgs,save_all=<span class="literal">True</span>,duration=<span class="number">100</span>,loop=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Denoising Diffusion Probabilistic Models&lt;/p&gt;
&lt;p&gt;https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pd</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="diffusion model" scheme="https://wangtongyouwen.github.io/categories/pytorch/diffusion-model/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="diffusion model" scheme="https://wangtongyouwen.github.io/tags/diffusion-model/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络12-Unet</title>
    <link href="https://wangtongyouwen.github.io/post/94472398.html"/>
    <id>https://wangtongyouwen.github.io/post/94472398.html</id>
    <published>2023-04-30T06:12:22.000Z</published>
    <updated>2023-04-30T13:07:07.759Z</updated>
    
    <content type="html"><![CDATA[<h1 id="u-net-convolutional-networks-for-biomedical-image-segmentation">U-Net: Convolutional Networks for Biomedical Image Segmentation</h1><p>https://arxiv.org/pdf/1505.04597.pdf</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304301414602.png" alt="image-20230430141414836" /><figcaption aria-hidden="true">image-20230430141414836</figcaption></figure><ul><li>为什么输入图片和输出图片的大小不同？---因为输入的图片本质也是388*388的，只是通过了一定的填充方式变成了572*572。这是为了让边缘的像素具有更好的上下文信息。</li></ul><p>example：</p><p>https://github.com/yassouali/pytorch-segmentation</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;u-net-convolutional-networks-for-biomedical-image-segmentation&quot;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/h1&gt;</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>pytorch基础入门24-损失函数</title>
    <link href="https://wangtongyouwen.github.io/post/24351970.html"/>
    <id>https://wangtongyouwen.github.io/post/24351970.html</id>
    <published>2023-04-27T09:28:25.000Z</published>
    <updated>2023-04-30T13:12:16.502Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># logits shape: [BS,NC]</span></span><br><span class="line">batchsize = <span class="number">2</span></span><br><span class="line">num_class = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">logits = torch.randn(batchsize,num_class)</span><br><span class="line">target = torch.randint(num_class,size=(batchsize,)) <span class="comment"># delta目标分布</span></span><br><span class="line">target_logits = torch.randn(batchsize,num_class) <span class="comment"># 非delta目标分布</span></span><br></pre></td></tr></table></figure><h1 id="crossentropyloss">CROSSENTROPYLOSS</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304271739035.png" alt="image-20230427173911712" /><figcaption aria-hidden="true">image-20230427173911712</figcaption></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304271743417.png" alt="image-20230427174342229" /><figcaption aria-hidden="true">image-20230427174342229</figcaption></figure><p>https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.调用 cross entropy loss (CE loss)</span></span><br><span class="line"><span class="comment"># 第一种方法调用CEloss</span></span><br><span class="line">ce_loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">ce_loss = ce_loss_fn(logits,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;cross entropy loss: <span class="subst">&#123;ce_loss&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 第二种方法</span></span><br><span class="line">ce_loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">ce_loss = ce_loss_fn(logits,target_logits)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;cross entropy loss: <span class="subst">&#123;ce_loss&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="nllloss">NLLLOSS</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304271754467.png" alt="image-20230427175450218" /><figcaption aria-hidden="true">image-20230427175450218</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.调用Negative Log Likelihood Loss (NLL loss)</span></span><br><span class="line">nll_fn = nn.NLLLoss()</span><br><span class="line">nll_loss = nll_fn(torch.log(torch.softmax(logits,-<span class="number">1</span>)),target_indices)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;neagative log-likelihood loss: <span class="subst">&#123;nll_loss&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>如果得到的logits是没有归一化的值，那么使用CEloss</li><li>如果得到的logits是已经softmax后的log概率值值，则使用NLLloss</li><li>总之，两个损失函数都是用来计算分类问题的</li></ul><p>In classification problems we want to estimate the probability of different outcomes. Let the estimated probability of outcome<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20" alt="i" /> be <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/187f4094cdfe699a627b3166c870d4e80a3ddbc9" alt="{q_{}(X=i)}" /> with to-be-optimized parameters <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" alt="" /> and let the frequency (empirical probability) of outcome in the training set be <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e4adae4de2fee09ec86818003df233cee809e070" alt="{p(X=i)}" />. Given N <a href="https://en.wikipedia.org/wiki/Conditionally_independent">conditionally independent</a> samples in the training set, then the <a href="https://en.wikipedia.org/wiki/Likelihood">likelihood</a> of the parameters <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" alt="" /> of the model <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ab8eaa7d05b1279a2c3bb4c4451a2305b5de380" alt="{q_{}(X=x)}" /> on the training set is</p><figure><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d452937ed5a5bdfdac361ad273d0c55868f0cdd3" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p>where the last expression is due to the definition of the multinomial PMF. Therefore, the log-likelihood, divided by <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5e3890c981ae85503089652feb48b191b57aae3" alt="N" /> is</p><figure><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9601b9fef9a3e4c9bb43553b1b3a1d523c0f3dfa" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p>so that <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximizing the likelihood</a> with respect to the parameters <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" alt="" /> is the same as minimizing the cross-entropy.</p><h1 id="kullback-leibler-divergence-loss">Kullback-Leibler divergence loss</h1><p>https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304301259064.png" alt="image-20230430125950441" /><figcaption aria-hidden="true">image-20230430125950441</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. 调用 KL divergence loss(KL loss)</span></span><br><span class="line">KL_loss_fn = nn.KLDivLoss()</span><br><span class="line">kld_loss = KL_loss_fn(torch.log(torch.softmax(logits,-<span class="number">1</span>)),torch.softmax(target_logits,dim=-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;KL divergence loss: <span class="subst">&#123;kld_loss&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 4. CE = IE(信息熵) + KLD </span><br><span class="line">ce_loss_fn_smaple = nn.CrossEntropyLoss(reduction=&quot;none&quot;)</span><br><span class="line">ce_loss_sample = ce_loss_fn_smaple(logits,torch.softmax(target_logits,dim=-1))</span><br><span class="line">print(f&quot;cross entropy loss sample:&#123;ce_loss_sample&#125;&quot;)</span><br><span class="line"></span><br><span class="line">kld_loss_fn_sample = nn.KLDivLoss(reduction=&quot;none&quot;)</span><br><span class="line">kld_loss_sample = kld_loss_fn_sample(torch.log(torch.softmax(logits,-1)),torch.softmax(target_logits,dim=-1)).sum(-1)</span><br><span class="line">print(f&quot;KL divergence loss sample:&#123;kld_loss_sample&#125;&quot;)</span><br><span class="line"></span><br><span class="line">target_information_entropy = torch.distributions.Categorical(probs=torch.softmax(target_logits,dim=-1)).entropy()</span><br><span class="line">print(f&quot;information entropy sample:&#123;target_information_entropy&#125;&quot;)</span><br><span class="line"></span><br><span class="line">torch.allclose(ce_loss_sample,kld_loss_sample+target_information_entropy)</span><br></pre></td></tr></table></figure><h1 id="bceloss">BCELOSS</h1><p>https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5. 调用Binary Cross Entropy loss （BCE loss）</span></span><br><span class="line">bce_loss_fn = nn.BCELoss()</span><br><span class="line">logits = torch.randn(batchsize)</span><br><span class="line">prob_1 = torch.sigmoid(logits)</span><br><span class="line">target = torch.randint(<span class="number">2</span>,size=(batchsize,))</span><br><span class="line">bce_loss = bce_loss_fn(prob_1,target.<span class="built_in">float</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;binary cross entropy loss: <span class="subst">&#123;bce_loss&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 用 NLL loss 代替 BCE loss</span></span><br><span class="line">prob_0 = <span class="number">1</span> - prob_1.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">prob = torch.cat([prob_0,prob_1.unsqueeze(-<span class="number">1</span>)],dim=-<span class="number">1</span>)</span><br><span class="line">nll_loss_binary = nll_fn(torch.log(prob),target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;negative likelihood loss binary:<span class="subst">&#123;nll_loss_binary&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="cosineembeddingloss">COSINEEMBEDDINGLOSS</h1><p>https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304301347056.png" alt="image-20230430134714165" /><figcaption aria-hidden="true">image-20230430134714165</figcaption></figure><ul><li>计算相似度匹配（图片检索任务：找出相似度最相似的）</li><li>对比学习，自监督学习</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络3-transformer</title>
    <link href="https://wangtongyouwen.github.io/post/2fee727b.html"/>
    <id>https://wangtongyouwen.github.io/post/2fee727b.html</id>
    <published>2023-04-27T09:28:25.000Z</published>
    <updated>2023-04-30T13:07:07.761Z</updated>
    
    <content type="html"><![CDATA[<p>https://arxiv.org/pdf/1706.03762.pdf</p><p>https://nlp.seas.harvard.edu/2018/04/03/attention.html</p><h3 id="attention-is-all-you-need-----transformer">attention is all you need ---&gt; transformer</h3><p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101725197.png" alt="image-20230408205122663" style="zoom: 80%;" /></p><p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101725367.png" alt="image-20230408205258220" style="zoom:50%;" /></p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304082110329.jpg" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304082209301.png" alt="image-20230408220929314" style="zoom:80%;" /></p><h3 id="pytorch-源码">1 pytorch 源码</h3><p>https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Examples::</span><br><span class="line">        &gt;&gt;&gt; transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)</span><br><span class="line">        &gt;&gt;&gt; src = torch.rand((<span class="number">10</span>, <span class="number">32</span>, <span class="number">512</span>))</span><br><span class="line">        &gt;&gt;&gt; tgt = torch.rand((<span class="number">20</span>, <span class="number">32</span>, <span class="number">512</span>))</span><br><span class="line">        &gt;&gt;&gt; out = transformer_model(src, tgt)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span> = <span class="number">512</span>, nhead: <span class="built_in">int</span> = <span class="number">8</span>, num_encoder_layers: <span class="built_in">int</span> = <span class="number">6</span>,</span></span><br><span class="line"><span class="params">             num_decoder_layers: <span class="built_in">int</span> = <span class="number">6</span>, dim_feedforward: <span class="built_in">int</span> = <span class="number">2048</span>, dropout: <span class="built_in">float</span> = <span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">             activation: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">Callable</span>[[Tensor], Tensor]] = F.relu,</span></span><br><span class="line"><span class="params">             custom_encoder: <span class="type">Optional</span>[<span class="type">Any</span>] = <span class="literal">None</span>, custom_decoder: <span class="type">Optional</span>[<span class="type">Any</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             layer_norm_eps: <span class="built_in">float</span> = <span class="number">1e-5</span>, batch_first: <span class="built_in">bool</span> = <span class="literal">False</span>, norm_first: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    factory_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: device, <span class="string">&#x27;dtype&#x27;</span>: dtype&#125;</span><br><span class="line">    <span class="built_in">super</span>(Transformer, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> custom_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.encoder = custom_encoder</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout,</span><br><span class="line">                                                activation, layer_norm_eps, batch_first, norm_first,</span><br><span class="line">                                                **factory_kwargs)</span><br><span class="line">        encoder_norm = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> custom_decoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.decoder = custom_decoder</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout,</span><br><span class="line">                                                activation, layer_norm_eps, batch_first, norm_first,</span><br><span class="line">                                                **factory_kwargs)</span><br><span class="line">        decoder_norm = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)</span><br><span class="line"></span><br><span class="line">    self._reset_parameters()</span><br><span class="line"></span><br><span class="line">    self.d_model = d_model</span><br><span class="line">    self.nhead = nhead</span><br><span class="line"></span><br><span class="line">    self.batch_first = batch_first</span><br></pre></td></tr></table></figure><p>其中初始化部分最为重要的四部分：TransformerEncoderLayer（通过encoder_layer连接），TransformerDecoderLayer（通过decoder_layer连接）</p><h4 id="transformerencoderlayer">1.1 TransformerEncoderLayer</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Args:</span><br><span class="line">    d_model: the number of expected features <span class="keyword">in</span> the input (required).</span><br><span class="line">    nhead: the number of heads <span class="keyword">in</span> the multiheadattention models (required).</span><br><span class="line">    dim_feedforward: the dimension of the feedforward network model (default=2048).</span><br><span class="line">    dropout: the dropout value (default=0.1).</span><br><span class="line">    activation: the activation <span class="keyword">function</span> of the intermediate layer, can be a string</span><br><span class="line">        (<span class="string">&quot;relu&quot;</span> or <span class="string">&quot;gelu&quot;</span>) or a unary callable. Default: relu</span><br><span class="line">    layer_norm_eps: the eps value <span class="keyword">in</span> layer normalization components (default=1e-5).</span><br><span class="line">    batch_first: If ``True``, <span class="keyword">then</span> the input and output tensors are provided</span><br><span class="line">        as (batch, <span class="built_in">seq</span>, feature). Default: ``False`` (<span class="built_in">seq</span>, batch, feature).</span><br><span class="line">    norm_first: <span class="keyword">if</span> ``True``, layer norm is <span class="keyword">done</span> prior to attention and feedforward</span><br><span class="line">        operations, respectively. Otherwise it<span class="string">&#x27;s done after. Default: ``False`` (after).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Examples::</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; out = encoder_layer(src)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Alternatively, when ``batch_first`` is ``True``:</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; src = torch.rand(32, 10, 512)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; out = encoder_layer(src)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span>, nhead: <span class="built_in">int</span>, dim_feedforward: <span class="built_in">int</span> = <span class="number">2048</span>, dropout: <span class="built_in">float</span> = <span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">              activation: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">Callable</span>[[Tensor], Tensor]] = F.relu,</span></span><br><span class="line"><span class="params">              layer_norm_eps: <span class="built_in">float</span> = <span class="number">1e-5</span>, batch_first: <span class="built_in">bool</span> = <span class="literal">False</span>, norm_first: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">              device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">     factory_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: device, <span class="string">&#x27;dtype&#x27;</span>: dtype&#125;</span><br><span class="line">     <span class="built_in">super</span>(TransformerEncoderLayer, self).__init__()</span><br><span class="line">     self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,</span><br><span class="line">                                         **factory_kwargs)</span><br><span class="line">     <span class="comment"># Implementation of Feedforward model</span></span><br><span class="line">     self.linear1 = Linear(d_model, dim_feedforward, **factory_kwargs)</span><br><span class="line">     self.dropout = Dropout(dropout)</span><br><span class="line">     self.linear2 = Linear(dim_feedforward, d_model, **factory_kwargs)</span><br><span class="line"></span><br><span class="line">     self.norm_first = norm_first</span><br><span class="line">     self.norm1 = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">     self.norm2 = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">     self.dropout1 = Dropout(dropout)</span><br><span class="line">     self.dropout2 = Dropout(dropout)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># Legacy string support for activation function.</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">isinstance</span>(activation, <span class="built_in">str</span>):</span><br><span class="line">         activation = _get_activation_fn(activation)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># We can&#x27;t test self.activation in forward() in TorchScript,</span></span><br><span class="line">     <span class="comment"># so stash some information about it instead.</span></span><br><span class="line">     <span class="keyword">if</span> activation <span class="keyword">is</span> F.relu <span class="keyword">or</span> <span class="built_in">isinstance</span>(activation, torch.nn.ReLU):</span><br><span class="line">         self.activation_relu_or_gelu = <span class="number">1</span></span><br><span class="line">     <span class="keyword">elif</span> activation <span class="keyword">is</span> F.gelu <span class="keyword">or</span> <span class="built_in">isinstance</span>(activation, torch.nn.GELU):</span><br><span class="line">         self.activation_relu_or_gelu = <span class="number">2</span></span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         self.activation_relu_or_gelu = <span class="number">0</span></span><br><span class="line">     self.activation = activation</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src: Tensor, src_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,src_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span></span>) -&gt; Tensor:</span><br><span class="line">x = src</span><br><span class="line">     <span class="keyword">if</span> self.norm_first:</span><br><span class="line">         x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)</span><br><span class="line">         x = x + self._ff_block(self.norm2(x))</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))</span><br><span class="line">         x = self.norm2(x + self._ff_block(x))</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span> x</span><br><span class="line"> </span><br></pre></td></tr></table></figure><h4 id="transformerencoder">1.2 TransformerEncoder</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r&quot;&quot;&quot;TransformerEncoder is a stack of N encoder layers. Users can build the</span></span><br><span class="line"><span class="string">    BERT(https://arxiv.org/abs/1810.04805) model with corresponding parameters.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        encoder_layer: an instance of the TransformerEncoderLayer() class (required).</span></span><br><span class="line"><span class="string">        num_layers: the number of sub-encoder-layers in the encoder (required).</span></span><br><span class="line"><span class="string">        norm: the layer normalization component (optional).</span></span><br><span class="line"><span class="string">        enable_nested_tensor: if True, input will automatically convert to nested tensor</span></span><br><span class="line"><span class="string">            (and convert back on output). This will improve the overall performance of</span></span><br><span class="line"><span class="string">            TransformerEncoder when padding rate is high. Default: ``True`` (enabled).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; out = transformer_encoder(src)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;norm&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder_layer, num_layers, norm=<span class="literal">None</span>, enable_nested_tensor=<span class="literal">True</span>, mask_check=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerEncoder, self).__init__()</span><br><span class="line">        self.layers = _get_clones(encoder_layer, num_layers)</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.norm = norm</span><br><span class="line">        self.enable_nested_tensor = enable_nested_tensor</span><br><span class="line">        self.mask_check = mask_check</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src: Tensor, mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>, src_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span></span>) -&gt; Tensor:</span><br><span class="line">        <span class="string">r&quot;&quot;&quot;Pass the input through the encoder layers in turn.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            src: the sequence to the encoder (required).</span></span><br><span class="line"><span class="string">            mask: the mask for the src sequence (optional).</span></span><br><span class="line"><span class="string">            src_key_padding_mask: the mask for the src keys per batch (optional).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Shape:</span></span><br><span class="line"><span class="string">            see the docs in Transformer class.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h4 id="transformerdecoderlayer">1.3 TransformerDecoderLayer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r&quot;&quot;&quot;TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.</span></span><br><span class="line"><span class="string">    This standard decoder layer is based on the paper &quot;Attention Is All You Need&quot;.</span></span><br><span class="line"><span class="string">    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,</span></span><br><span class="line"><span class="string">    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in</span></span><br><span class="line"><span class="string">    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement</span></span><br><span class="line"><span class="string">    in a different way during application.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        d_model: the number of expected features in the input (required).</span></span><br><span class="line"><span class="string">        nhead: the number of heads in the multiheadattention models (required).</span></span><br><span class="line"><span class="string">        dim_feedforward: the dimension of the feedforward network model (default=2048).</span></span><br><span class="line"><span class="string">        dropout: the dropout value (default=0.1).</span></span><br><span class="line"><span class="string">        activation: the activation function of the intermediate layer, can be a string</span></span><br><span class="line"><span class="string">            (&quot;relu&quot; or &quot;gelu&quot;) or a unary callable. Default: relu</span></span><br><span class="line"><span class="string">        layer_norm_eps: the eps value in layer normalization components (default=1e-5).</span></span><br><span class="line"><span class="string">        batch_first: If ``True``, then the input and output tensors are provided</span></span><br><span class="line"><span class="string">            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).</span></span><br><span class="line"><span class="string">        norm_first: if ``True``, layer norm is done prior to self attention, multihead</span></span><br><span class="line"><span class="string">            attention and feedforward operations, respectively. Otherwise it&#x27;s done after.</span></span><br><span class="line"><span class="string">            Default: ``False`` (after).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; memory = torch.rand(10, 32, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; tgt = torch.rand(20, 32, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; out = decoder_layer(tgt, memory)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Alternatively, when ``batch_first`` is ``True``:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8, batch_first=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; memory = torch.rand(32, 10, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; tgt = torch.rand(32, 20, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; out = decoder_layer(tgt, memory)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span>, nhead: <span class="built_in">int</span>, dim_feedforward: <span class="built_in">int</span> = <span class="number">2048</span>, dropout: <span class="built_in">float</span> = <span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 activation: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">Callable</span>[[Tensor], Tensor]] = F.relu,</span></span><br><span class="line"><span class="params">                 layer_norm_eps: <span class="built_in">float</span> = <span class="number">1e-5</span>, batch_first: <span class="built_in">bool</span> = <span class="literal">False</span>, norm_first: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        factory_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: device, <span class="string">&#x27;dtype&#x27;</span>: dtype&#125;</span><br><span class="line">        <span class="built_in">super</span>(TransformerDecoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,</span><br><span class="line">                                            **factory_kwargs)</span><br><span class="line">        self.multihead_attn = MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,</span><br><span class="line">                                                 **factory_kwargs)</span><br><span class="line">        <span class="comment"># Implementation of Feedforward model</span></span><br><span class="line">        self.linear1 = Linear(d_model, dim_feedforward, **factory_kwargs)</span><br><span class="line">        self.dropout = Dropout(dropout)</span><br><span class="line">        self.linear2 = Linear(dim_feedforward, d_model, **factory_kwargs)</span><br><span class="line"></span><br><span class="line">        self.norm_first = norm_first</span><br><span class="line">        self.norm1 = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">        self.norm2 = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">        self.norm3 = LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)</span><br><span class="line">        self.dropout1 = Dropout(dropout)</span><br><span class="line">        self.dropout2 = Dropout(dropout)</span><br><span class="line">        self.dropout3 = Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Legacy string support for activation function.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(activation, <span class="built_in">str</span>):</span><br><span class="line">            self.activation = _get_activation_fn(activation)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.activation = activation</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tgt: Tensor, memory: Tensor, tgt_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>, memory_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">            tgt_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>, memory_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span></span>) -&gt; Tensor:</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pass the inputs (and mask) through the decoder layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        tgt: the sequence to the decoder layer (required).</span></span><br><span class="line"><span class="string">        memory: the sequence from the last layer of the encoder (required).</span></span><br><span class="line"><span class="string">        tgt_mask: the mask for the tgt sequence (optional).</span></span><br><span class="line"><span class="string">        memory_mask: the mask for the memory sequence (optional).</span></span><br><span class="line"><span class="string">        tgt_key_padding_mask: the mask for the tgt keys per batch (optional).</span></span><br><span class="line"><span class="string">        memory_key_padding_mask: the mask for the memory keys per batch (optional).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        see the docs in Transformer class.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf</span></span><br><span class="line"></span><br><span class="line">    x = tgt</span><br><span class="line">    <span class="keyword">if</span> self.norm_first:</span><br><span class="line">        x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)</span><br><span class="line">        x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)</span><br><span class="line">        x = x + self._ff_block(self.norm3(x))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))</span><br><span class="line">        x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))</span><br><span class="line">        x = self.norm3(x + self._ff_block(x))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h4 id="transformerdecoder">1.4 TransformerDecoder</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r&quot;&quot;&quot;TransformerDecoder is a stack of N decoder layers</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        decoder_layer: an instance of the TransformerDecoderLayer() class (required).</span></span><br><span class="line"><span class="string">        num_layers: the number of sub-decoder-layers in the decoder (required).</span></span><br><span class="line"><span class="string">        norm: the layer normalization component (optional).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; memory = torch.rand(10, 32, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; tgt = torch.rand(20, 32, 512)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; out = transformer_decoder(tgt, memory)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;norm&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, decoder_layer, num_layers, norm=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerDecoder, self).__init__()</span><br><span class="line">        self.layers = _get_clones(decoder_layer, num_layers)</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.norm = norm</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tgt: Tensor, memory: Tensor, tgt_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                memory_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>, tgt_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                memory_key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span></span>) -&gt; Tensor:</span><br><span class="line">        <span class="string">r&quot;&quot;&quot;Pass the inputs (and mask) through the decoder layer in turn.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            tgt: the sequence to the decoder (required).</span></span><br><span class="line"><span class="string">            memory: the sequence from the last layer of the encoder (required).</span></span><br><span class="line"><span class="string">            tgt_mask: the mask for the tgt sequence (optional).</span></span><br><span class="line"><span class="string">            memory_mask: the mask for the memory sequence (optional).</span></span><br><span class="line"><span class="string">            tgt_key_padding_mask: the mask for the tgt keys per batch (optional).</span></span><br><span class="line"><span class="string">            memory_key_padding_mask: the mask for the memory keys per batch (optional).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Shape:</span></span><br><span class="line"><span class="string">            see the docs in Transformer class.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        output = tgt</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> mod <span class="keyword">in</span> self.layers:</span><br><span class="line">            output = mod(output, memory, tgt_mask=tgt_mask,</span><br><span class="line">                         memory_mask=memory_mask,</span><br><span class="line">                         tgt_key_padding_mask=tgt_key_padding_mask,</span><br><span class="line">                         memory_key_padding_mask=memory_key_padding_mask)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            output = self.norm(output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p><em>Below the attention mask shows the position each tgt word (row) is allowed to look at (column). Words are blocked for attending to future words during training.</em></p><figure><img src="https://nlp.seas.harvard.edu/images/the-annotated-transformer_31_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption></figure><p>在进行解码过程中，第一个词的预测只与第一个词有关，因此最后的的attention机制是个上三角的形式，如上图所示。</p><h4 id="attention">1.5 Attention</h4><figure><img src="https://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption></figure><p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</p><p>We call our particular attention “Scaled Dot-Product Attention”. The input consists of queries and keys of dimension <span class="math inline">\(d_k\)</span>, and values of dimension <span class="math inline">\(d_v\)</span>. We compute the dot products of the query with all keys, divide each by <span class="math inline">\(\sqrt{d_k}\)</span>, and apply a softmax function to obtain the weights on the values.</p><p>In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix <span class="math inline">\(Q\)</span>. The keys and values are also packed together into matrices <span class="math inline">\(K\)</span> and <span class="math inline">\(V\)</span>. We compute the matrix of outputs as: <span class="math display">\[\mathrm{Attention}(Q, K, V) = \mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})V\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">query, key, value, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;Compute &#x27;Scaled Dot Product Attention&#x27;&quot;</span></span><br><span class="line">    d_k = query.size(-<span class="number">1</span>)</span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) \</span><br><span class="line">             / math.sqrt(d_k)</span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">    p_attn = F.softmax(scores, dim = -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304100940797.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="encoder-细节">2 Encoder 细节</h3><h4 id="word-embedding">2.1 word embedding</h4><p>考虑 source sentence 和 target sentence 构建序列，序列的字符以其词表中的索引的形式表示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># source sentence 和 target sentence 的初始长度</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line"><span class="comment"># 单词表大小</span></span><br><span class="line">max_num_src_words = <span class="number">8</span></span><br><span class="line">max_num_tgt_words = <span class="number">8</span></span><br><span class="line">model_dim = <span class="number">8</span> <span class="comment"># 特征大小，原文是512</span></span><br><span class="line"><span class="comment"># 序列最大长度</span></span><br><span class="line">max_src_seq_len = <span class="number">5</span></span><br><span class="line">max_tgt_seq_len = <span class="number">5</span></span><br><span class="line">max_position_len = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># src_len = torch.randint(2,5,(batch_size,))</span></span><br><span class="line"><span class="comment"># tgt_len = torch.randint(2,5,(batch_size,)) </span></span><br><span class="line">src_len = torch.Tensor([<span class="number">2</span>,<span class="number">4</span>]).to(torch.int32)  <span class="comment"># 句子长度（2个句子）</span></span><br><span class="line">tgt_len = torch.Tensor([<span class="number">4</span>,<span class="number">3</span>]).to(torch.int32)</span><br><span class="line"><span class="built_in">print</span>(src_len,tgt_len)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 单词索引构成的源句子和目标句子,pad为最大序列长度,unsqueeze 变为2维张量，然后使用cat拼接起来,padding 默认值为0,构建batch</span></span><br><span class="line">src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(<span class="number">1</span>,max_num_src_words,(L,)),(<span class="number">0</span>,max_src_seq_len - L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> src_len]) </span><br><span class="line">tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(<span class="number">1</span>,max_num_tgt_words,(L,)),(<span class="number">0</span>,max_tgt_seq_len - L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> tgt_len])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(src_seq,<span class="string">&quot;\n&quot;</span>,tgt_seq,end=<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step2 构造 word embedding</span></span><br><span class="line"><span class="comment"># 第0行是默认padding的0，第1-9行是每个单词的embedding结果</span></span><br><span class="line">src_embedding_table = nn.Embedding(max_num_src_words + <span class="number">1</span>, model_dim)</span><br><span class="line">tgt_embedding_table = nn.Embedding(max_num_tgt_words + <span class="number">1</span>, model_dim)</span><br><span class="line">src_embedding = src_embedding_table(src_seq) <span class="comment"># embedding 的 forward 方法</span></span><br><span class="line">stgt_embedding = tgt_embedding_table(tgt_seq) </span><br><span class="line"><span class="built_in">print</span>(src_embedding_table.weight)</span><br><span class="line"><span class="built_in">print</span>(src_seq)</span><br><span class="line"><span class="built_in">print</span>(src_embedding)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="position-embedding">2.2 position embedding</h4><p><span class="math display">\[\begin{aligned}P E_{(p o s, 2 i)} &amp; =\sin \left(p o s / 10000^{2 i / d_{\mathrm{model}}}\right) \\P E_{(p o s, 2 i+1)} &amp; =\cos \left(p o s / 10000^{2 i / d_{\mathrm{model}}}\right)\end{aligned}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3 构建 position embedding</span></span><br><span class="line">pos_mat = torch.arange(max_position_len).reshape((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">i_mat = torch.<span class="built_in">pow</span>(<span class="number">10000</span>,torch.arange(<span class="number">0</span>,model_dim,<span class="number">2</span>).reshape(<span class="number">1</span>,-<span class="number">1</span>)/model_dim)</span><br><span class="line">pe_embedding_table = torch.zeros(max_position_len,model_dim)</span><br><span class="line"><span class="comment"># element point</span></span><br><span class="line">pe_embedding_table[:,<span class="number">0</span>::<span class="number">2</span>] = torch.sin(pos_mat/i_mat)  <span class="comment"># 偶数行</span></span><br><span class="line">pe_embedding_table[:,<span class="number">1</span>::<span class="number">2</span>] = torch.cos(pos_mat/i_mat)  <span class="comment"># 奇数行</span></span><br><span class="line"><span class="built_in">print</span>(pos_mat,<span class="string">&#x27;\n&#x27;</span>,i_mat,<span class="string">&#x27;\n&#x27;</span>,pe_embedding_table)</span><br><span class="line"></span><br><span class="line">src_pos = torch.cat([torch.unsqueeze(torch.arange(<span class="built_in">max</span>(src_len)),<span class="number">0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> src_len]).to(torch.int32)</span><br><span class="line">tgt_pos = torch.cat([torch.unsqueeze(torch.arange(<span class="built_in">max</span>(tgt_len)),<span class="number">0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> tgt_len]).to(torch.int32)</span><br><span class="line"></span><br><span class="line">src_pe_embedding = pe_embedding(src_pos)</span><br><span class="line">tgt_pe_embedding = pe_embedding(tgt_pos)</span><br><span class="line"><span class="built_in">print</span>(src_pe_embedding)</span><br><span class="line"><span class="built_in">print</span>(tgt_pe_embedding)</span><br></pre></td></tr></table></figure><p><span class="math inline">\(10000^{2 i / d_{\mathrm{model}}}\)</span> 表示为<span class="math inline">\(\omega_k\)</span>，pos表示为<span class="math inline">\(t\)</span></p><p>解决 out of demain: 如果是超出序列长度，可以通过之前序列长度的线性组合来表示</p><p>For every sine-cosine pair corresponding to frequency <span class="math inline">\(\omega_k\)</span>, there is a linear transformation $ M ^{2 } $(independent of t) where the following equation holds:</p>$$ M <span class="math display">\[\begin{bmatrix}    sin(\omega _k \cdot t)  \\    cos(\omega _k \cdot t)  \\     \end{bmatrix}\]</span>=<span class="math display">\[\begin{bmatrix} sin(\omega _k \cdot (t+\phi))\\cos(\omega _k \cdot (t+\phi)) \end{bmatrix}\]</span><p>$$ proof:</p>Let <span class="math inline">\(M\)</span> be a <span class="math inline">\(2\times2\)</span> matrix, we want to find <span class="math inline">\(u_1,v_1,u_2\)</span> and <span class="math inline">\(v_2\)</span> so that: $$<span class="math display">\[\begin{bmatrix} u_1 &amp;v_1 \\ u_2 &amp; v_2\end{bmatrix}\]</span><span class="math display">\[\begin{bmatrix}    sin(\omega _k \cdot t)  \\    cos(\omega _k \cdot t)  \\     \end{bmatrix}\]</span>=<span class="math display">\[\begin{bmatrix} sin(\omega _k \cdot (t+\phi))\\cos(\omega _k \cdot (t+\phi)) \end{bmatrix}\]</span><span class="math display">\[By applying the addition theorem, we can expand the right hand side as follows:\]</span><span class="math display">\[\begin{bmatrix} u_1 &amp;v_1 \\ u_2 &amp; v_2\end{bmatrix}\]</span><span class="math display">\[\begin{bmatrix}    sin(\omega _k \cdot t)  \\    cos(\omega _k \cdot t)  \\     \end{bmatrix}\]</span>=<span class="math display">\[\begin{bmatrix} sin(\omega_k \cdot t)cos(\omega_k \cdot \phi) + cos(\omega_k \cdot t)sin(\omega_k \cdot \phi)         \\cos(\omega_k \cdot t)cos(\omega_k \cdot \phi)  - sin(\omega_k \cdot t)sin(\omega_k \cdot \phi)\end{bmatrix}\]</span><span class="math display">\[Which result in the following two equations:\]</span><span class="math display">\[\begin{array}{l}u_{1} \sin \left(\omega_{k} \cdot t\right)+v_{1} \cos \left(\omega_{k} \cdot t\right)=\cos \left(\omega_{k} \cdot \phi\right) \sin \left(\omega_{k} \cdot t\right)+\sin \left(\omega_{k} \cdot \phi\right) \cos \left(\omega_{k} \cdot t\right) \\u_{2} \sin \left(\omega_{k} \cdot t\right)+v_{2} \cos \left(\omega_{k} \cdot t\right)=-\sin \left(\omega_{k} \cdot \phi\right) \sin \left(\omega_{k} \cdot t\right)+\cos \left(\omega_{k} \cdot \phi\right) \cos \left(\omega_{k} \cdot t\right)\end{array}\]</span><span class="math display">\[By solving above equations, we get:\]</span><span class="math display">\[\begin{aligned}u_{1}=\cos \left(\omega_{k} \cdot \phi\right) ， v_{1}=\sin \left(\omega_{k} \cdot \phi\right) \\u_{2}=-\sin \left(\omega_{k} \cdot \phi\right) ， v_{2}=\cos \left(\omega_{k} \cdot \phi\right)\end{aligned}\]</span><span class="math display">\[So the final transformation matrix M is:\]</span> M_{,k}=<span class="math display">\[\begin{bmatrix} cos(\omega_k,\phi) &amp; sin(\omega_k,\phi) \\- sin(\omega_k,\phi) &amp; cos(\omega_k,\phi)\end{bmatrix}\]</span><p>$$</p><h4 id="构建encoder的self-attention-mask">2.3 构建encoder的self-attention mask</h4><p>mask的shape：[batch_size,max_src_len,max_tgt_len] 值为1或-inf</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step4 构建encoder的self-attention mask</span></span><br><span class="line">valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(<span class="number">0</span>,<span class="built_in">max</span>(src_len) - L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> src_len]),<span class="number">2</span>) <span class="comment"># 有效长度</span></span><br><span class="line">valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos,valid_encoder_pos.transpose(<span class="number">1</span>,<span class="number">2</span>)) <span class="comment"># 有效矩阵</span></span><br><span class="line">invalid_encoder_pos_matrix = <span class="number">1</span> - valid_encoder_pos_matrix</span><br><span class="line">mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.<span class="built_in">bool</span>) <span class="comment"># 变为bool</span></span><br><span class="line"><span class="built_in">print</span>(valid_encoder_pos_matrix,<span class="string">&#x27;\n&#x27;</span>,invalid_encoder_pos_matrix,<span class="string">&#x27;\n&#x27;</span>,mask_encoder_self_attention) <span class="comment">#(batchsize,maxlen after padding,_)</span></span><br><span class="line"><span class="comment"># true 需要 mask</span></span><br><span class="line"></span><br><span class="line">score = torch.randn(batch_size,<span class="built_in">max</span>(src_len),<span class="built_in">max</span>(src_len))</span><br><span class="line"><span class="comment"># print(score.shape,mask_encoder_self_attention.shape)</span></span><br><span class="line"><span class="comment"># masked </span></span><br><span class="line">masked_score = score.masked_fill(mask_encoder_self_attention,-<span class="number">1e9</span>)</span><br><span class="line">prob = F.softmax(masked_score,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(src_len)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br><span class="line"><span class="built_in">print</span>(masked_score)</span><br><span class="line"><span class="built_in">print</span>(prob)</span><br><span class="line"><span class="comment"># 无需因果的遮掩</span></span><br></pre></td></tr></table></figure><h4 id="scaled-的重要性">2.4 scaled 的重要性</h4><p><span class="math display">\[\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\]</span></p><p>这里的softmax中为什么要除以<span class="math inline">\(\sqrt{d_k}\)</span>?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># when the varience of prob is too big</span></span><br><span class="line">alpha1 = <span class="number">0.1</span></span><br><span class="line">alpha2 = <span class="number">10</span></span><br><span class="line">score = torch.randn(<span class="number">5</span>)</span><br><span class="line">prob1 = F.softmax(score*alpha1,-<span class="number">1</span>)</span><br><span class="line">prob2 = F.softmax(score*alpha2,-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax_func</span>(<span class="params">score</span>):</span><br><span class="line">    <span class="keyword">return</span> F.softmax(score)</span><br><span class="line">jaco_mat1 = torch.autograd.functional.jacobian(softmax_func,score*alpha1)</span><br><span class="line">jaco_mat2 = torch.autograd.functional.jacobian(softmax_func,score*alpha2)</span><br><span class="line"><span class="comment"># jaco matrix is close to zero when the varience is too big</span></span><br><span class="line"><span class="comment"># print(score,prob1,prob2)</span></span><br><span class="line"><span class="built_in">print</span>(jaco_mat1,<span class="string">&#x27;\n&#x27;</span>,jaco_mat2)</span><br></pre></td></tr></table></figure><h3 id="decoder-细节">3 decoder 细节</h3><h4 id="intra-attention-的-mask">3.1 intra-attention 的 mask</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step5 构造intra-attention的mask</span></span><br><span class="line"><span class="comment"># Q @ k^T shape:(batch_size,tgt_seq_len,src_seq_len)</span></span><br><span class="line">valid_decoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(<span class="number">0</span>,<span class="built_in">max</span>(tgt_len) - L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> tgt_len]),<span class="number">2</span>)</span><br><span class="line">valid_cross_pos_matrix = torch.bmm(valid_decoder_pos,valid_encoder_pos.transpose(<span class="number">1</span>,<span class="number">2</span>)) <span class="comment"># 有效位置</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源序列有效位置张量：&quot;</span>,valid_encoder_pos,<span class="string">&quot;\n 目标序列有效位置张量：&quot;</span>,valid_decoder_pos,<span class="string">&quot;\n 目标序列对源头序列有效位置张量：&quot;</span>,valid_cross_pos)</span><br><span class="line"></span><br><span class="line">invalid_cross_pos_matrix = <span class="number">1</span> - valid_cross_pos_matrix</span><br><span class="line">mask_cross_attention = invalid_cross_pos_matrix.to(torch.<span class="built_in">bool</span>)</span><br><span class="line"><span class="built_in">print</span>(mask_cross_attention)</span><br><span class="line"><span class="comment"># print(valid_cross_pos)</span></span><br><span class="line">score = torch.randn(batch_size,<span class="built_in">max</span>(tgt_len),<span class="built_in">max</span>(tgt_len))</span><br><span class="line"><span class="comment"># print(score.shape,mask_encoder_self_attention.shape)</span></span><br><span class="line"><span class="comment"># masked </span></span><br><span class="line">masked_cross_score = score.masked_fill(mask_cross_attention,-<span class="number">1e9</span>)</span><br><span class="line">prob_cross = F.softmax(masked_cross_score,-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(prob_cross)</span><br></pre></td></tr></table></figure><h4 id="decoder-self-attention">3.2 decoder self-attention</h4><p>下三角形的mask：防止因果</p><p>要把答案遮住，如果预测第四个位置，就要把第四个位置以后的所有内容都遮住。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step6 构造 decoder self-attention 的 mask</span></span><br><span class="line">valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L,L))),(<span class="number">0</span>,<span class="built_in">max</span>(tgt_len) - L,<span class="number">0</span>,<span class="built_in">max</span>(tgt_len) - L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> tgt_len])</span><br><span class="line"></span><br><span class="line">invalid_decoder_tri_matrix = <span class="number">1</span> - valid_decoder_tri_matrix</span><br><span class="line">invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.<span class="built_in">bool</span>)</span><br><span class="line"><span class="built_in">print</span>(valid_decoder_tri_matrix,invalid_decoder_tri_matrix)</span><br><span class="line"></span><br><span class="line">score = torch.randn(batch_size,<span class="built_in">max</span>(tgt_len),<span class="built_in">max</span>(tgt_len))</span><br><span class="line">masked_score = score.masked_fill(invalid_decoder_tri_matrix,-<span class="number">1e9</span>)</span><br><span class="line">prob = F.softmax(masked_score,-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(tgt_len)</span><br><span class="line"><span class="built_in">print</span>(prob)</span><br></pre></td></tr></table></figure><p>流式预测的时候，特别需要这个掩码。</p><h4 id="scaled-self-attention">3.3 scaled self-attention</h4><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101603265.png" alt="image-20230410160332412" /><figcaption aria-hidden="true">image-20230410160332412</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaled_dot_product_attention</span>(<span class="params">Q,K,V,attn_mask</span>):</span><br><span class="line">    <span class="comment"># shape pf Q,k,V: (batch_size * num_head,seq_len,model_dim/num_head)</span></span><br><span class="line">    score = torch.bmn(Q,K.transpose(-<span class="number">2</span>,-<span class="number">1</span>))/torch.sqrt(model_dim)</span><br><span class="line">    masked_score = score.masked_fill(attn_mask,-<span class="number">1e9</span>)</span><br><span class="line">    prob = F.softmax(masked_score,-<span class="number">1</span>)</span><br><span class="line">    context = torch.bmn(prov,V)</span><br><span class="line">    <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure><p>源码：D:\0_python-packages.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multi_head_attention_forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">    query: Tensor,</span></span><br><span class="line"><span class="params">    key: Tensor,</span></span><br><span class="line"><span class="params">    value: Tensor,</span></span><br><span class="line"><span class="params">    embed_dim_to_check: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    num_heads: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    in_proj_weight: <span class="type">Optional</span>[Tensor],</span></span><br><span class="line"><span class="params">    in_proj_bias: <span class="type">Optional</span>[Tensor],</span></span><br><span class="line"><span class="params">    bias_k: <span class="type">Optional</span>[Tensor],</span></span><br><span class="line"><span class="params">    bias_v: <span class="type">Optional</span>[Tensor],</span></span><br><span class="line"><span class="params">    add_zero_attn: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">    dropout_p: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">    out_proj_weight: Tensor,</span></span><br><span class="line"><span class="params">    out_proj_bias: <span class="type">Optional</span>[Tensor],</span></span><br><span class="line"><span class="params">    training: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    key_padding_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    need_weights: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    attn_mask: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    use_separate_proj_weight: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    q_proj_weight: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    k_proj_weight: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    v_proj_weight: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    static_k: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    static_v: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    average_attn_weights: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[Tensor, <span class="type">Optional</span>[Tensor]]:</span><br></pre></td></tr></table></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101653337.png" alt="image-20230410165300158" /><figcaption aria-hidden="true">image-20230410165300158</figcaption></figure><h3 id="loss-function">4 Loss function</h3><p>https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304101703643.png" alt="image-20230410170322549" /><figcaption aria-hidden="true">image-20230410170322549</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">bath_size = <span class="number">2</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">vocab_size = <span class="number">4</span></span><br><span class="line">logits = torch.randn(bath_size,seq_len,vocab_size)      <span class="comment"># bath_size = 2, seq_len = 3, vocab_size = 4</span></span><br><span class="line">label = torch.randint(<span class="number">0</span>,vocab_size,(bath_size,seq_len))</span><br><span class="line">logits = logits.transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">F.cross_entropy(logits,label) <span class="comment"># 六个单词的平均交叉熵</span></span><br><span class="line">F.cross_entropy(logits,label,reduction=<span class="string">&quot;none&quot;</span>) <span class="comment"># 返回所有单词的交叉熵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mask</span></span><br><span class="line">tgt_len =torch.Tensor([<span class="number">2</span>,<span class="number">3</span>]).to(torch.int32)</span><br><span class="line">mask = torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(<span class="number">0</span>,<span class="built_in">max</span>(tgt_len)-L)),<span class="number">0</span>) <span class="keyword">for</span> L <span class="keyword">in</span> tgt_len])</span><br><span class="line"></span><br><span class="line">cross_entropy = F.cross_entropy(logits,label,reduction=<span class="string">&quot;none&quot;</span>) * mask </span><br><span class="line"><span class="built_in">print</span>(cross_entropy)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;https://arxiv.org/pdf/1706.03762.pdf&lt;/p&gt;
&lt;p&gt;https://nlp.seas.harvard.edu/2018/04/03/attention.html&lt;/p&gt;
&lt;h3 id=&quot;attention-is-all-you-nee</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>pytorch项目4-读取Excel/csv文件格式为PyTorch张量</title>
    <link href="https://wangtongyouwen.github.io/post/9358f042.html"/>
    <id>https://wangtongyouwen.github.io/post/9358f042.html</id>
    <published>2023-04-27T08:33:55.000Z</published>
    <updated>2023-05-05T11:59:32.158Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ExcelDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.xlsx&quot;</span>, sheet_name=<span class="number">0</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>, sheet=<span class="subst">&#123;sheet_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.xlsx&quot;</span>, sheet_name=<span class="number">0</span></span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>, sheet=<span class="subst">&#123;sheet_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            df = pandas.read_excel(</span><br><span class="line">                <span class="comment"># filepath,header=0,index_col=0,</span></span><br><span class="line">                filepath, header=<span class="number">0</span>,</span><br><span class="line">                names=[<span class="string">&#x27;admit&#x27;</span>, <span class="string">&#x27;gre&#x27;</span>, <span class="string">&#x27;gpa&#x27;</span>, <span class="string">&#x27;prestige&#x27;</span>],</span><br><span class="line">                sheet_name=sheet_name,</span><br><span class="line">                dtype=&#123;<span class="string">&quot;gre&quot;</span>: np.float32, <span class="string">&quot;gpa&quot;</span>: np.float32, <span class="string">&quot;admit&quot;</span>: np.int8, <span class="string">&quot;prestige&quot;</span>: np.string_&#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;the shape of dataframe is <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            feat = df.iloc[:, <span class="number">1</span>:<span class="number">3</span>].values</span><br><span class="line">            label = df.iloc[:, <span class="number">0</span>].values</span><br><span class="line">            self.x = torch.from_numpy(feat)</span><br><span class="line">            self.y = torch.from_numpy(label)</span><br><span class="line">            <span class="comment"># print(feat,label)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">            <span class="keyword">return</span> self.x[index], self.y[index]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Csv2Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath=<span class="string">&quot;train.csv&quot;</span></span>):</span><br><span class="line">        <span class="comment"># there is no sheet name definition in csv format file</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;reading <span class="subst">&#123;filepath&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file=filepath,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = f.readlines()</span><br><span class="line">        feat = []</span><br><span class="line">        label = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</span><br><span class="line">            values = line.strip().split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            row_feat = [<span class="built_in">float</span>(v) <span class="keyword">if</span> v <span class="keyword">is</span> <span class="keyword">not</span>  <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> v <span class="keyword">in</span> values[<span class="number">1</span>:<span class="number">2</span>]]</span><br><span class="line">            row_label = <span class="built_in">int</span>(values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            feat.append(row_feat)</span><br><span class="line">            label.append(row_label)</span><br><span class="line">        feat = np.array(feat,dtype=np.float32)</span><br><span class="line">        label = np.array(label,dtype=np.int8)</span><br><span class="line"></span><br><span class="line">        self.x = torch.from_numpy(feat)</span><br><span class="line">        self.y = torch.from_numpy(label)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br></pre></td></tr></table></figure><p>其中对缺省值进行处理，可以使用平均数来代替这个缺省值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/categories/pytorch/project/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>pytorch项目3-基于ResNet的水果蔬菜分类</title>
    <link href="https://wangtongyouwen.github.io/post/4627104a.html"/>
    <id>https://wangtongyouwen.github.io/post/4627104a.html</id>
    <published>2023-04-26T13:21:35.000Z</published>
    <updated>2023-05-06T07:00:06.166Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据集介绍">1 数据集介绍</h2><p>https://aistudio.baidu.com/aistudio/datasetdetail/119023</p><p>其中的图片有36各类，不同类别在不同的文件夹中，其中文件后缀有"jpg,png,JPG"</p><h2 id="数据集预处理">2 数据集预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pre_Data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 对所有图片进行RGB转换，并且统一调整到一致大小，但不让图片发生变形或扭曲,划分训练集和测试集&quot;&quot;&quot;</span></span><br><span class="line">    test_split_ratio = <span class="number">0.05</span></span><br><span class="line">    desired_size =<span class="number">128</span> <span class="comment"># 图片缩放后的同一大小</span></span><br><span class="line">    raw_path = <span class="string">&quot;./raw&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># class files in the raw data</span></span><br><span class="line">    dirs = glob.glob(os.path.join(raw_path,<span class="string">&quot;*&quot;</span>))</span><br><span class="line">    dirs = [d <span class="keyword">for</span> d <span class="keyword">in</span> dirs <span class="keyword">if</span> os.path.isdir(d)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(dirs)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(dirs)&#125;</span> classes: <span class="subst">&#123;dirs&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> dirs:</span><br><span class="line">        <span class="comment"># 对每个类别单独处理</span></span><br><span class="line">        path = path.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>] <span class="comment"># classes</span></span><br><span class="line">        <span class="comment"># print(path)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>,exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>):</span><br><span class="line">            os.makedirs(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        files = glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">        files += glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.JPG&quot;</span>))</span><br><span class="line">        files += glob.glob(os.path.join(raw_path,path,<span class="string">&quot;*.png&quot;</span>))</span><br><span class="line">        <span class="comment"># print(files)</span></span><br><span class="line">        random.shuffle(files)</span><br><span class="line"></span><br><span class="line">        boundary = <span class="built_in">int</span>(<span class="built_in">len</span>(files)*test_split_ratio) <span class="comment"># 测试集和训练集的边界</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i,file <span class="keyword">in</span> <span class="built_in">enumerate</span>(files):</span><br><span class="line">            img = Image.<span class="built_in">open</span>(file).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">            <span class="comment"># print(img)</span></span><br><span class="line">            old_size = img.size <span class="comment"># old_size[0] is in (width,height) format</span></span><br><span class="line">            <span class="comment"># print(old_size)</span></span><br><span class="line"></span><br><span class="line">            ratio = <span class="built_in">float</span>(desired_size)/<span class="built_in">max</span>(old_size)</span><br><span class="line"></span><br><span class="line">            new_size = <span class="built_in">tuple</span>([<span class="built_in">int</span>(x*ratio) <span class="keyword">for</span> x <span class="keyword">in</span> old_size])</span><br><span class="line"></span><br><span class="line">            im = img.resize(new_size,Image.LANCZOS) <span class="comment"># 无模糊</span></span><br><span class="line"></span><br><span class="line">            new_im = Image.new(<span class="string">&quot;RGB&quot;</span>,(desired_size,desired_size))</span><br><span class="line">            new_im.paste(im,((desired_size-new_size[<span class="number">0</span>])//<span class="number">2</span>,</span><br><span class="line">                             (desired_size-new_size[<span class="number">1</span>])//<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">assert</span> new_im.mode == <span class="string">&quot;RGB&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i &lt;= boundary:</span><br><span class="line">                new_im.save(os.path.join(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>,file.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]+ <span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(get_filename(file)+<span class="string">&quot;.jpg&quot;</span>) <span class="keyword">not</span> <span class="keyword">in</span> os.listdir(os.path.join(<span class="string">f&quot;test/<span class="subst">&#123;path&#125;</span>&quot;</span>)):</span><br><span class="line">                    new_im.save(os.path.join(<span class="string">f&quot;train/<span class="subst">&#123;path&#125;</span>&quot;</span>,file.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]+ <span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;classes <span class="subst">&#123;path&#125;</span> is done !&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_files = glob.glob(os.path.join(<span class="string">&quot;test&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">    train_files = glob.glob(os.path.join(<span class="string">&quot;train&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(test_files)&#125;</span> files for testing&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(train_files)&#125;</span> files for training&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_mean_std</span>():</span><br><span class="line">    train_files = glob.glob(os.path.join(<span class="string">&quot;train&quot;</span>,<span class="string">&quot;*&quot;</span>,<span class="string">&quot;*.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;totally <span class="subst">&#123;<span class="built_in">len</span>(train_files)&#125;</span> files for training&quot;</span>)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> train_files:</span><br><span class="line">        img = Image.<span class="built_in">open</span>(file).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        img = np.array(img).astype(np.uint8)</span><br><span class="line">        img = img / <span class="number">255</span></span><br><span class="line">        result.append(img)</span><br><span class="line">    <span class="built_in">print</span>(np.shape(result)) <span class="comment"># [bs,H,W,C]</span></span><br><span class="line">    mean = np.mean(result,axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    std = np.std(result,axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">    <span class="built_in">print</span>(mean,std</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="eval">3 eval</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">data_loader, model, device</span>):</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    metric_logger = misc.MetricLogger(delimiter=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    header = <span class="string">&quot;test:&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># switch to evaluation mode</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> metric_logger.log_every(data_loader, <span class="number">10</span>, header):</span><br><span class="line">        <span class="comment"># print(batch)</span></span><br><span class="line">        images = batch[<span class="number">0</span>]</span><br><span class="line">        target = batch[-<span class="number">1</span>]</span><br><span class="line">        images = images.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line">        target = target.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute output</span></span><br><span class="line">        output = model(images)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line"></span><br><span class="line">        output = F.softmax(output, dim=-<span class="number">1</span>)</span><br><span class="line">        acc1, acc5 = accuracy(output, target, topk=(<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        batch_size = images.shape[<span class="number">0</span>]</span><br><span class="line">        metric_logger.update(loss=loss.item())</span><br><span class="line">        metric_logger.meters[<span class="string">&#x27;acc1&#x27;</span>].update(acc1.item(), n=batch_size)</span><br><span class="line">        metric_logger.meters[<span class="string">&#x27;acc5&#x27;</span>].update(acc5.item(), n=batch_size)</span><br><span class="line">    <span class="comment"># gather the stats from all processes</span></span><br><span class="line">    metric_logger.synchronize_between_processes()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;* Acc@1 &#123;top1.global_avg:.3f&#125; Acc@5 &#123;top5.global_avg:.3f&#125; loss &#123;losses.global_avg:.3f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))</span><br><span class="line">    <span class="keyword">return</span> &#123;k: meter.global_avg <span class="keyword">for</span> k, meter <span class="keyword">in</span> metric_logger.meters.items()&#125;</span><br></pre></td></tr></table></figure><h2 id="train">4 train</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model: nn.Module, criterion: nn.Module, data_loader: Iterable, optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">                    device: torch.device, epoch: <span class="built_in">int</span>, loss_scaler, max_norm: <span class="built_in">float</span> = <span class="number">0</span>, log_writer=<span class="literal">None</span>, args=<span class="literal">None</span></span>):</span><br><span class="line">    model.train(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    accum_iter = args.accum_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;log_dir:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(log_writer.log_dir))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_iter_step, (samples, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        samples = samples.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line">        targets = targets.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        outputs = model(samples)</span><br><span class="line"></span><br><span class="line">        warmup_lr = args.lr</span><br><span class="line">        optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>] = warmup_lr</span><br><span class="line"></span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss /= accum_iter</span><br><span class="line"></span><br><span class="line">        loss_scaler(loss, optimizer, clip_grad=max_norm,</span><br><span class="line">                    parameters=model.parameters(), create_graph=<span class="literal">False</span>,</span><br><span class="line">                    update_grad=(data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        loss_value = loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> math.isfinite(loss_value):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Loss is &#123;&#125;, stopping training&quot;</span>.<span class="built_in">format</span>(loss_value))</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot; We use epoch_1000x as the x-axis in tensorboard.</span></span><br><span class="line"><span class="string">            This calibrates different curves when batch size changes.</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            epoch_1000x = <span class="built_in">int</span>((data_iter_step / <span class="built_in">len</span>(data_loader) + epoch) * <span class="number">1000</span>)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;loss&#x27;</span>, loss_value, epoch_1000x)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;lr&#x27;</span>, warmup_lr, epoch_1000x)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch:<span class="subst">&#123;epoch&#125;</span>,Step: <span class="subst">&#123;data_iter_step&#125;</span>,loss: <span class="subst">&#123;loss&#125;</span>,lr: <span class="subst">&#123;warmup_lr&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="dataset">5 dataset</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def build_transform(is_train, args):</span><br><span class="line">    if is_train:</span><br><span class="line">        # this should always dispatch to transforms_imagenet_train</span><br><span class="line">        print(&quot;train transform&quot;)</span><br><span class="line">        return torchvision.transforms.Compose([</span><br><span class="line">            torchvision.transforms.Resize((args.input_size, args.input_size)),</span><br><span class="line">            torchvision.transforms.RandomHorizontalFlip(),</span><br><span class="line">            torchvision.transforms.RandomVerticalFlip(),</span><br><span class="line">            torchvision.transforms.RandomPerspective(distortion_scale=0.6, p=1.0),</span><br><span class="line">            torchvision.transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),</span><br><span class="line">            torchvision.transforms.ToTensor(),</span><br><span class="line">        ])</span><br><span class="line">    # eval transform</span><br><span class="line">    print(&quot;eval transform&quot;)</span><br><span class="line">    return torchvision.transforms.Compose([</span><br><span class="line">        torchvision.transforms.Resize((args.input_size, args.input_size)),</span><br><span class="line">        torchvision.transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def build_dataset(is_train, args):</span><br><span class="line">    transform = build_transform(is_train, args)</span><br><span class="line">    path = os.path.join(args.root_path, &quot;train&quot; if is_train else &quot;test&quot;)</span><br><span class="line">    dataset = torchvision.datasets.ImageFolder(path, transform=transform)</span><br><span class="line">    info = dataset.find_classes(path)</span><br><span class="line">    print(f&quot;finding classes from &#123;path&#125;:\t &#123;info[0]&#125;&quot;)</span><br><span class="line">    print(f&quot;mapping classes from &#123;path&#125; to indexes:\t &#123;info[1]&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    return dataset</span><br></pre></td></tr></table></figure><h2 id="argparse">6 argparse</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_args_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;MAE pre-training&#x27;</span>, add_help=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">72</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, default=<span class="number">400</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--accum_iter&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Accumulate gradient iterations (for increasing the effective batch size under memory constraints)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Model parameters</span></span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--input_size&#x27;</span>, default=<span class="number">128</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;images input size&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimizer parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weight_decay&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;weight decay (default: 0.0001)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>, metavar=<span class="string">&#x27;LR&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;learning rate (absolute lr)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dataset parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--root-path&#x27;</span>, default=<span class="string">&#x27;./dataset_fruit_veg/&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where the train test pic is &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--output_dir&#x27;</span>, default=<span class="string">&#x27;./output_dir_pretrained&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to save, empty for no saving&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--log_dir&#x27;</span>, default=<span class="string">&#x27;./output_dir_pretrained&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;path where to tensorboard log&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--resume&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;resume from checkpoint&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--start_epoch&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;start epoch&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, default=<span class="number">5</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--pin_mem&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--no_pin_mem&#x27;</span>, action=<span class="string">&#x27;store_false&#x27;</span>, dest=<span class="string">&#x27;pin_mem&#x27;</span>)</span><br><span class="line">    parser.set_defaults(pin_mem=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># distributed training parameters</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--world_size&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of distributed processes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dist_on_itp&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dist_url&#x27;</span>, default=<span class="string">&#x27;env://&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;url used to set up distributed training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser</span><br></pre></td></tr></table></figure><h2 id="主要代码">7 主要代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args, mode=<span class="string">&quot;train&quot;</span>, test_image_path=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;mode&#125;</span> mode...&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建数据批次</span></span><br><span class="line">        dataset_train = build_dataset(is_train=<span class="literal">True</span>, args=args)</span><br><span class="line">        dataset_val = build_dataset(is_train=<span class="literal">False</span>, args=args)</span><br><span class="line"></span><br><span class="line">        sampler_train = torch.utils.data.RandomSampler(dataset_train)</span><br><span class="line">        sampler_val = torch.utils.data.SequentialSampler(dataset_val)</span><br><span class="line"></span><br><span class="line">        data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">            dataset_train, sampler=sampler_train,</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">            pin_memory=args.pin_mem,</span><br><span class="line">            drop_last=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        data_loader_val = torch.utils.data.DataLoader(</span><br><span class="line">            dataset_val, sampler=sampler_val,</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            <span class="comment"># batch_size = 1</span></span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">            pin_memory=args.pin_mem,</span><br><span class="line">            drop_last=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 构建模型</span></span><br><span class="line">        model = timm.create_model(<span class="string">&quot;resnet18&quot;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">36</span>, drop_rate=<span class="number">0.1</span>, drop_path_rate=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">        n_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;number of trainable params (M):%.2f&#x27;</span> % (n_parameters / <span class="number">1.e6</span>))</span><br><span class="line"></span><br><span class="line">        criterion = nn.CrossEntropyLoss()</span><br><span class="line">        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log dir</span></span><br><span class="line">        os.makedirs(args.log_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        log_writer = SummaryWriter(log_dir=args.log_dir)</span><br><span class="line">        loss_scaler = NativeScaler()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读入已有的模型</span></span><br><span class="line">        misc.load_model(args=args, model_without_ddp=model, optimizer=optimizer, loss_scaler=loss_scaler)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch<span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;length of data_loader_train is <span class="subst">&#123;<span class="built_in">len</span>(data_loader_train)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Evaluating...&quot;</span>)</span><br><span class="line">                model.<span class="built_in">eval</span>()</span><br><span class="line">                test_stats = evaluate(data_loader_val, model, device)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Accuracy of the network on the <span class="subst">&#123;<span class="built_in">len</span>(dataset_val)&#125;</span> test images: <span class="subst">&#123;test_stats[<span class="string">&#x27;acc1&#x27;</span>]:<span class="number">.1</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_acc1&quot;</span>, test_stats[<span class="string">&quot;acc1&quot;</span>], epoch)</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_acc5&quot;</span>, test_stats[<span class="string">&quot;acc5&quot;</span>], epoch)</span><br><span class="line">                    log_writer.add_scalar(<span class="string">&quot;perf/test_loss&quot;</span>, test_stats[<span class="string">&quot;loss&quot;</span>], epoch)</span><br><span class="line">                model.train()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;training...&quot;</span>)</span><br><span class="line">            train_stats = train_one_epoch(</span><br><span class="line">                model, criterion, data_loader_train,</span><br><span class="line">                optimizer, device, epoch + <span class="number">1</span>, loss_scaler, <span class="literal">None</span>, log_writer=log_writer, args=args</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(train_stats)</span><br><span class="line">            <span class="keyword">if</span> args.output_dir:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;saving checkpoint...&quot;</span>)</span><br><span class="line">                misc.save_model(</span><br><span class="line">                    args=args,model=model,model_without_ddp=model,optimizer=optimizer,</span><br><span class="line">                    loss_scaler=loss_scaler,epoch=epoch</span><br><span class="line">                )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model = timm.create_model(<span class="string">&quot;resnet18&quot;</span>, pretrained=<span class="literal">True</span>, num_classes=<span class="number">36</span>, drop_rate=<span class="number">0.1</span>, drop_path_rate=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">        class_dict = &#123;<span class="string">&#x27;apple&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;banana&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;beetroot&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;bell pepper&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;cabbage&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;capsicum&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">                      <span class="string">&#x27;carrot&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;cauliflower&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;chilli pepper&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;corn&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;cucumber&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;eggplant&#x27;</span>: <span class="number">11</span>,</span><br><span class="line">                      <span class="string">&#x27;garlic&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;ginger&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;grapes&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;jalepeno&#x27;</span>: <span class="number">15</span>, <span class="string">&#x27;kiwi&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;lemon&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;lettuce&#x27;</span>: <span class="number">18</span>,</span><br><span class="line">                      <span class="string">&#x27;mango&#x27;</span>: <span class="number">19</span>, <span class="string">&#x27;onion&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;orange&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;paprika&#x27;</span>: <span class="number">22</span>, <span class="string">&#x27;pear&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;peas&#x27;</span>: <span class="number">24</span>, <span class="string">&#x27;pineapple&#x27;</span>: <span class="number">25</span>,</span><br><span class="line">                      <span class="string">&#x27;pomegranate&#x27;</span>: <span class="number">26</span>, <span class="string">&#x27;potato&#x27;</span>: <span class="number">27</span>, <span class="string">&#x27;raddish&#x27;</span>: <span class="number">28</span>, <span class="string">&#x27;soy beans&#x27;</span>: <span class="number">29</span>, <span class="string">&#x27;spinach&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;sweetcorn&#x27;</span>: <span class="number">31</span>,</span><br><span class="line">                      <span class="string">&#x27;sweetpotato&#x27;</span>: <span class="number">32</span>, <span class="string">&#x27;tomato&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;turnip&#x27;</span>: <span class="number">34</span>, <span class="string">&#x27;watermelon&#x27;</span>: <span class="number">35</span>&#125;</span><br><span class="line"></span><br><span class="line">        n_parameters = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;number of trainable params (M):%.2f&#x27;</span> % (n_parameters / <span class="number">1.e6</span>))</span><br><span class="line"></span><br><span class="line">        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)</span><br><span class="line">        os.makedirs(args.log_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        loss_scaler = NativeScaler()</span><br><span class="line"></span><br><span class="line">        misc.load_model(args=args, model_without_ddp=model, optimizer=optimizer, loss_scaler=loss_scaler)</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(test_image_path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        image = image.resize((args.input_size, args.input_size), Image.ANTIALIAS)</span><br><span class="line">        image = torchvision.transforms.ToTensor()(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            output = model(image)</span><br><span class="line"></span><br><span class="line">        output = F.softmax(output, dim=-<span class="number">1</span>)</span><br><span class="line">        class_idx = torch.argmax(output, dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">        score = torch.<span class="built_in">max</span>(output, dim=<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;image path is <span class="subst">&#123;test_image_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;score is <span class="subst">&#123;score.item()&#125;</span>, class id is <span class="subst">&#123;class_idx.item()&#125;</span>,  &quot;</span></span><br><span class="line">            <span class="string">f&quot;class name is <span class="subst">&#123;<span class="built_in">list</span>(class_dict.keys())[<span class="built_in">list</span>(class_dict.values()).index(class_idx)]&#125;</span>&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p>分为两大部分：</p><ul><li>首先进行eval</li><li>然后进行训练</li></ul><h2 id="infer">8 infer</h2><ul><li>修改resume</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&#x27;--resume&#x27;, default=&#x27;./output_dir_pretrained/checkpoint-24.pth&#x27;,help=&#x27;resume from checkpoint&#x27;)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;数据集介绍&quot;&gt;1 数据集介绍&lt;/h2&gt;
&lt;p&gt;https://aistudio.baidu.com/aistudio/datasetdetail/119023&lt;/p&gt;
&lt;p&gt;其中的图片有36各类，不同类别在不同的文件夹中，其中文件后缀有&quot;jpg,png,JPG</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/categories/pytorch/project/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="project" scheme="https://wangtongyouwen.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络11-GAN</title>
    <link href="https://wangtongyouwen.github.io/post/cad0a038.html"/>
    <id>https://wangtongyouwen.github.io/post/cad0a038.html</id>
    <published>2023-04-24T11:36:29.000Z</published>
    <updated>2023-04-30T13:07:07.758Z</updated>
    
    <content type="html"><![CDATA[<h1 id="generative-adversarial-nets">Generative Adversarial Nets</h1><p>https://arxiv.org/pdf/1406.2661.pdf</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241952572.png" alt="image-20230424195239653" /><figcaption aria-hidden="true">image-20230424195239653</figcaption></figure><p>Pearson散度和Jensen-Shannon散度都是衡量两个概率分布之间差异的方法，但它们具有不同的计算方式和特点。</p><ol type="1"><li>Pearson散度（Pearson Divergence）： Pearson散度是衡量两个概率分布之间的差异的一种方法，主要基于卡方统计量（Chi-Square statistic）。对于两个概率分布P和Q，Pearson散度的计算公式如下：</li></ol><p>D_Pearson(P, Q) = Σ[(P(x) - Q(x))^2 / Q(x)]</p><p>其中，x表示数据空间中的元素，P(x)和Q(x)分别表示概率分布P和Q在x处的概率密度。</p><p>Pearson散度的值越大，表示两个概率分布之间的差异越大。需要注意的是，Pearson散度不是一种距离度量，因为它不满足三角不等式。</p><ol type="1"><li>Jensen-Shannon散度（Jensen-Shannon Divergence）： Jensen-Shannon散度是一种对称的、有界的散度度量方法，用于衡量两个概率分布之间的差异。它是基于Kullback-Leibler散度（KL散度）的改进版本。对于两个概率分布P和Q，Jensen-Shannon散度的计算公式如下：</li></ol><p>D_JS(P, Q) = (1/2) * D_KL(P, M) + (1/2) * D_KL(Q, M)</p><p>其中，M = (1/2) * (P + Q)，D_KL(P, M)和D_KL(Q, M)分别表示P和Q相对于M的Kullback-Leibler散度。</p><p>Jensen-Shannon散度的值在0到1之间，值越大表示两个概率分布之间的差异越大。当两个分布完全相同时，Jensen-Shannon散度为0；当两个分布完全不相交时，Jensen-Shannon散度接近1。可以通过计算Jensen-Shannon散度的平方根得到Jensen-Shannon距离，它满足距离度量的性质。</p><p>总结一下，Pearson散度和Jensen-Shannon散度都是衡量两个概率分布之间差异的方法，但它们的计算方式和特点不同。Pearson散度基于卡方统计量，而Jensen-Shannon散度基于Kullback-Leibler散度。Jensen-Shannon散度是对称的、有界的，可以通过计算其平方根得到满足距离度量性质的Jensen-Shannon距离。</p><h1 id="code">code</h1><h2 id="generator">1 Generator</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.utils.data.dataloader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;基于 MNist 实现对抗生成网络(GAN)&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(latent_dim, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, np.prod(image_size)),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        output = self.model(z)</span><br><span class="line">        image = torch.reshape(output, (z.shape[<span class="number">0</span>], *image_size))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure><h2 id="discriminator">2 Discriminator</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(np.prod(image_size), <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        prob = self.model(torch.reshape(image, (image.shape[<span class="number">0</span>], -<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> prob</span><br></pre></td></tr></table></figure><h2 id="training">3 training</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training</span></span><br><span class="line">image_size = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">latent_dim = <span class="number">100</span></span><br><span class="line">num_epoch = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                     transform=torchvision.transforms.Compose([</span><br><span class="line">                                         torchvision.transforms.Resize(<span class="number">28</span>),</span><br><span class="line">                                         torchvision.transforms.ToTensor(),</span><br><span class="line">                                         torchvision.transforms.Normalize(mean=[<span class="number">0.5</span>], std=[<span class="number">0.5</span>])</span><br><span class="line">                                     ]))</span><br><span class="line"></span><br><span class="line">DataLoader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generator = Generator().cuda()</span><br><span class="line">discriminator = Discriminator().cuda()</span><br><span class="line"></span><br><span class="line">g_optimizer = torch.optim.Adam(params=generator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">d_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=<span class="number">0.0002</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">raw = os.path.abspath(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">output_dir = os.path.join(raw, <span class="string">&quot;mnist_data/MNIST/result&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否存在预训练的权重文件</span></span><br><span class="line">generator_weights_path = os.path.join(output_dir, <span class="string">&#x27;generator.pth&#x27;</span>)</span><br><span class="line">discriminator_weights_path = os.path.join(output_dir, <span class="string">&#x27;discriminator.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(generator_weights_path) <span class="keyword">and</span> os.path.exists(discriminator_weights_path):</span><br><span class="line">    generator.load_state_dict(torch.load(generator_weights_path))</span><br><span class="line">    discriminator.load_state_dict(torch.load(discriminator_weights_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="keyword">for</span> i, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(DataLoader):</span><br><span class="line">        gt_images, _ = mini_batch</span><br><span class="line">        gt_images = gt_images.cuda()</span><br><span class="line">        z = torch.randn(batch_size, latent_dim)</span><br><span class="line">        z = z.cuda()</span><br><span class="line">        pred_images = generator(z)</span><br><span class="line">        pred_images = pred_images.cuda()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        target_ones = torch.ones(batch_size, <span class="number">1</span>)</span><br><span class="line">        target_ones = target_ones.cuda()</span><br><span class="line">        target_zeros = torch.zeros(batch_size, <span class="number">1</span>)</span><br><span class="line">        target_zeros = target_zeros.cuda()</span><br><span class="line">        g_loss = loss_fn(discriminator(pred_images), target_ones)  <span class="comment"># 生成器</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line"></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        d_loss = loss_fn(discriminator(gt_images), target_ones) + loss_fn(discriminator(pred_images.detach()), target_zeros)  <span class="comment"># 判别器</span></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            raw = os.path.abspath(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">            output_dir = os.path.join(raw, <span class="string">&quot;mnist_data/MNIST/result&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">                os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line">            torchvision.utils.save_image(pred_images, os.path.join(output_dir, <span class="string">f&quot;image_<span class="subst">&#123;epoch&#125;</span>_<span class="subst">&#123;i // <span class="number">1000</span>&#125;</span>.png&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch: <span class="subst">&#123;epoch&#125;</span>, Batch: <span class="subst">&#123;i&#125;</span>, Generator Loss: <span class="subst">&#123;g_loss.item()&#125;</span>, Discriminator Loss: <span class="subst">&#123;d_loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存模型权重</span></span><br><span class="line">    torch.save(generator.state_dict(), generator_weights_path)</span><br><span class="line">    torch.save(discriminator.state_dict(), discriminator_weights_path)</span><br></pre></td></tr></table></figure><h1 id="cgan">CGAN</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262015876.png" alt="image-20230426201511591" /><figcaption aria-hidden="true">image-20230426201511591</figcaption></figure><p>CGAN（条件生成对抗网络，Conditional GAN）是在GAN的基础上引入条件信息的一种变体。与普通GAN相比，CGAN的生成器和判别器都接收额外的条件信息（如类别标签、文本描述等），并根据这些条件信息生成特定类别的数据。这使得CGAN能够有更好的控制生成数据的特征。</p><p>CGAN的特点如下：</p><ol type="1"><li>控制生成数据特征：CGAN可以根据输入的条件信息，生成具有特定特征的数据。这使得CGAN在生成数据时具有更高的可控性。</li><li>引入条件信息：CGAN的生成器和判别器都接收额外的条件信息，使得网络可以在训练过程中学习如何利用这些条件信息来生成和识别数据。</li><li>更好的生成性能：由于条件信息的引入，CGAN可以在生成数据时更好地捕捉数据的特征和结构，从而提高生成数据的质量。</li></ol><p>总之，与普通GAN相比，CGAN通过引入条件信息，实现了对生成数据特征的控制，使得生成数据更具有可控性和更高的质量。在很多应用场景中，如图像生成、文本生成等，CGAN已经表现出很好的性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,latent_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>,label_emb_dim)</span><br><span class="line">       ...</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z,labels</span>):</span><br><span class="line">        <span class="comment"># shape of z: [batchsize,latent_dim]</span></span><br><span class="line">        label_embedding = self.embedding(labels)</span><br><span class="line">        z = torch.cat([z,label_embedding], axis=-<span class="number">1</span>)</span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>,label_emb_dim)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image,labels</span>):</span><br><span class="line">        <span class="comment"># shape of image [batchsize,1,28,28]</span></span><br><span class="line">        label_embedding = self.embedding(labels)</span><br><span class="line">        prob = self.model(torch.cat([torch.reshape(image, (image.shape[<span class="number">0</span>], -<span class="number">1</span>)),label_embedding],axis=-<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> prob</span><br><span class="line">        </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练过程中需要对generator和discriminator的调用中引入参数label</span></span><br><span class="line">gt_images, labels = mini_batch</span><br></pre></td></tr></table></figure><h1 id="least-squares-gan">least-squares-GAN</h1><p>Least Squares Generative Adversarial Networks（LSGAN）是一种生成对抗网络（GAN）的变体，它主要针对传统GAN在训练过程中容易出现的不稳定性和梯度消失问题进行了改进。LSGAN的核心思想是将判别器（Discriminator）的损失函数从交叉熵损失（Cross-Entropy Loss）替换为最小二乘损失（Least Squares Loss），从而提高训练的稳定性和生成数据的质量。</p><p>LSGAN的主要特点如下：</p><ol type="1"><li>稳定性：与传统GAN相比，LSGAN在训练过程中表现出更高的稳定性。这主要归功于最小二乘损失函数的平滑性，它能够减少梯度消失问题的发生，使得生成器（Generator）和判别器（Discriminator）在训练过程中保持更好的平衡。</li><li>生成质量：LSGAN生成的数据质量通常优于传统GAN。最小二乘损失有助于判别器更好地区分真实数据和生成数据，从而为生成器提供更有效的梯度指导，使得生成器能够生成更高质量的数据。</li><li>更低的梯度消失风险：在传统GAN中，由于交叉熵损失在判别器接近最优时可能导致梯度消失问题，这使得生成器的训练变得困难。然而，在LSGAN中，最小二乘损失能够减轻梯度消失问题，使得生成器在整个训练过程中都能够收到有效的梯度信息。</li><li>容易实现：LSGAN的实现非常简单，只需将传统GAN的损失函数替换为最小二乘损失即可。这意味着在现有的GAN架构中，很容易将其升级为LSGAN。</li></ol><p>总之，LSGAN通过使用最小二乘损失改进了传统GAN的训练稳定性和生成数据质量。这使得LSGAN在各种生成任务中，如图像生成、文本生成等，都能取得更好的性能。</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262051780.png" alt="image-20230426205146063" /><figcaption aria-hidden="true">image-20230426205146063</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">logits = torch.linspace(-<span class="number">10</span>,<span class="number">10</span>,<span class="number">2000</span>)</span><br><span class="line">loss = []</span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"><span class="keyword">for</span> lgs <span class="keyword">in</span> logits:</span><br><span class="line">    loss.append(loss_fn(torch.sigmoid(lgs),torch.ones_like(lgs)))</span><br><span class="line"></span><br><span class="line">plt.plot(logits,loss)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304262107840.png" alt="image-20230426210738626" /><figcaption aria-hidden="true">image-20230426210738626</figcaption></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;generative-adversarial-nets&quot;&gt;Generative Adversarial Nets&lt;/h1&gt;
&lt;p&gt;https://arxiv.org/pdf/1406.2661.pdf&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>pytorch基础入门12-位置编码</title>
    <link href="https://wangtongyouwen.github.io/post/f94e9029.html"/>
    <id>https://wangtongyouwen.github.io/post/f94e9029.html</id>
    <published>2023-04-24T08:26:35.000Z</published>
    <updated>2023-04-30T06:10:14.229Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241635006.png" alt="image-20230424163501351" /><figcaption aria-hidden="true">image-20230424163501351</figcaption></figure><h1 id="transformer">1 transformer</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241637416.png" alt="image-20230424163709530" /><figcaption aria-hidden="true">image-20230424163709530</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.1d absolute sincos constant embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_1d_absolute_sincos_embeddings</span>(<span class="params">n_pos_vec,dim</span>):</span><br><span class="line">    <span class="comment"># pos_vec: torch.arrange(n_pos)</span></span><br><span class="line">    <span class="keyword">assert</span> dim % <span class="number">2</span> ==<span class="number">0</span>,<span class="string">&quot;wrong dimension&quot;</span></span><br><span class="line">    position_embedding = torch.zeros(n_pos_vec.numel(),dim,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    omega = torch.arange(dim//<span class="number">2</span>,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    omega /= dim / <span class="number">2.</span></span><br><span class="line">    omega = <span class="number">1.</span> / (<span class="number">10000</span> ** omega)</span><br><span class="line"></span><br><span class="line">    out = n_pos_vec[:,<span class="literal">None</span>] @ omega[<span class="literal">None</span>,:] <span class="comment"># [n_pos_vec,1]*[1,dim//2]</span></span><br><span class="line"></span><br><span class="line">    emb_sin = torch.sin(out)</span><br><span class="line">    emb_cos = torch.cos(out)</span><br><span class="line"></span><br><span class="line">    position_embedding[:,<span class="number">0</span>::<span class="number">2</span>] = emb_sin</span><br><span class="line">    position_embedding[:,<span class="number">1</span>::<span class="number">2</span>] = emb_cos</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>  position_embedding</span><br></pre></td></tr></table></figure><h1 id="swin-transformer">2 Swin transformer</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241914252.png" alt="image-20230424191316681" /><figcaption aria-hidden="true">image-20230424191316681</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.2d relative bias trainable embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_2d_relative_bias_trainable_embeddings</span>(<span class="params">n_head,height,width</span>):</span><br><span class="line">    <span class="comment"># width:5   bias=[-width+1, width-1]  2*width-1</span></span><br><span class="line">    <span class="comment"># height:5                            2*height-1</span></span><br><span class="line">    position_embedding = nn.Embedding((<span class="number">2</span>*width-<span class="number">1</span>)*(<span class="number">2</span>*height-<span class="number">1</span>),n_head)</span><br><span class="line">    nn.init.constant_(position_embedding,<span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_relative_position_index</span>(<span class="params">height,width</span>):</span><br><span class="line">        cords = torch.stack(torch.meshgrid(torch.arange(height),torch.arange(width))) <span class="comment">#[2,height,width]</span></span><br><span class="line">        cords_flatten = torch.flatten(cords,<span class="number">1</span>) <span class="comment"># [2,height*width]</span></span><br><span class="line">        relative_cords_bias = cords_flatten[:,:,<span class="literal">None</span>] - cords_flatten[:,<span class="literal">None</span>,:] <span class="comment">#[2,height*width,height*width]</span></span><br><span class="line"></span><br><span class="line">        relative_cords_bias[<span class="number">0</span>,:,:] += height - <span class="number">1</span></span><br><span class="line">        relative_cords_bias[<span class="number">1</span>,:,:] += width - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># A:2d,B:1d B[i*cols+j] = a[i,j]</span></span><br><span class="line"></span><br><span class="line">        relative_cords_bias[<span class="number">0</span>,:,:] *= relative_cords_bias[<span class="number">1</span>,:,:].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  relative_cords_bias.<span class="built_in">sum</span>(<span class="number">0</span>) <span class="comment"># [height*width,height*width]</span></span><br><span class="line">    relative_position_bias = get_relative_position_index(height,width)</span><br><span class="line">    bias_embedding = position_embedding(torch.flatten(relative_position_bias)).reshape(height*width,height*width,n_head) <span class="comment"># [height*width,height*width,n_head]</span></span><br><span class="line"></span><br><span class="line">    bias_embedding.permute(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>).unsqueeze(<span class="number">0</span>) <span class="comment"># [1,n_head,height*width,height*width]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bias_embedding</span><br></pre></td></tr></table></figure><h1 id="masked-ae">3 Masked AE</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.2d absolute constant sincos embedding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_2d_absolute_sincos_embeddings</span>(<span class="params">height,width,dim</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> dim % <span class="number">4</span> == <span class="number">0</span>, <span class="string">&quot;wrong dimension&quot;</span></span><br><span class="line">    position_embedding = torch.zeros(height*width,dim)</span><br><span class="line">    cords = torch.stack(torch.meshgrid(torch.arange(height,dtype=torch.<span class="built_in">float</span>), torch.arange(width,dtype=torch.<span class="built_in">float</span>)))  <span class="comment"># [2,height,width]</span></span><br><span class="line">    height_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(cords[<span class="number">0</span>]),dim//<span class="number">2</span>) <span class="comment"># [height*width,dim//2]</span></span><br><span class="line">    width_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(cords[<span class="number">1</span>]),dim//<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    position_embedding[:,:dim//<span class="number">2</span>] = height_embedding</span><br><span class="line">    position_embedding[:,dim//<span class="number">2</span>:] = width_embedding</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> position_embedding</span><br></pre></td></tr></table></figure><h1 id="section"></h1>]]></content>
    
    
      
      
    <summary type="html">&lt;figure&gt;
&lt;img src=&quot;https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304241635006.png&quot; alt=&quot;image-20230424163501351&quot; /&gt;&lt;fig</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>pytorch基础入门11-Normalization</title>
    <link href="https://wangtongyouwen.github.io/post/87a49949.html"/>
    <id>https://wangtongyouwen.github.io/post/87a49949.html</id>
    <published>2023-04-20T10:24:36.000Z</published>
    <updated>2023-04-30T06:10:05.146Z</updated>
    
    <content type="html"><![CDATA[<h1 id="layer-normalization">Layer Normalization</h1><p><a href="https://arxiv.org/pdf/1607.06450.pdf">1607.06450.pdf (arxiv.org)</a></p><p>这篇文章讨论了一种称为层归一化（Layer Normalization）的方法，用于稳定神经网络的训练过程，并减少训练时间。层归一化的核心思想是通过对单个训练样本的神经元输入求和来计算归一化所需的均值和方差。这与之前的批量归一化（Batch Normalization）方法不同，后者依赖于一个 mini-batch 中所有样本的输入分布。</p><p>以下是该论文的主要观点：</p><ol type="1"><li>层归一化将批量归一化的概念从 mini-batch 级别扩展到层级别，计算用于归一化的均值和方差来自单个训练样本中的所有神经元输入求和。</li><li>与批量归一化类似，层归一化也为每个神经元提供自适应的偏置和增益，这些参数在归一化之后但在非线性激活函数之前应用。</li><li>与批量归一化不同，层归一化在训练和测试阶段执行相同的计算，因此不依赖于 mini-batch 大小。</li><li>层归一化很容易应用于循环神经网络（RNN），因为可以在每个时间步骤单独计算归一化统计数据。</li><li>层归一化在稳定循环神经网络的隐藏状态动态方面非常有效。</li><li>实证研究表明，与以前发布的技术相比，层归一化可以显著减少训练时间。</li></ol><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202124984.png" alt="image-20230420212422293" /><figcaption aria-hidden="true">image-20230420212422293</figcaption></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202123289.png" alt="image-20230420212333495" /><figcaption aria-hidden="true">image-20230420212333495</figcaption></figure><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202229447.png" alt="image-20230420222926884" /><figcaption aria-hidden="true">image-20230420222926884</figcaption></figure><h1 id="五种归一化的代码实现">五种归一化的代码实现</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202236940.png" alt="image-20230420223608053" /><figcaption aria-hidden="true">image-20230420223608053</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 首先定义一些常量</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">time_steps = <span class="number">3</span></span><br><span class="line">embedding_dim = <span class="number">4</span></span><br><span class="line">input_x = torch.randn(batch_size,time_steps,embedding_dim)</span><br></pre></td></tr></table></figure><h2 id="batch-normalization">1 batch normalization</h2><p>torch.nn.BatchNorm1d(<em>num_features</em>, <em>eps=1e-05</em>, <em>momentum=0.1</em>, <em>affine=True</em>, <em>track_running_stats=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p><p>https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm1d</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304202240276.png" alt="parameter and shape" /><figcaption aria-hidden="true">parameter and shape</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 官方API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [C]</span></span><br><span class="line"><span class="comment"># cv: [N,C,H,W] -&gt; [C]</span></span><br><span class="line">batch_norm_op = nn.BatchNorm1d(embedding_dim,affine=<span class="literal">False</span>)</span><br><span class="line">bn_y = batch_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(bn_y)</span><br><span class="line"><span class="comment"># 手写batch_norm</span></span><br><span class="line">bn_mean = input_x.mean(dim=(<span class="number">0</span>,<span class="number">1</span>)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).repeat(batch_size,time_steps,<span class="number">1</span>)</span><br><span class="line">bn_std = input_x.std(dim=(<span class="number">0</span>,<span class="number">1</span>),unbiased=<span class="literal">False</span>).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).repeat(batch_size,time_steps,<span class="number">1</span>)</span><br><span class="line">verify_bn_y = (input_x-bn_mean)/(bn_std + <span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_bn_y)</span><br></pre></td></tr></table></figure><h2 id="layer-normalization-1">2 layer normalization</h2><p>torch.nn.LayerNorm(<em>normalized_shape</em>, <em>eps=1e-05</em>, <em>elementwise_affine=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p><p>https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html?highlight=layer+norm#torch.nn.LayerNorm</p><ul><li>需要保证batchsize是第一个维度，剩下的维度中有embedding_dim即可</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现layer_norm并验证API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [N,L]</span></span><br><span class="line"><span class="comment"># Cv: [N,C,H,W] -&gt; [N,H,W]</span></span><br><span class="line">layer_norm_op = nn.LayerNorm(embedding_dim,elementwise_affine=<span class="literal">False</span>)</span><br><span class="line">ln_y = layer_norm_op(input_x)</span><br><span class="line"><span class="built_in">print</span>(ln_y)</span><br><span class="line"><span class="comment"># shouxie  layer_norm</span></span><br><span class="line">ln_mean = input_x.mean(dim=-<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">ln_std = input_x.std(dim=-<span class="number">1</span>,keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">verify_ln_y = (input_x-ln_mean)/(ln_std + <span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_ln_y)</span><br></pre></td></tr></table></figure><h2 id="instance-normalization">3 Instance Normalization</h2><ul><li>一般用于风格迁移中</li></ul><p>https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html?highlight=instance#torch.nn.InstanceNorm1d</p><p>torch.nn.InstanceNorm1d(<em>num_features</em>, <em>eps=1e-05</em>, <em>momentum=0.1</em>, <em>affine=False</em>, <em>track_running_stats=False</em>, <em>device=None</em>, <em>dtype=None</em>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用instance norm API</span></span><br><span class="line"><span class="comment"># nlp: [N,L,C] -&gt; [N,C]</span></span><br><span class="line"><span class="comment"># Cv: [N,C,H,W] -&gt; [N,C]</span></span><br><span class="line">ins_norm_op = nn.InstanceNorm1d(embedding_dim)</span><br><span class="line">in_y = ins_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(in_y)</span><br><span class="line"><span class="comment"># 手写ins_norm</span></span><br><span class="line">in_mean = input_x.mean(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">in_std = input_x.std(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">verify_ins_y = (input_x-in_mean)/(in_std+<span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_ins_y)</span><br></pre></td></tr></table></figure><ul><li>因为在同一个mini-batch中，如果在序列上对其加权平均，最后得到的也就是序列中的风格信息。</li></ul><h2 id="group-normalization">4 group normalization</h2><p>与layer norm比较相同</p><p>torch.nn.GroupNorm(<em>num_groups</em>, <em>num_channels</em>, <em>eps=1e-05</em>, <em>affine=True</em>, <em>device=None</em>, <em>dtype=None</em>)</p><p>https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html?highlight=group+norm#torch.nn.GroupNorm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用group norm API</span></span><br><span class="line"><span class="comment"># nlp: [N,G,L,C/G] -&gt; [N,G]</span></span><br><span class="line"><span class="comment"># Cv: [N,G,C/G,H,W] -&gt; [N,G]</span></span><br><span class="line">group_norm_op = nn.GroupNorm(num_group,embedding_dim,affine=<span class="literal">False</span>)</span><br><span class="line">gn_y = group_norm_op(input_x.transpose(-<span class="number">1</span>,-<span class="number">2</span>)).transpose(-<span class="number">1</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(gn_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写 group norm</span></span><br><span class="line">group_input_x = torch.split(input_x,split_size_or_sections=embedding_dim//num_group,dim=-<span class="number">1</span>)</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> g_inputx <span class="keyword">in</span> group_input_x:</span><br><span class="line">    gn_mean = g_inputx.mean(dim=(<span class="number">1</span>,<span class="number">2</span>),keepdim=<span class="literal">True</span>)</span><br><span class="line">    gn_std = g_inputx.std(dim=(<span class="number">1</span>,<span class="number">2</span>),keepdim=<span class="literal">True</span>,unbiased=<span class="literal">False</span>)</span><br><span class="line">    gn_result = (g_inputx-gn_mean)/(gn_std+<span class="number">1e-5</span>)</span><br><span class="line">    results.append(gn_result)</span><br><span class="line">verify_gn_y = torch.cat(results,dim=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(verify_gn_y)</span><br></pre></td></tr></table></figure><h2 id="weight-normalization">5 Weight Normalization</h2><p>torch.nn.utils.weight_norm(<em>module</em>, <em>name='weight'</em>, <em>dim=0</em>) https://pytorch.org/docs/stable/_modules/torch/nn/utils/weight_norm.html#weight_norm <span class="math display">\[w = g\frac{v}{||v||}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现weight_norm并验证API</span></span><br><span class="line">linear = nn.Linear(embedding_dim,<span class="number">3</span>,bias=<span class="literal">False</span>) <span class="comment"># without weight norm</span></span><br><span class="line">wn_linear = torch.nn.utils.weight_norm(linear)</span><br><span class="line">wn_linear_output = wn_linear(input_x)</span><br><span class="line"><span class="built_in">print</span>(wn_linear_output)</span><br><span class="line"><span class="keyword">for</span> i,k <span class="keyword">in</span> <span class="built_in">enumerate</span>(wn_linear.named_parameters()):</span><br><span class="line">    <span class="built_in">print</span>(i,k)</span><br><span class="line"><span class="comment"># 手写实现 weight norm</span></span><br><span class="line">weight_direction = linear.weight/(linear.weight.norm(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>))</span><br><span class="line">weight_magnitude = wn_linear.weight_g</span><br><span class="line">verify_wn_linear_output = input_x @ (weight_direction.transpose(-<span class="number">1</span>,-<span class="number">2</span>) * weight_magnitude.transpose(-<span class="number">1</span>,-<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(verify_wn_linear_output)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">feat_dim = <span class="number">3</span></span><br><span class="line">hid_dim = <span class="number">4</span></span><br><span class="line">inputx = torch.randn(batch_size, feat_dim)</span><br><span class="line">linear = nn.Linear(feat_dim, hid_dim, bias=<span class="literal">False</span>)</span><br><span class="line">wn_linear = torch.nn.utils.weight_norm(linear)</span><br><span class="line"></span><br><span class="line">weight_magnitude = torch.tensor([linear.weight[i, :].norm() <span class="keyword">for</span> i <span class="keyword">in</span> torch.arange(linear.weight.shape[<span class="number">0</span>])],</span><br><span class="line">                                dtype=torch.float32).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">weight_direction = linear.weight / weight_magnitude</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.weight:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(linear.weight)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.magnitude:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_magnitude)  <span class="comment"># 幅度向量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear.direction:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_direction)  <span class="comment"># 单位向量，表示方向</span></span><br><span class="line"><span class="built_in">print</span>((weight_direction ** <span class="number">2</span>).<span class="built_in">sum</span>(dim=-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weight_direction*weight_magnitude:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(weight_direction * weight_magnitude)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;inputx @ (weight_direction * weight_magnitude).T:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(inputx @ (weight_direction * weight_magnitude).T)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear(inputx):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(linear(inputx))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;wn_linear(inputx:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wn_linear(inputx))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;parameters of wn_linear:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> n, p <span class="keyword">in</span> wn_linear.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(n, p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;construct weight of linear:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wn_linear.weight_g * (wn_linear.weight_v / torch.tensor(</span><br><span class="line">    [wn_linear.weight_v[i, :].norm() <span class="keyword">for</span> i <span class="keyword">in</span> torch.arange(wn_linear.weight_v.shape[<span class="number">0</span>])],dtype=torch.float32).unsqueeze(-<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;layer-normalization&quot;&gt;Layer Normalization&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.06450.pdf&quot;&gt;1607.06450.pdf (arxiv.org)&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络10-MAE</title>
    <link href="https://wangtongyouwen.github.io/post/f0f056f4.html"/>
    <id>https://wangtongyouwen.github.io/post/f0f056f4.html</id>
    <published>2023-04-19T13:21:04.000Z</published>
    <updated>2023-04-30T06:09:49.154Z</updated>
    
    <content type="html"><![CDATA[<h1 id="masked-autoencoders-are-scalable-vision-learners">Masked Autoencoders Are Scalable Vision Learners</h1><p><a href="https://arxiv.org/pdf/2111.06377.pdf">2111.06377.pdf (arxiv.org)</a></p><p>本文表明，掩蔽自编码器（MAE）是计算机视觉领域可扩展的自监督学习方法。我们的 MAE 方法很简单：我们随机遮盖输入图像的一部分区域，并重建丢失的像素。该方法基于两个核心设计。首先，我们开发了一种非对称的编码器-解码器架构，其中编码器仅对可见子图像区域（没有遮盖标记）进行操作，而轻量级的解码器则从潜在表示和遮盖标记中重建原始图像。其次，我们发现遮盖输入图像较大比例（例如 75%）会产生一个具有意义且难度适中的自监督任务。将这两个设计结合起来，使我们能够高效、有效地训练大型模型：我们加速训练（至少提高 3 倍）并提高准确性。我们的可扩展方法允许学习高容量模型以实现更好的泛化：例如，一个普通的 ViT-Huge 模型在仅使用 ImageNet-1K 数据的方法中达到了最高准确率（87.8%）。在下游任务中，迁移性能超过了有监督预训练，并展示出有希望的扩展行为。</p><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304192127666.png" alt="image-20230419212658615" /><figcaption aria-hidden="true">image-20230419212658615</figcaption></figure><p>image-&gt;patch-&gt;random mask-&gt;shuffle the patch-&gt;encoder-&gt;combine the whole embedding-&gt;unshuffle to align all tokens with target-&gt;decoder</p><p>自编码器是一种可以重构原始信号的方法，它有一个编码器，将观察到的信号映射到潜在表示，以及一个解码器，从潜在表示和掩码标记中重构原始信号。与传统的自编码器不同，我们采用了一种不对称的设计，允许编码器仅对部分观察到的信号（不带掩码标记）进行操作，并使用轻量级解码器从潜在表示和掩码标记中重构完整信号。</p><h2 id="mask">mask</h2><p>其中对于掩码的部分，并不是空向量，而是一个可以学习的向量，可以用过对其学习而恢复完整信号。因为图片中存在大量的冗余信息，所以这个掩码比例通常很高，比如75%</p><p>作者将图像分成规则的非重叠块，然后对其进行采样并遮蔽剩余的块。他们的采样策略很简单：随机采样块，不重复，遵循均匀分布。高遮蔽比率的随机采样大大减少了冗余，从而创造了一个不能通过可见邻近块外推来轻松解决的任务。均匀分布防止了潜在的中心偏差（即图像中心附近有更多的遮蔽块）。最后，高度稀疏的输入为设计高效编码器提供了机会。</p><p>重要的是，不需要任何<strong>专门的稀疏操作</strong>。首先，我们为每个输入图像块生成一个标记（通过线性投影并添加<strong>位置嵌入</strong>）。接下来，我们随机打乱标记列表，并根据遮盖比例删除列表的最后一部分。这个过程为<strong>编码器产生了一个小的标记子集</strong>，相当于在不重复采样的情况下采样图像块。编码后，我们将一列遮盖标记添加到编码后的图像块列表中，并对整个列表进行反打乱操作（反转随机打乱操作）以使所有标记与其目标对齐。解码器应用于这个完整列表（添加位置嵌入）。如前所述，不需要稀疏操作。这种简单的实现引入的开销可忽略不计，因为洗牌和反洗牌操作很快。</p><h2 id="encoder">encoder</h2><p>这个编码器类似ViT的结构，但仅应用于可见的、未遮盖的图像块。与标准的 ViT 一样，我们的编码器通过线性投影和添加位置嵌入对图像块进行嵌入，然后通过一系列 Transformer 模块处理生成的集合。然而，我们的编码器仅在完整集合的一小部分（例如，25%）上进行操作。遮盖的图像块被移除；不使用遮盖标记。这使我们能够仅用一部分计算和内存资源训练非常大的编码器。</p><h2 id="decoder">decoder</h2><p>MAE解码器的输入是完整的标记集合，包括：（i）编码后的可见图像块，以及（ii）遮盖标记。每个遮盖标记是一个共享的、可学习的向量，表示需要预测的缺失图像块的存在。我们为完整集合中的所有标记添加位置嵌入；如果没有这个，遮盖标记将无法获取关于它们在图像中的位置的信息。</p><p>MAE 解码器仅在预训练阶段(回归任务)用于执行图像重建任务（只有编码器用于生成图像表示以进行识别）。因此，解码器架构可以灵活地设计，其设计方式独立于编码器设计。我们尝试使用非常小的解码器，比编码器更窄、更浅。例如，我们默认的解码器每个标记的计算量不到编码器的10%。借助这种非对称设计，完整的标记集合仅由轻量级解码器处理，从而大幅减少预训练时间。</p><ul><li>解码器的目标是完成这个自回归任务，是为了更好的获得存在掩码的编码器，通过编码器才能完成cv的常见任务。</li><li>解码器输出中的每个元素都是代表一个图像块的像素值向量。解码器的最后一层是线性投影，其输出通道数量等于图像块中的像素值数量</li><li>损失函数计算像素空间中重建图像与原始图像之间的均方误差(MSE),仅在遮盖的图像块上计算损失</li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304192302724.png" alt="image-20230419230225444" /><figcaption aria-hidden="true">image-20230419230225444</figcaption></figure><h1 id="code">code</h1><p>https://github.com/facebookresearch/mae</p><h2 id="models_mae">1 models_mae</h2><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201412692.png" alt="image-20230420141204420" /><figcaption aria-hidden="true">image-20230420141204420</figcaption></figure><h3 id="模型搭建">1.1 模型搭建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MaskedAutoencoderViT</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Masked Autoencoder with VisionTransformer backbone</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">1024</span>, depth=<span class="number">24</span>, num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, norm_layer=nn.LayerNorm, norm_pix_loss=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE encoder specifics</span></span><br><span class="line">        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)</span><br><span class="line">        num_patches = self.patch_embed.num_patches</span><br><span class="line"></span><br><span class="line">        self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))</span><br><span class="line">        self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line"></span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line">        self.norm = norm_layer(embed_dim)</span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE decoder specifics</span></span><br><span class="line">        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.mask_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, decoder_embed_dim))</span><br><span class="line"></span><br><span class="line">        self.decoder_pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, decoder_embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line"></span><br><span class="line">        self.decoder_blocks = nn.ModuleList([</span><br><span class="line">            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(decoder_depth)])</span><br><span class="line"></span><br><span class="line">        self.decoder_norm = norm_layer(decoder_embed_dim)</span><br><span class="line">        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**<span class="number">2</span> * in_chans, bias=<span class="literal">True</span>) <span class="comment"># decoder to patch</span></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        self.norm_pix_loss = norm_pix_loss</span><br><span class="line"></span><br><span class="line">        self.initialize_weights()</span><br></pre></td></tr></table></figure><h3 id="embedding的构造">1.2 embedding的构造</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span>, flatten=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])</span><br><span class="line">        self.num_patches = self.grid_size[<span class="number">0</span>] * self.grid_size[<span class="number">1</span>]</span><br><span class="line">        self.flatten = flatten</span><br><span class="line"></span><br><span class="line">        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">assert</span> H == self.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == self.img_size[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        <span class="keyword">if</span> self.flatten:</span><br><span class="line">            x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># BCHW -&gt; BNC</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="初始化参数">1.3 初始化参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># initialization</span></span><br><span class="line">    <span class="comment"># initialize (and freeze) pos_embed by sin-cos embedding</span></span><br><span class="line">    pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-<span class="number">1</span>], <span class="built_in">int</span>(self.patch_embed.num_patches**<span class="number">.5</span>), cls_token=<span class="literal">True</span>)</span><br><span class="line">    self.pos_embed.data.copy_(torch.from_numpy(pos_embed).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    decoder_pos_embed = get_2d_sincos_pos_embed(self.decoder_pos_embed.shape[-<span class="number">1</span>], <span class="built_in">int</span>(self.patch_embed.num_patches**<span class="number">.5</span>), cls_token=<span class="literal">True</span>)</span><br><span class="line">    self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize patch_embed like nn.Linear (instead of nn.Conv2d)</span></span><br><span class="line">    w = self.patch_embed.proj.weight.data</span><br><span class="line">    torch.nn.init.xavier_uniform_(w.view([w.shape[<span class="number">0</span>], -<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># timm&#x27;s trunc_normal_(std=.02) is effectively normal_(std=0.02) as cutoff is too big (2.)</span></span><br><span class="line">    torch.nn.init.normal_(self.cls_token, std=<span class="number">.02</span>)</span><br><span class="line">    torch.nn.init.normal_(self.mask_token, std=<span class="number">.02</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize nn.Linear and nn.LayerNorm</span></span><br><span class="line">    self.apply(self._init_weights)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">        <span class="comment"># we use xavier_uniform following official JAX ViT:</span></span><br><span class="line">        torch.nn.init.xavier_uniform_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">        nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><ul><li>copy?</li></ul><p><code>pos_embed</code> 是一个位置嵌入矩阵，用于捕捉序列中元素的相对或绝对位置信息。在 Transformer 网络中，位置嵌入用于将位置信息与输入嵌入相结合，从而帮助模型处理输入序列。</p><p><code>get_2d_sincos_pos_embed</code> 函数生成了一个基于正弦和余弦函数的二维位置嵌入矩阵。在这种情况下，<code>pos_embed</code> 是一个预先初始化的 PyTorch 张量，而 <code>get_2d_sincos_pos_embed</code> 返回的是一个 NumPy 数组。</p><p><code>copy_()</code> 函数的目的是将 NumPy 数组的值复制到预先分配的 PyTorch 张量中。直接将值赋给 <code>pos_embed</code> 变量会导致以下问题：</p><ol type="1"><li><p>数据类型不匹配：<code>get_2d_sincos_pos_embed</code> 返回的 NumPy 数组可能具有与 PyTorch 张量不同的数据类型。使用 <code>copy_()</code> 函数可以确保在复制过程中自动执行必要的类型转换。在这里，<code>.float().unsqueeze(0)</code> 用于将 NumPy 数组转换为 PyTorch 张量，并确保其具有正确的维度和数据类型。</p></li><li><p>张量的引用问题：直接将值赋给 <code>pos_embed</code> 变量可能会更改原始张量的引用，这可能会导致意外的行为。<code>copy_()</code> 函数确保只有张量的值被修改，而不更改其引用。这对于在模型中保持预期的参数更新行为很重要。</p></li></ol><p>综上所述，使用 <code>copy_()</code> 函数将位置嵌入矩阵的值复制到预先分配的 PyTorch 张量中，可以确保正确处理数据类型转换，并在保持张量引用不变的情况下更新张量的值。</p><h3 id="patch-and-unpatch">1.4 patch and unpatch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">patchify</span>(<span class="params">self, imgs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    imgs: (N, 3, H, W)</span></span><br><span class="line"><span class="string">    x: (N, L, patch_size**2 *3)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    p = self.patch_embed.patch_size[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> imgs.shape[<span class="number">2</span>] == imgs.shape[<span class="number">3</span>] <span class="keyword">and</span> imgs.shape[<span class="number">2</span>] % p == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    h = w = imgs.shape[<span class="number">2</span>] // p</span><br><span class="line">    x = imgs.reshape(shape=(imgs.shape[<span class="number">0</span>], <span class="number">3</span>, h, p, w, p))</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nchpwq-&gt;nhwpqc&#x27;</span>, x)</span><br><span class="line">    x = x.reshape(shape=(imgs.shape[<span class="number">0</span>], h * w, p**<span class="number">2</span> * <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unpatchify</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x: (N, L, patch_size**2 *3)</span></span><br><span class="line"><span class="string">    imgs: (N, 3, H, W)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    p = self.patch_embed.patch_size[<span class="number">0</span>]</span><br><span class="line">    h = w = <span class="built_in">int</span>(x.shape[<span class="number">1</span>]**<span class="number">.5</span>)</span><br><span class="line">    <span class="keyword">assert</span> h * w == x.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    x = x.reshape(shape=(x.shape[<span class="number">0</span>], h, w, p, p, <span class="number">3</span>))</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;nhwpqc-&gt;nchpwq&#x27;</span>, x)</span><br><span class="line">    imgs = x.reshape(shape=(x.shape[<span class="number">0</span>], <span class="number">3</span>, h * p, h * p))</span><br><span class="line">    <span class="keyword">return</span> imgs</span><br></pre></td></tr></table></figure><h3 id="掩码构建">1.5 掩码构建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_masking</span>(<span class="params">self, x, mask_ratio</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Perform per-sample random masking by per-sample shuffling.</span></span><br><span class="line"><span class="string">    Per-sample shuffling is done by argsort random noise.</span></span><br><span class="line"><span class="string">    x: [N, L, D], sequence</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N, L, D = x.shape  <span class="comment"># batch, length, dim</span></span><br><span class="line">    len_keep = <span class="built_in">int</span>(L * (<span class="number">1</span> - mask_ratio))</span><br><span class="line">    </span><br><span class="line">    noise = torch.rand(N, L, device=x.device)  <span class="comment"># noise in [0, 1]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># sort noise for each sample</span></span><br><span class="line">    ids_shuffle = torch.argsort(noise, dim=<span class="number">1</span>)  <span class="comment"># ascend: small is keep, large is remove</span></span><br><span class="line">    ids_restore = torch.argsort(ids_shuffle, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># keep the first subset</span></span><br><span class="line">    ids_keep = ids_shuffle[:, :len_keep]</span><br><span class="line">    x_masked = torch.gather(x, dim=<span class="number">1</span>, index=ids_keep.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, D))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate the binary mask: 0 is keep, 1 is remove</span></span><br><span class="line">    mask = torch.ones([N, L], device=x.device)</span><br><span class="line">    mask[:, :len_keep] = <span class="number">0</span></span><br><span class="line">    <span class="comment"># unshuffle to get the binary mask</span></span><br><span class="line">    mask = torch.gather(mask, dim=<span class="number">1</span>, index=ids_restore)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x_masked, mask, ids_restore</span><br></pre></td></tr></table></figure><h3 id="encoder-forward">1.6 encoder forward</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_encoder</span>(<span class="params">self, x, mask_ratio</span>):</span><br><span class="line">    <span class="comment"># embed patches</span></span><br><span class="line">    x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add pos embed w/o cls token</span></span><br><span class="line">    x = x + self.pos_embed[:, <span class="number">1</span>:, :]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># masking: length -&gt; length * mask_ratio</span></span><br><span class="line">    x, mask, ids_restore = self.random_masking(x, mask_ratio)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># append cls token</span></span><br><span class="line">    cls_token = self.cls_token + self.pos_embed[:, :<span class="number">1</span>, :]  <span class="comment"># 第0个位置</span></span><br><span class="line">    cls_tokens = cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply Transformer blocks</span></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line">    x = self.norm(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x, mask, ids_restore</span><br></pre></td></tr></table></figure><h3 id="decoder-forward">1.7 decoder forward</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_decoder</span>(<span class="params">self, x, ids_restore</span>):</span><br><span class="line">    <span class="comment"># embed tokens</span></span><br><span class="line">    x = self.decoder_embed(x) <span class="comment"># 降维</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># append mask tokens to sequence</span></span><br><span class="line">    mask_tokens = self.mask_token.repeat(x.shape[<span class="number">0</span>], ids_restore.shape[<span class="number">1</span>] + <span class="number">1</span> - x.shape[<span class="number">1</span>], <span class="number">1</span>) <span class="comment"># repeat in batchsize</span></span><br><span class="line">    x_ = torch.cat([x[:, <span class="number">1</span>:, :], mask_tokens], dim=<span class="number">1</span>)  <span class="comment"># no cls token</span></span><br><span class="line">    x_ = torch.gather(x_, dim=<span class="number">1</span>, index=ids_restore.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, x.shape[<span class="number">2</span>]))  <span class="comment"># unshuffle</span></span><br><span class="line">    x = torch.cat([x[:, :<span class="number">1</span>, :], x_], dim=<span class="number">1</span>)  <span class="comment"># append cls token</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add pos embed</span></span><br><span class="line">    x = x + self.decoder_pos_embed</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply Transformer blocks</span></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.decoder_blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line">    x = self.decoder_norm(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predictor projection</span></span><br><span class="line">    x = self.decoder_pred(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove cls token</span></span><br><span class="line">    x = x[:, <span class="number">1</span>:, :]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="loss-forward">1.8 loss forward</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_loss</span>(<span class="params">self, imgs, pred, mask</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    imgs: [N, 3, H, W]</span></span><br><span class="line"><span class="string">    pred: [N, L, p*p*3]</span></span><br><span class="line"><span class="string">    mask: [N, L], 0 is keep, 1 is remove, </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    target = self.patchify(imgs)  <span class="comment"># N, L, patch_size**2 *3</span></span><br><span class="line">    <span class="keyword">if</span> self.norm_pix_loss:</span><br><span class="line">        mean = target.mean(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        var = target.var(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        target = (target - mean) / (var + <span class="number">1.e-6</span>)**<span class="number">.5</span> <span class="comment"># 防止方差为0</span></span><br><span class="line"></span><br><span class="line">    loss = (pred - target) ** <span class="number">2</span></span><br><span class="line">    loss = loss.mean(dim=-<span class="number">1</span>)  <span class="comment"># [N, L], mean loss per patch</span></span><br><span class="line"></span><br><span class="line">    loss = (loss * mask).<span class="built_in">sum</span>() / mask.<span class="built_in">sum</span>()  <span class="comment"># mean loss on removed patches</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="different-models">1.9 different models</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_base_patch16_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">16</span>, embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_large_patch16_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">16</span>, embed_dim=<span class="number">1024</span>, depth=<span class="number">24</span>, num_heads=<span class="number">16</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mae_vit_huge_patch14_dec512d8b</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    model = MaskedAutoencoderViT(</span><br><span class="line">        patch_size=<span class="number">14</span>, embed_dim=<span class="number">1280</span>, depth=<span class="number">32</span>, num_heads=<span class="number">16</span>,</span><br><span class="line">        decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span><br><span class="line">        mlp_ratio=<span class="number">4</span>, norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mae_vit_base_patch16 = mae_vit_base_patch16_dec512d8b  # decoder: 512 dim, 8 blocks</span><br><span class="line">mae_vit_large_patch16 = mae_vit_large_patch16_dec512d8b  # decoder: 512 dim, 8 blocks</span><br><span class="line">mae_vit_huge_patch14 = mae_vit_huge_patch14_dec512d8b  # decoder: 512 dim, 8 blocks</span><br></pre></td></tr></table></figure><h2 id="main_pretrain">2 main_pretrain</h2><figure><img src="C:\Users\jyh\AppData\Roaming\Typora\typora-user-images\image-20230420154128379.png" alt="image-20230420154128379" /><figcaption aria-hidden="true">image-20230420154128379</figcaption></figure><h3 id="设置参数的入口">2.1 设置参数的入口</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args = get_args_parser()</span><br><span class="line">    args = args.parse_args()</span><br><span class="line">    <span class="keyword">if</span> args.output_dir:</span><br><span class="line">        Path(args.output_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure><h3 id="main">2.2 main</h3><p>略。这个函数能够实现单机单卡，多机多卡，单机多卡，cpu等模式，通用性很强</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--accum_iter&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Accumulate gradient iterations (for increasing the effective batch size under memory constraints)&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>此内容可以用在低GPU内存，但是想要训练大batchsize的网络上(时间换空间)</li></ul><h3 id="misc.init_distributed_mode">2.3 misc.init_distributed_mode</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_distributed_mode</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="keyword">if</span> args.dist_on_itp:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_RANK&#x27;</span>])</span><br><span class="line">        args.world_size = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_SIZE&#x27;</span>])</span><br><span class="line">        args.gpu = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_LOCAL_RANK&#x27;</span>])</span><br><span class="line">        args.dist_url = <span class="string">&quot;tcp://%s:%s&quot;</span> % (os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>], os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>])</span><br><span class="line">        os.environ[<span class="string">&#x27;LOCAL_RANK&#x27;</span>] = <span class="built_in">str</span>(args.gpu)</span><br><span class="line">        os.environ[<span class="string">&#x27;RANK&#x27;</span>] = <span class="built_in">str</span>(args.rank)</span><br><span class="line">        os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>] = <span class="built_in">str</span>(args.world_size)</span><br><span class="line">        <span class="comment"># [&quot;RANK&quot;, &quot;WORLD_SIZE&quot;, &quot;MASTER_ADDR&quot;, &quot;MASTER_PORT&quot;, &quot;LOCAL_RANK&quot;]</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;RANK&#x27;</span> <span class="keyword">in</span> os.environ <span class="keyword">and</span> <span class="string">&#x27;WORLD_SIZE&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&quot;RANK&quot;</span>])</span><br><span class="line">        args.world_size = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>])</span><br><span class="line">        args.gpu = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;LOCAL_RANK&#x27;</span>])</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;SLURM_PROCID&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">        args.rank = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;SLURM_PROCID&#x27;</span>])</span><br><span class="line">        args.gpu = args.rank % torch.cuda.device_count()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Not using distributed mode&#x27;</span>)</span><br><span class="line">        setup_for_distributed(is_master=<span class="literal">True</span>)  <span class="comment"># hack</span></span><br><span class="line">        args.distributed = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    args.distributed = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    torch.cuda.set_device(args.gpu)</span><br><span class="line">    args.dist_backend = <span class="string">&#x27;nccl&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;| distributed init (rank &#123;&#125;): &#123;&#125;, gpu &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        args.rank, args.dist_url, args.gpu), flush=<span class="literal">True</span>)</span><br><span class="line">    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,</span><br><span class="line">                                         world_size=args.world_size, rank=args.rank)</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">    setup_for_distributed(args.rank == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="prepare">2.4 prepare</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">misc.init_distributed_mode(args)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;job dir: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.path.dirname(os.path.realpath(__file__))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(args).replace(<span class="string">&#x27;, &#x27;</span>, <span class="string">&#x27;,\n&#x27;</span>))</span><br><span class="line"></span><br><span class="line">device = torch.device(args.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fix the seed for reproducibility</span></span><br><span class="line">seed = args.seed + misc.get_rank()</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line"></span><br><span class="line">cudnn.benchmark = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h3 id="simple-augmentation">2.5 simple augmentation</h3><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201555531.png" alt="image-20230420155514559" /><figcaption aria-hidden="true">image-20230420155514559</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># simple augmentation</span></span><br><span class="line">transform_train = transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(args.input_size, scale=(<span class="number">0.2</span>, <span class="number">1.0</span>), interpolation=<span class="number">3</span>),  <span class="comment"># 3 is bicubic</span></span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(), <span class="comment"># unint8-&gt;float</span></span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line">dataset_train = datasets.ImageFolder(os.path.join(args.data_path, <span class="string">&#x27;train&#x27;</span>), transform=transform_train)</span><br><span class="line"><span class="built_in">print</span>(dataset_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_train, sampler=sampler_train,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="define-model">2.6 define model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">model = models_mae.__dict__[args.model](norm_pix_loss=args.norm_pix_loss)</span><br><span class="line"></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">model_without_ddp = model</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model = %s&quot;</span> % <span class="built_in">str</span>(model_without_ddp))</span><br><span class="line"></span><br><span class="line">eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.lr <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># only base_lr is specified</span></span><br><span class="line">    args.lr = args.blr * eff_batch_size / <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;base lr: %.2e&quot;</span> % (args.lr * <span class="number">256</span> / eff_batch_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;actual lr: %.2e&quot;</span> % args.lr)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accumulate grad iterations: %d&quot;</span> % args.accum_iter)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;effective batch size: %d&quot;</span> % eff_batch_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=<span class="literal">True</span>)</span><br><span class="line">    model_without_ddp = model.module</span><br><span class="line">    </span><br><span class="line">misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)</span><br></pre></td></tr></table></figure><h3 id="optimizer">2.7 optimizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># following timm: set wd as 0 for bias and norm layers</span></span><br><span class="line">param_groups = optim_factory.add_weight_decay(model_without_ddp, args.weight_decay)</span><br><span class="line">optimizer = torch.optim.AdamW(param_groups, lr=args.lr, betas=(<span class="number">0.9</span>, <span class="number">0.95</span>))</span><br><span class="line"><span class="built_in">print</span>(optimizer)</span><br><span class="line">loss_scaler = NativeScaler()</span><br></pre></td></tr></table></figure><h3 id="train">2.8 train</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Start training for <span class="subst">&#123;args.epochs&#125;</span> epochs&quot;</span>)</span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line">    <span class="keyword">if</span> args.distributed:</span><br><span class="line">        data_loader_train.sampler.set_epoch(epoch)</span><br><span class="line">    train_stats = train_one_epoch(</span><br><span class="line">        model, data_loader_train,</span><br><span class="line">        optimizer, device, epoch, loss_scaler,</span><br><span class="line">        log_writer=log_writer,</span><br><span class="line">        args=args</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> (epoch % <span class="number">20</span> == <span class="number">0</span> <span class="keyword">or</span> epoch + <span class="number">1</span> == args.epochs):</span><br><span class="line">        misc.save_model(</span><br><span class="line">            args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,</span><br><span class="line">            loss_scaler=loss_scaler, epoch=epoch)</span><br><span class="line"></span><br><span class="line">    log_stats = &#123;**&#123;<span class="string">f&#x27;train_<span class="subst">&#123;k&#125;</span>&#x27;</span>: v <span class="keyword">for</span> k, v <span class="keyword">in</span> train_stats.items()&#125;,</span><br><span class="line">                    <span class="string">&#x27;epoch&#x27;</span>: epoch,&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> misc.is_main_process():</span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            log_writer.flush()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.output_dir, <span class="string">&quot;log.txt&quot;</span>), mode=<span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(log_stats) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">total_time = time.time() - start_time</span><br><span class="line">total_time_str = <span class="built_in">str</span>(datetime.timedelta(seconds=<span class="built_in">int</span>(total_time)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training time &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(total_time_str))</span><br></pre></td></tr></table></figure><p>其中核心代码，单个epoch的训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model: torch.nn.Module,</span></span><br><span class="line"><span class="params">                    data_loader: Iterable, optimizer: torch.optim.Optimizer,</span></span><br><span class="line"><span class="params">                    device: torch.device, epoch: <span class="built_in">int</span>, loss_scaler,</span></span><br><span class="line"><span class="params">                    log_writer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                    args=<span class="literal">None</span></span>):</span><br><span class="line">    model.train(<span class="literal">True</span>)</span><br><span class="line">    metric_logger = misc.MetricLogger(delimiter=<span class="string">&quot;  &quot;</span>)</span><br><span class="line">    metric_logger.add_meter(<span class="string">&#x27;lr&#x27;</span>, misc.SmoothedValue(window_size=<span class="number">1</span>, fmt=<span class="string">&#x27;&#123;value:.6f&#125;&#x27;</span>))</span><br><span class="line">    header = <span class="string">&#x27;Epoch: [&#123;&#125;]&#x27;</span>.<span class="built_in">format</span>(epoch)</span><br><span class="line">    print_freq = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    accum_iter = args.accum_iter</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;log_dir: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(log_writer.log_dir))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_iter_step, (samples, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(metric_logger.log_every(data_loader, print_freq, header)):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># we use a per iteration (instead of per epoch) lr scheduler</span></span><br><span class="line">        <span class="keyword">if</span> data_iter_step % accum_iter == <span class="number">0</span>:</span><br><span class="line">            lr_sched.adjust_learning_rate(optimizer, data_iter_step / <span class="built_in">len</span>(data_loader) + epoch, args)</span><br><span class="line"></span><br><span class="line">        samples = samples.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.amp.autocast(): <span class="comment"># 自动混合精度</span></span><br><span class="line">            loss, _, _ = model(samples, mask_ratio=args.mask_ratio)</span><br><span class="line"></span><br><span class="line">        loss_value = loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> math.isfinite(loss_value):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Loss is &#123;&#125;, stopping training&quot;</span>.<span class="built_in">format</span>(loss_value))</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        loss /= accum_iter</span><br><span class="line">        loss_scaler(loss, optimizer, parameters=model.parameters(),</span><br><span class="line">                    update_grad=(data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        torch.cuda.synchronize()</span><br><span class="line"></span><br><span class="line">        metric_logger.update(loss=loss_value)</span><br><span class="line"></span><br><span class="line">        lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]</span><br><span class="line">        metric_logger.update(lr=lr)</span><br><span class="line"></span><br><span class="line">        loss_value_reduce = misc.all_reduce_mean(loss_value)</span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot; We use epoch_1000x as the x-axis in tensorboard.</span></span><br><span class="line"><span class="string">            This calibrates different curves when batch size changes.</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            epoch_1000x = <span class="built_in">int</span>((data_iter_step / <span class="built_in">len</span>(data_loader) + epoch) * <span class="number">1000</span>)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, loss_value_reduce, epoch_1000x)</span><br><span class="line">            log_writer.add_scalar(<span class="string">&#x27;lr&#x27;</span>, lr, epoch_1000x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># gather the stats from all processes</span></span><br><span class="line">    metric_logger.synchronize_between_processes()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Averaged stats:&quot;</span>, metric_logger)</span><br><span class="line">    <span class="keyword">return</span> &#123;k: meter.global_avg <span class="keyword">for</span> k, meter <span class="keyword">in</span> metric_logger.meters.items()&#125;</span><br></pre></td></tr></table></figure><ul><li><p>如果因为timm报错，需要把 qk_scale=None注释掉</p></li><li><p>如果需要多卡训练 python -m torch.distributed.launch --nproc_per_node=2 main_prerain.py --batchsize=32 --world_size=2 --data_path="..."</p></li><li><p>dataset的目录结构</p></li></ul><p>/path/to/imagenet-1k/： train/ class1/ img1.jpeg class2/ img2.jpeg val/ class1/ img3.jpeg class2/ img4.jpeg</p><h2 id="main_fintune">3 main_fintune</h2><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201725532.png" alt="image-20230420172505860" /><figcaption aria-hidden="true">image-20230420172505860</figcaption></figure><p>大体和main_pretrain相同，这个是对编码器进行微调，微调的目的是为了更好的完成下游任务</p><h3 id="datasetnew">3.1 dataset(new)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">is_train, args</span>):</span><br><span class="line">    transform = build_transform(is_train, args)</span><br><span class="line"></span><br><span class="line">    root = os.path.join(args.data_path, <span class="string">&#x27;train&#x27;</span> <span class="keyword">if</span> is_train <span class="keyword">else</span> <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">    dataset = datasets.ImageFolder(root, transform=transform)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_transform</span>(<span class="params">is_train, args</span>):</span><br><span class="line">    mean = IMAGENET_DEFAULT_MEAN</span><br><span class="line">    std = IMAGENET_DEFAULT_STD</span><br><span class="line">    <span class="comment"># train transform</span></span><br><span class="line">    <span class="comment"># 强增广</span></span><br><span class="line">    <span class="keyword">if</span> is_train:</span><br><span class="line">        <span class="comment"># this should always dispatch to transforms_imagenet_train</span></span><br><span class="line">        transform = create_transform(</span><br><span class="line">            input_size=args.input_size,</span><br><span class="line">            is_training=<span class="literal">True</span>,</span><br><span class="line">            color_jitter=args.color_jitter,</span><br><span class="line">            auto_augment=args.aa,</span><br><span class="line">            interpolation=<span class="string">&#x27;bicubic&#x27;</span>,</span><br><span class="line">            re_prob=args.reprob,</span><br><span class="line">            re_mode=args.remode,</span><br><span class="line">            re_count=args.recount,</span><br><span class="line">            mean=mean,</span><br><span class="line">            std=std,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> transform</span><br><span class="line"></span><br><span class="line">    <span class="comment"># eval transform</span></span><br><span class="line">    <span class="comment"># 基本没有增广</span></span><br><span class="line">    t = []</span><br><span class="line">    <span class="keyword">if</span> args.input_size &lt;= <span class="number">224</span>:</span><br><span class="line">        crop_pct = <span class="number">224</span> / <span class="number">256</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        crop_pct = <span class="number">1.0</span></span><br><span class="line">    size = <span class="built_in">int</span>(args.input_size / crop_pct)</span><br><span class="line">    t.append(</span><br><span class="line">        transforms.Resize(size, interpolation=PIL.Image.BICUBIC),  <span class="comment"># to maintain same ratio w.r.t. 224 images</span></span><br><span class="line">    )</span><br><span class="line">    t.append(transforms.CenterCrop(args.input_size))</span><br><span class="line"></span><br><span class="line">    t.append(transforms.ToTensor())</span><br><span class="line">    t.append(transforms.Normalize(mean, std))</span><br><span class="line">    <span class="keyword">return</span> transforms.Compose(t)</span><br></pre></td></tr></table></figure><h3 id="dataloader">3.2 dataloader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_train, sampler=sampler_train,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">data_loader_val = torch.utils.data.DataLoader(</span><br><span class="line">    dataset_val, sampler=sampler_val,</span><br><span class="line">    batch_size=args.batch_size,</span><br><span class="line">    num_workers=args.num_workers,</span><br><span class="line">    pin_memory=args.pin_mem,</span><br><span class="line">    drop_last=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="mixup增广">3.3 mixup增广</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mixup_fn = <span class="literal">None</span></span><br><span class="line">mixup_active = args.mixup &gt; <span class="number">0</span> <span class="keyword">or</span> args.cutmix &gt; <span class="number">0.</span> <span class="keyword">or</span> args.cutmix_minmax <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> mixup_active:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Mixup is activated!&quot;</span>)</span><br><span class="line">    mixup_fn = Mixup(</span><br><span class="line">        mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,</span><br><span class="line">        prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,</span><br><span class="line">        label_smoothing=args.smoothing, num_classes=args.nb_classes)</span><br></pre></td></tr></table></figure><h3 id="model定义">3.4 model定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = models_vit.__dict__[args.model](</span><br><span class="line">    num_classes=args.nb_classes,</span><br><span class="line">    drop_path_rate=args.drop_path,</span><br><span class="line">    global_pool=args.global_pool,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(timm.models.vision_transformer.VisionTransformer):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Vision Transformer with support for global average pooling</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, global_pool=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">        self.global_pool = global_pool</span><br><span class="line">        <span class="keyword">if</span> self.global_pool:</span><br><span class="line">            norm_layer = kwargs[<span class="string">&#x27;norm_layer&#x27;</span>]</span><br><span class="line">            embed_dim = kwargs[<span class="string">&#x27;embed_dim&#x27;</span>]</span><br><span class="line">            self.fc_norm = norm_layer(embed_dim)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">del</span> self.norm  <span class="comment"># remove the original norm</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">        cls_tokens = self.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># stole cls_tokens impl from Phil Wang, thanks</span></span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        x = x + self.pos_embed</span><br><span class="line">        x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.global_pool:</span><br><span class="line">            x = x[:, <span class="number">1</span>:, :].mean(dim=<span class="number">1</span>)  <span class="comment"># global pool without cls token</span></span><br><span class="line">            outcome = self.fc_norm(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x = self.norm(x)</span><br><span class="line">            outcome = x[:, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outcome</span><br></pre></td></tr></table></figure><h3 id="预训练权重的导入">3.5 预训练权重的导入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.finetune <span class="keyword">and</span> <span class="keyword">not</span> args.<span class="built_in">eval</span>:</span><br><span class="line">    checkpoint = torch.load(args.finetune, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Load pre-trained checkpoint from: %s&quot;</span> % args.finetune)</span><br><span class="line">    checkpoint_model = checkpoint[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">    state_dict = model.state_dict()</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">in</span> checkpoint_model <span class="keyword">and</span> checkpoint_model[k].shape != state_dict[k].shape:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Removing key <span class="subst">&#123;k&#125;</span> from pretrained checkpoint&quot;</span>)</span><br><span class="line">            <span class="keyword">del</span> checkpoint_model[k]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># interpolate position embedding</span></span><br><span class="line">    interpolate_pos_embed(model, checkpoint_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load pre-trained model</span></span><br><span class="line">    msg = model.load_state_dict(checkpoint_model, strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(msg)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.global_pool:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>, <span class="string">&#x27;fc_norm.weight&#x27;</span>, <span class="string">&#x27;fc_norm.bias&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># manually initialize fc layer</span></span><br><span class="line">    trunc_normal_(model.head.weight, std=<span class="number">2e-5</span>)</span><br></pre></td></tr></table></figure><ul><li>确保head部分的权重没有导入</li><li>线性插值：让微调阶段的position embedding仍然适用(如果模型变大)</li></ul><h2 id="linear-probing">4 linear probing</h2><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304201725555.png" alt="image-20230420172530538" /><figcaption aria-hidden="true">image-20230420172530538</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for linear prob only</span></span><br><span class="line"><span class="comment"># hack: revise model&#x27;s head with BN</span></span><br><span class="line">model.head = torch.nn.Sequential(torch.nn.BatchNorm1d(model.head.in_features, affine=<span class="literal">False</span>, eps=<span class="number">1e-6</span>), model.head)</span><br><span class="line"><span class="comment"># freeze all but the head</span></span><br><span class="line"><span class="keyword">for</span> _, p <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    p.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> _, p <span class="keyword">in</span> model.head.named_parameters():</span><br><span class="line">    p.requires_grad = <span class="literal">True</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;masked-autoencoders-are-scalable-vision-learners&quot;&gt;Masked Autoencoders Are Scalable Vision Learners&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.o</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络9-ResNet</title>
    <link href="https://wangtongyouwen.github.io/post/1c753934.html"/>
    <id>https://wangtongyouwen.github.io/post/1c753934.html</id>
    <published>2023-04-19T11:24:03.000Z</published>
    <updated>2023-05-05T12:01:19.996Z</updated>
    
    <content type="html"><![CDATA[<p>https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf</p><h1 id="使用timm复现resnet">使用timm复现ResNet</h1><p>论文内容略，本文采用的python+pytorch 环境为:</p><p>torch 1.13.1+cu117</p><p>python 3.7</p><p>timm 0.4.12</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm</span><br><span class="line">timm.create_model(<span class="string">&quot;resnet50&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br></pre></td><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (act1): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer2): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (3): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer3): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (3): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (4): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (5): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer4): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">    (2): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act1): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act2): ReLU(inplace=True)</span><br><span class="line">      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (act3): ReLU(inplace=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)</span><br><span class="line">  (fc): Linear(in_features=2048, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>lib/site-packages/timm/models/resnet.py</p><h2 id="resnet">1 ResNet</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stem</span></span><br><span class="line">self.conv1 = nn.Conv2d(in_chans, inplanes, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = norm_layer(inplanes)</span><br><span class="line">self.act1 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">self.feature_info = [<span class="built_in">dict</span>(num_chs=inplanes, reduction=<span class="number">2</span>, module=<span class="string">&#x27;act1&#x27;</span>)]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Stem Pooling</span></span><br><span class="line"><span class="keyword">if</span> aa_layer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">self.maxpool = nn.Sequential(*[</span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">aa_layer(channels=inplanes, stride=<span class="number">2</span>)])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>核心部分：feature map</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Feature Blocks</span></span><br><span class="line">channels = [<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">stage_modules, stage_feature_info = make_blocks(</span><br><span class="line">block, channels, layers, inplanes, cardinality=cardinality, base_width=base_width,</span><br><span class="line">output_stride=output_stride, reduce_first=block_reduce_first, avg_down=avg_down,</span><br><span class="line">down_kernel_size=down_kernel_size, act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer,</span><br><span class="line">drop_block_rate=drop_block_rate, drop_path_rate=drop_path_rate, **block_args)</span><br><span class="line"><span class="keyword">for</span> stage <span class="keyword">in</span> stage_modules:</span><br><span class="line">self.add_module(*stage)  <span class="comment"># layer1, layer2, etc</span></span><br><span class="line">self.feature_info.extend(stage_feature_info)</span><br></pre></td></tr></table></figure><p>其中make_blocks是构建每个stage的具体实现，这里具体内容在第二部分查看</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.num_features = <span class="number">512</span> * block.expansion</span><br><span class="line">self.global_pool, self.fc = create_classifier(self.num_features, self.num_classes, pool_type=global_pool)</span><br></pre></td></tr></table></figure><p>为什么这里有block.expansion?</p><p>在ResNet50中有些stage之间的通道数是不相同的，如果直接使用残差连接，无法完成直接相加，需要对某些深度通道进行压缩，expansion能够保证某些通道的输出维度是匹配的</p><h2 id="make_blocks">2 make_blocks</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_blocks</span>(<span class="params"></span></span><br><span class="line"><span class="params">        block_fn, channels, block_repeats, inplanes, reduce_first=<span class="number">1</span>, output_stride=<span class="number">32</span>,</span></span><br><span class="line"><span class="params">        down_kernel_size=<span class="number">1</span>, avg_down=<span class="literal">False</span>, drop_block_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.</span>, **kwargs</span>):</span><br><span class="line">    stages = []</span><br><span class="line">    feature_info = []</span><br><span class="line">    net_num_blocks = <span class="built_in">sum</span>(block_repeats)</span><br><span class="line">    net_block_idx = <span class="number">0</span></span><br><span class="line">    net_stride = <span class="number">4</span></span><br><span class="line">    dilation = prev_dilation = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> stage_idx, (planes, num_blocks, db) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(channels, block_repeats, drop_blocks(drop_block_rate))):</span><br><span class="line">        stage_name = <span class="string">f&#x27;layer<span class="subst">&#123;stage_idx + <span class="number">1</span>&#125;</span>&#x27;</span>  <span class="comment"># never liked this name, but weight compat requires it</span></span><br><span class="line">        stride = <span class="number">1</span> <span class="keyword">if</span> stage_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> net_stride &gt;= output_stride:</span><br><span class="line">            dilation *= stride</span><br><span class="line">            stride = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            net_stride *= stride</span><br><span class="line"></span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> inplanes != planes * block_fn.expansion:</span><br><span class="line">            down_kwargs = <span class="built_in">dict</span>(</span><br><span class="line">                in_channels=inplanes, out_channels=planes * block_fn.expansion, kernel_size=down_kernel_size,</span><br><span class="line">                stride=stride, dilation=dilation, first_dilation=prev_dilation, norm_layer=kwargs.get(<span class="string">&#x27;norm_layer&#x27;</span>))</span><br><span class="line">            downsample = downsample_avg(**down_kwargs) <span class="keyword">if</span> avg_down <span class="keyword">else</span> downsample_conv(**down_kwargs)</span><br><span class="line"></span><br><span class="line">        block_kwargs = <span class="built_in">dict</span>(reduce_first=reduce_first, dilation=dilation, drop_block=db, **kwargs)</span><br><span class="line">        blocks = []</span><br><span class="line">        <span class="keyword">for</span> block_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            downsample = downsample <span class="keyword">if</span> block_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            stride = stride <span class="keyword">if</span> block_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">            block_dpr = drop_path_rate * net_block_idx / (net_num_blocks - <span class="number">1</span>)  <span class="comment"># stochastic depth linear decay rule</span></span><br><span class="line">            blocks.append(block_fn(</span><br><span class="line">                inplanes, planes, stride, downsample, first_dilation=prev_dilation,</span><br><span class="line">                drop_path=DropPath(block_dpr) <span class="keyword">if</span> block_dpr &gt; <span class="number">0.</span> <span class="keyword">else</span> <span class="literal">None</span>, **block_kwargs))</span><br><span class="line">            prev_dilation = dilation</span><br><span class="line">            inplanes = planes * block_fn.expansion</span><br><span class="line">            net_block_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        stages.append((stage_name, nn.Sequential(*blocks)))</span><br><span class="line">        feature_info.append(<span class="built_in">dict</span>(num_chs=inplanes, reduction=net_stride, module=stage_name))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stages, feature_info</span><br></pre></td></tr></table></figure><p>这段代码定义了一个名为<code>make_blocks</code>的函数，用于构建一系列残差块（residual blocks）并形成卷积神经网络（CNN）的多个阶段。这种结构在 ResNet 及其变体中很常见。<code>make_blocks</code>函数接收多个参数，用于控制网络的结构和行为。函数的主要目的是根据给定的参数创建网络的各个阶段并返回这些阶段及其相关的特征信息。</p><p>以下是函数参数的简要说明：</p><ul><li><code>block_fn</code>：残差块的函数，如 ResNet 中的基本块或瓶颈块。</li><li><code>channels</code>：每个阶段的输出通道数量。</li><li><code>block_repeats</code>：每个阶段的残差块重复次数。</li><li><code>inplanes</code>：输入通道数量。</li><li>其他参数用于控制步长（<code>output_stride</code>）、下采样方式（<code>avg_down</code>）、DropBlock（<code>drop_block_rate</code>）和 Stochastic Depth（<code>drop_path_rate</code>）等高级功能。</li></ul><p>代码的主要部分是一个循环，针对每个阶段执行以下操作：</p><ol type="1"><li>为每个阶段创建一个名为<code>stage_name</code>的变量，如<code>layer1</code>、<code>layer2</code>等。</li><li>计算步长（<code>stride</code>）和扩张率（<code>dilation</code>），这些值控制每个阶段的空间分辨率。</li><li>如果需要，创建下采样层（<code>downsample</code>），以使输入与输出具有兼容的尺寸。</li><li>根据给定的参数，创建一系列残差块。</li><li>将这些残差块组合成一个名为<code>nn.Sequential</code>的模块，将其添加到<code>stages</code>列表中。</li><li>将每个阶段的特征信息添加到<code>feature_info</code>列表中。</li></ol><p>最后，函数返回<code>stages</code>和<code>feature_info</code>，它们分别表示网络的各个阶段及其相关的特征信息。这些信息通常在之后的代码中用于构建完整的神经网络，并在训练过程中用于损失计算和评估等任务。</p><ul><li>downsample和block.expansion之间的联系：</li></ul><p><code>downsample</code> 和 <code>block.expansion</code> 在这段代码中具有不同的目的，但它们之间存在联系。首先，让我们解释它们各自的作用：</p><ol type="1"><li><code>downsample</code>：<code>downsample</code> 是一个可选的下采样层，用于在输入和输出之间调整维度。在构建残差网络时，<code>downsample</code> 的目的是使跳过连接（skip connection）中的输入与残差块输出具有相同的尺寸，以便将它们相加。<code>downsample</code> 层通常包含一个卷积层和一个批量归一化层，用于调整输入的通道数量和/或分辨率。这样，即使输入和输出具有不同的尺寸，也可以将它们相加。</li><li><code>block.expansion</code>：<code>block.expansion</code> 是残差块中的扩张因子，用于控制输入和输出通道的增长。在 ResNet 架构中，基本块的扩张因子为 1（即输入和输出通道数量相同），而瓶颈块的扩张因子为 4（即输出通道数量为输入通道数量的 4 倍）。</li></ol><p>这两者之间的联系是：<code>downsample</code> 层用于调整输入的通道数量，使其与残差块输出的通道数量匹配。而<code>block.expansion</code> 则决定了残差块输出的通道数量。因此，在计算下采样层时，通常会将输出通道数量设置为 <code>planes * block_fn.expansion</code>，其中 <code>planes</code> 是当前阶段的输出通道数量，<code>block_fn.expansion</code> 是残差块的扩张因子。</p><p>简而言之，<code>downsample</code> 和 <code>block.expansion</code> 分别负责调整输入尺寸以匹配输出尺寸，以及控制残差块中输入和输出通道的增长。尽管它们具有不同的目的，但它们之间存在联系，共同影响网络的整体结构。</p><h2 id="basicblock">3 BasicBlock</h2><p>这个类就是对ResNet进行的一个实现，这个网络中的block大小都是相同的，所以没有用到上述的downsample和block.expansion</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, cardinality=<span class="number">1</span>, base_width=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 reduce_first=<span class="number">1</span>, dilation=<span class="number">1</span>, first_dilation=<span class="literal">None</span>, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,</span></span><br><span class="line"><span class="params">                 attn_layer=<span class="literal">None</span>, aa_layer=<span class="literal">None</span>, drop_block=<span class="literal">None</span>, drop_path=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> cardinality == <span class="number">1</span>, <span class="string">&#x27;BasicBlock only supports cardinality of 1&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> base_width == <span class="number">64</span>, <span class="string">&#x27;BasicBlock does not support changing base width&#x27;</span></span><br><span class="line">        first_planes = planes // reduce_first</span><br><span class="line">        outplanes = planes * self.expansion</span><br><span class="line">        first_dilation = first_dilation <span class="keyword">or</span> dilation</span><br><span class="line">        use_aa = aa_layer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (stride == <span class="number">2</span> <span class="keyword">or</span> first_dilation != dilation)</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(</span><br><span class="line">            inplanes, first_planes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span> <span class="keyword">if</span> use_aa <span class="keyword">else</span> stride, padding=first_dilation,</span><br><span class="line">            dilation=first_dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = norm_layer(first_planes)</span><br><span class="line">        self.act1 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.aa = aa_layer(channels=first_planes, stride=stride) <span class="keyword">if</span> use_aa <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(</span><br><span class="line">            first_planes, outplanes, kernel_size=<span class="number">3</span>, padding=dilation, dilation=dilation, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = norm_layer(outplanes)</span><br><span class="line"></span><br><span class="line">        self.se = create_attn(attn_layer, outplanes)</span><br><span class="line"></span><br><span class="line">        self.act2 = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.dilation = dilation</span><br><span class="line">        self.drop_block = drop_block</span><br><span class="line">        self.drop_path = drop_path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">zero_init_last_bn</span>(<span class="params">self</span>):</span><br><span class="line">        nn.init.zeros_(self.bn2.weight)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        shortcut = x</span><br><span class="line"></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        <span class="keyword">if</span> self.drop_block <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_block(x)</span><br><span class="line">        x = self.act1(x)</span><br><span class="line">        <span class="keyword">if</span> self.aa <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.aa(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.bn2(x)</span><br><span class="line">        <span class="keyword">if</span> self.drop_block <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_block(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.se <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.se(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.drop_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.drop_path(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            shortcut = self.downsample(shortcut)</span><br><span class="line">        x += shortcut</span><br><span class="line">        x = self.act2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&lt;/p&gt;
&lt;h1 id=&quot;使用timm复现resnet&quot;&gt;使用timm复</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>用pytorch实现基础网络8-ConvNext</title>
    <link href="https://wangtongyouwen.github.io/post/aa153511.html"/>
    <id>https://wangtongyouwen.github.io/post/aa153511.html</id>
    <published>2023-04-18T10:32:10.000Z</published>
    <updated>2023-04-30T06:08:29.723Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-convnet-for-the-2020s">A ConvNet for the 2020s</h1><p>https://arxiv.org/pdf/2201.03545.pdf</p><p>A vanilla <strong>ViT</strong>, on the other hand, faces <strong>difficulties</strong> when applied to general computer vision tasks such as object detection and semantic segmentation</p><p>It is the <strong>hierarchical</strong> Transformers (e.g., <strong>Swin Transformers</strong>) that reintroduced several <strong>ConvNet</strong> priors, making Transformers practically viable as a generic vision backbone and demonstrating <strong>remarkable performance on a wide variety of vision tasks</strong>.</p><h2 id="理解什么是resnet-50">1 理解什么是ResNet-50</h2><ul><li>由48层卷积+1层maxpool+1层avgpool构成，卷积每个block的配比为3:4:6:3</li><li>ResNet50 Architecture</li></ul><figure><img src="https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png" alt="Table 1" /><figcaption aria-hidden="true">Table 1</figcaption></figure><h2 id="convnext主要宗旨">2 ConVNeXt主要宗旨</h2><ul><li>本文主要是希望基于ReSNet-50结构，并参考Swin-T的思考来升级改造ResNet，最终得到ResNet结构，并实现了新的准确率，并进一步探索了它的可扩展性。</li></ul><h2 id="优化器参数">3 优化器参数</h2><ul><li>AdamW，300epochs</li><li>准确率直接从76.1%提升到了78.8%</li><li>预训练学习率为4e-3，weight_decay=0.05,batchsize=4096</li><li>微调学习率为5e-5,weight_decay=1e-8,batchsize=512,layer-wise Ir decay</li></ul><h2 id="宏观设计">4 宏观设计</h2><ul><li>将[3,4,6,3]的区块比例改成了[3,3,9,3]</li><li>将底层的卷积替换成了4*4 stride=4的卷积，类似于patch</li><li>引入depth-wise conv，并将channels从64提升到96</li><li>引入bottleneck结构{channels分别为96 384 96}，并增大 kernel size 到 7*7</li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191428468.png" alt="image-20230419142812305" /><figcaption aria-hidden="true">image-20230419142812305</figcaption></figure><ul><li>至此，ImageNet-1k的准确率从78.8%提升到80.6%</li></ul><h2 id="微观设计">5 微观设计</h2><ul><li>将RELU替换成GELU，将BN替换为LN</li><li>引入更少激活函数和归一化层</li><li>采用2*2，stride=2的卷积进行下采样，并在底层、下采样之前和最后的平均池化之后加入LN层，使得训练更加稳定</li><li>至此，ImageNet-1k的准确率进一步提升到82.0%，击败Swin-T中的81.3%</li></ul><h2 id="可扩展性">6 可扩展性</h2><ul><li>ImageNet-1k训练<ul><li>随着参数数目和计算量的增大，准确率也在逐步提升至85.5%</li></ul></li><li>增加ImageNet-22k训练，在迁移至ImageNet-1k微调<ul><li>伴随预训练，同样的模型，效果涨幅约为2%</li><li>最终，ConvNeXt-XL效果达到87.8%</li></ul></li></ul><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191537241.png" alt="image-20230419144017393" /><figcaption aria-hidden="true">image-20230419144017393</figcaption></figure><h1 id="code">CODE</h1><p><a href="https://github.com/facebookresearch/ConvNeXt">facebookresearch/ConvNeXt: Code release for ConvNeXt model (github.com)</a></p><h2 id="block">1 block</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; ConvNeXt Block. There are two equivalent implementations:</span></span><br><span class="line"><span class="string">    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)</span></span><br><span class="line"><span class="string">    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back</span></span><br><span class="line"><span class="string">    We use (2) as we find it slightly faster in PyTorch</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        drop_path (float): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, drop_path=<span class="number">0.</span>, layer_scale_init_value=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dwconv = nn.Conv2d(dim, dim, kernel_size=<span class="number">7</span>, padding=<span class="number">3</span>, groups=dim) <span class="comment"># depthwise conv</span></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.pwconv1 = nn.Linear(dim, <span class="number">4</span> * dim) <span class="comment"># pointwise/1x1 convs, implemented with linear layers</span></span><br><span class="line">        self.act = nn.GELU()</span><br><span class="line">        self.pwconv2 = nn.Linear(<span class="number">4</span> * dim, dim)</span><br><span class="line">        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), </span><br><span class="line">                                    requires_grad=<span class="literal">True</span>) <span class="keyword">if</span> layer_scale_init_value &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="built_in">input</span> = x</span><br><span class="line">        x = self.dwconv(x)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>) <span class="comment"># (N, C, H, W) -&gt; (N, H, W, C)</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.pwconv1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.pwconv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.gamma <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.gamma * x</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>) <span class="comment"># (N, H, W, C) -&gt; (N, C, H, W)</span></span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">input</span> + self.drop_path(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="connext">2 ConNeXt</h2><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191505813.png" alt="image-20230419150530038" /><figcaption aria-hidden="true">image-20230419150530038</figcaption></figure><ul><li>stem<ul><li>conv2d: 3-&gt;96 kernel_size =4,stride=4</li><li>layernarm: 96</li></ul></li><li>downsampler_layer<ul><li>layernrom: 96, 192, 384</li><li>conv2d: 96, 192, 384 -&gt; 192, 384, 768 kernel_size = 2,stride = 2 (patch merging)</li></ul></li><li>stage(4个阶段)<ul><li>block数量:3,3,9,3</li><li>block input_channel: 96, 192, 384, 768</li><li>cur记录总的深度：每个深度的dropout是不同的，随着深度增大，dropout比例越大</li></ul></li><li>layernorm：768</li><li>head(Linear): 768 -&gt; num_classes</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>, </span></span><br><span class="line"><span class="params">             depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">3</span>], dims=[<span class="number">96</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>], drop_path_rate=<span class="number">0.</span>, </span></span><br><span class="line"><span class="params">             layer_scale_init_value=<span class="number">1e-6</span>, head_init_scale=<span class="number">1.</span>,</span></span><br><span class="line"><span class="params">             </span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    self.downsample_layers = nn.ModuleList() <span class="comment"># stem and 3 intermediate downsampling conv layers</span></span><br><span class="line">    stem = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">4</span>, stride=<span class="number">4</span>),</span><br><span class="line">        LayerNorm(dims[<span class="number">0</span>], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    self.downsample_layers.append(stem)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        downsample_layer = nn.Sequential(</span><br><span class="line">                LayerNorm(dims[i], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>),</span><br><span class="line">                nn.Conv2d(dims[i], dims[i+<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.downsample_layers.append(downsample_layer)</span><br><span class="line"></span><br><span class="line">    self.stages = nn.ModuleList() <span class="comment"># 4 feature resolution stages, each consisting of multiple residual blocks</span></span><br><span class="line">    dp_rates=[x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))] </span><br><span class="line">    cur = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        stage = nn.Sequential(</span><br><span class="line">            *[Block(dim=dims[i], drop_path=dp_rates[cur + j], </span><br><span class="line">            layer_scale_init_value=layer_scale_init_value) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(depths[i])]</span><br><span class="line">        )</span><br><span class="line">        self.stages.append(stage)</span><br><span class="line">        cur += depths[i]</span><br><span class="line"></span><br><span class="line">    self.norm = nn.LayerNorm(dims[-<span class="number">1</span>], eps=<span class="number">1e-6</span>) <span class="comment"># final norm layer</span></span><br><span class="line">    self.head = nn.Linear(dims[-<span class="number">1</span>], num_classes)</span><br><span class="line"></span><br><span class="line">    self.apply(self._init_weights)</span><br><span class="line">    self.head.weight.data.mul_(head_init_scale)</span><br><span class="line">    self.head.bias.data.mul_(head_init_scale)</span><br></pre></td></tr></table></figure><h1 id="isotropic-convnext-各向同性">Isotropic ConvNeXt 各向同性</h1><figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304191537246.png" alt="image-20230419153724437" /><figcaption aria-hidden="true">image-20230419153724437</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ef __init__(self, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>, </span><br><span class="line">                 depth=<span class="number">18</span>, dim=<span class="number">384</span>, drop_path_rate=<span class="number">0.</span>, </span><br><span class="line">                 layer_scale_init_value=<span class="number">0</span>, head_init_scale=<span class="number">1.</span>,</span><br><span class="line">                 ):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.stem = nn.Conv2d(in_chans, dim, kernel_size=<span class="number">16</span>, stride=<span class="number">16</span>)</span><br><span class="line">        dp_rates=[x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, depth)] </span><br><span class="line">        self.blocks = nn.Sequential(*[Block(dim=dim, drop_path=dp_rates[i], </span><br><span class="line">                                    layer_scale_init_value=layer_scale_init_value)</span><br><span class="line">                                    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line"></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>) <span class="comment"># final norm layer</span></span><br><span class="line">        self.head = nn.Linear(dim, num_classes)</span><br><span class="line"></span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line">        self.head.weight.data.mul_(head_init_scale)</span><br><span class="line">        self.head.bias.data.mul_(head_init_scale)</span><br></pre></td></tr></table></figure><ul><li>不需要step，各向同性，通道数目在每个阶段都是相同的</li></ul><h1 id="训练">训练</h1><ul><li>data_path</li><li>data_set {CIFAR,IMNET,image_foler}</li></ul><p>https://timm.fast.ai/这里有大量的cv网络的实现</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;a-convnet-for-the-2020s&quot;&gt;A ConvNet for the 2020s&lt;/h1&gt;
&lt;p&gt;https://arxiv.org/pdf/2201.03545.pdf&lt;/p&gt;
&lt;p&gt;A vanilla &lt;strong&gt;ViT&lt;/strong</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/categories/pytorch/network/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="network" scheme="https://wangtongyouwen.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>pytorch基础入门10-word embedding</title>
    <link href="https://wangtongyouwen.github.io/post/70a386a7.html"/>
    <id>https://wangtongyouwen.github.io/post/70a386a7.html</id>
    <published>2023-04-17T14:27:03.000Z</published>
    <updated>2023-04-30T06:07:54.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="语言建模">语言建模</h2><ul><li>基于已有的人类组织的文本语料，基于无监督学习如何组织一句话并还能得到单词的语义表征</li><li>统计模型：n-gram</li><li>无监督学习：NNLM</li><li>大规模无监督学习：word2vec,BERT</li></ul><h3 id="n-gram">1 n-gram</h3><ul><li>特点：统计性、简单、泛化能力差、无法得到单词的语义信息</li><li>定义：n个相邻字符构成的序列<ul><li>unigram</li><li>bigram</li><li>trigram</li></ul></li><li>用途：基于n-gram的频数分析文本，如垃圾邮件分类</li><li>对于word n-gram，特征维度随着语料词汇增大和n增大而指数增大(curse of dimensionality 维度灾难)</li><li>对于character n-gram，特征维度只随着n增大而增大</li></ul><h3 id="单词的语义表征">2 单词的语义表征</h3><ul><li>稀疏式<ul><li>one-hot encoding 只能反应出单词在单词表中的位置信息，不能得出任何语义上的信息</li></ul></li><li>分布式<ul><li>类似于word embedding 固定长度，每个位置上都是浮点型，这种语义表征是隐式的，是训练获得的(通过向量点积能得到相似度)</li></ul></li><li>应用场景<ul><li>word/character/phrase/sentence/paragraph embedding</li><li>speaker/user/item embedding</li></ul></li></ul><h3 id="基于神经网络的语言模型nnlm">3 基于神经网络的语言模型(NNLM)</h3><ul><li>NNLM包括：<ul><li>输入层(one-hot)</li><li>投影层</li><li>隐含层</li><li>输出层</li></ul></li><li>word embeddings为副产物，隐含的语义表征</li><li>主要复杂度： N*D*H+H*V</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/dQiaQ6INiazLoDx1sOWTQSTiaoLahdlZvZ9gBdtWVSS6gsqz8PLgHAPUesz0mqVCyo2MwjO6yssqnBOPO5BJ8z1lg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="Image" style="zoom:67%;" /></p><ul><li>如何降低复杂度？如何训练大规模数据？</li></ul><h3 id="word2vec">4 word2vec</h3><h4 id="改进1抛弃了隐含层并提出cbow和skip-gram">改进1：抛弃了隐含层，并提出CBOW和Skip-gram</h4><ul><li>continuous Bag-of-Words<ul><li>不同于NNLM，CBOW考虑到了前后上下文</li><li>使用周围单词预测中间单词</li><li>输入：前n个单词和后n个单词</li><li>目标：基于H-softmax预测中间单词</li></ul></li></ul><p><span class="math display">\[J_{\theta}=\frac{1}{T}\sum^T_{t=1}log P(w_t|w_{t-n},\dots,w_{t-1},w_{t+1},\dots,w_{t+n})\]</span></p><ul><li>Skip-gram<ul><li>与CBOW相反，使用中间单词预测周围单词</li><li>输入：中间单词</li><li>目标：基于H-softmax预测前n个单词和后n个单词</li></ul></li></ul><p><span class="math display">\[J_{\theta} = \frac{1}{T}\sum^T_{t=1} \sum_{-n\le j\le n,n\ne 0}log\ \ p(w_{t+j}|w_t)\]</span></p><figure><img src="https://www.baeldung.com/wp-content/uploads/sites/4/2021/03/Screenshot-2021-03-05-at-11.29.31-1024x616-1.png" alt="Screenshot-2021-03-05-at-11.29.31" /><figcaption aria-hidden="true">Screenshot-2021-03-05-at-11.29.31</figcaption></figure><h4 id="改进2优化softmax">改进2：优化softmax</h4><ul><li>softmax<ul><li>计算量跟单词表数目K呈线性关系</li></ul></li></ul><p><span class="math display">\[\sigma(\vec z)_i = \frac{e^{z_i}}{\sum^K_{j=1}e^{z_j}}\]</span></p><ul><li>hierarchical softmax(huffman树)</li></ul><ol type="1"><li>将{w1,w2,...,wn}看成是由n棵树的森林(每棵树仅有一个节点)</li><li>在森林中选出两个树节点的权值最小的树合并，作为一棵新树的左右子树，且新树的根节点权值为其左、右子树节点权值之和</li><li>从森林中删除选取的两棵树，并将新树加入森林</li><li>重复2,3步，知道森林中只剩一棵树为止，该树就为所求的Huffman树</li></ol><p><img src="https://www.ruder.io/content/images/2016/05/hierarchical_softmax.png" alt="img" /> <span class="math display">\[p(right|n,c)=\sigma(h^Tv&#39;_n)\]</span></p><p><span class="math display">\[p(left|n,c) = 1-\sigma(h^Tv&#39;_n)\]</span></p><h4 id="改进3引入负采样">改进3：引入负采样</h4><ul><li>continuous bag ofwords<ul><li>输入：前n个单词和后n个单词</li><li>目标：使得预测中间单词的概率最大，负样本单词的概率最小</li></ul></li></ul><p><span class="math display">\[g(w) = \prod_{u\in {w} \bigcup NEG(w)}p(u|Context(w))\]</span></p><ul><li>Skip-gram<ul><li>入：中间单词</li><li>目标：使得上下文单词概率最大，负样本单词的概率最小</li></ul></li></ul><p><span class="math display">\[g(w) = \prod_{\tilde w\in {Context(w)}} \prod_{u\in {w} \bigcup  NEG^{\tilde w}(w)} p(u|\tilde w)\]</span></p><h2 id="word-embeddings-in-pytorch">word embeddings in pytorch</h2><p>https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;语言建模&quot;&gt;语言建模&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;基于已有的人类组织的文本语料，基于无监督学习如何组织一句话并还能得到单词的语义表征&lt;/li&gt;
&lt;li&gt;统计模型：n-gram&lt;/li&gt;
&lt;li&gt;无监督学习：NNLM&lt;/li&gt;
&lt;li&gt;大规模无监督学习：w</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>pytorch实用工具2-编写技巧</title>
    <link href="https://wangtongyouwen.github.io/post/898bb30b.html"/>
    <id>https://wangtongyouwen.github.io/post/898bb30b.html</id>
    <published>2023-04-17T11:36:18.000Z</published>
    <updated>2023-04-17T14:20:00.293Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304172006805.png" alt="编写技巧" /><figcaption aria-hidden="true">编写技巧</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange,reduce,repeat</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.randn(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>) <span class="comment"># 4D tensor bs*ic*h*w</span></span><br></pre></td></tr></table></figure><h2 id="rearrange">1 rearrange</h2><h3 id="转置">1.1 转置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转置</span></span><br><span class="line">out1 = x.transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">out2 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b h i w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure><h3 id="变形">1.2 变形</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变形</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; (b i) h w&#x27;</span>)</span><br><span class="line">out2 = x.reshape(<span class="number">6</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">out3 = rearrange(out2,<span class="string">&#x27;(b i) h w -&gt; b i h w&#x27;</span>,b=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out3,x))</span><br></pre></td></tr></table></figure><h3 id="image2patch">1.3 image2patch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image2patch</span></span><br><span class="line">bs, ic, h, w = x.shape</span><br><span class="line">p = <span class="number">2</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i (h1 p1) (w1 p2) -&gt; b (h1 w1) (i p1 p2)&#x27;</span>,p1=<span class="number">2</span>,p2=<span class="number">2</span>) <span class="comment"># p是patch的边长 [batchsize,num_patch,patch_depth]</span></span><br><span class="line">out2 = F.unfold(x, kernel_size=(p, p),stride=(p, p)).transpose(-<span class="number">1</span>, -<span class="number">2</span>)  <span class="comment"># [bs,num_patch,patch_depth]</span></span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure><h3 id="堆叠">1.4 堆叠</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 堆叠</span></span><br><span class="line"><span class="built_in">print</span>(bs,i,h,w) <span class="comment"># (2,2,4,4)</span></span><br><span class="line">tensor_list = [x,x,x] <span class="comment"># only in the form of einops</span></span><br><span class="line">out1 = rearrange(tensor_list,<span class="string">&#x27;n b i h w -&gt; n b i h w&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(out1.shape)</span><br><span class="line"></span><br><span class="line">y = torch.randn(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">out2 = y.repeat(bs,i,h,w).reshape(<span class="number">3</span>,bs,i,h,w)</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br></pre></td></tr></table></figure><h2 id="reduce">2 reduce</h2><h3 id="求平均池化">2.1 求平均池化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求平均池化</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>) <span class="comment"># mean, min, max, sum, prod</span></span><br><span class="line">out2 = torch.mean(x,(-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure><h3 id="求和">2.2 求和</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求和</span></span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i h 1&#x27;</span>,<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># keep dimension</span></span><br><span class="line">out2 = torch.<span class="built_in">sum</span>(x,(-<span class="number">1</span>)).unsqueeze(-<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure><h3 id="多个维度操作">2.3 多个维度操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多个维度操作</span></span><br><span class="line">b, i, h, w = x.shape</span><br><span class="line">out1 = reduce(x,<span class="string">&#x27;b i h w -&gt; b i&#x27;</span>,<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">out2 = torch.max_pool2d(x,(h,w)).reshape(b,i)</span><br><span class="line"><span class="built_in">print</span>(torch.allclose(out1,out2))</span><br></pre></td></tr></table></figure><h2 id="repeat">3 repeat</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制</span></span><br><span class="line">out1 = rearrange(x,<span class="string">&#x27;b i h w -&gt; b i h w 1&#x27;</span>)</span><br><span class="line">out2 = repeat(out1,<span class="string">&#x27;b i h w 1 -&gt; b i (2 h) w 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">out3 = torch.tile(out1,(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,))</span><br><span class="line"><span class="built_in">print</span>(out2.shape)</span><br><span class="line"><span class="built_in">print</span>(out3.shape)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure&gt;
&lt;img src=&quot;https://picgo-1259245122.cos.ap-shanghai.myqcloud.com/img/blog/202304172006805.png&quot; alt=&quot;编写技巧&quot; /&gt;&lt;figcaption aria-hidden</summary>
      
    
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/categories/pytorch/"/>
    
    <category term="tools" scheme="https://wangtongyouwen.github.io/categories/pytorch/tools/"/>
    
    
    <category term="pytorch" scheme="https://wangtongyouwen.github.io/tags/pytorch/"/>
    
    <category term="tools" scheme="https://wangtongyouwen.github.io/tags/tools/"/>
    
  </entry>
  
</feed>
